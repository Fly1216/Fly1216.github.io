<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>国赛数据挖掘样题</title>
      <link href="/2023/07/05/%E5%9B%BD%E8%B5%9B%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98%E6%A0%B7%E9%A2%98/"/>
      <url>/2023/07/05/%E5%9B%BD%E8%B5%9B%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98%E6%A0%B7%E9%A2%98/</url>
      
        <content type="html"><![CDATA[<p>版权：flyohh</p><h1 id="电商"><a href="#电商" class="headerlink" title="电商"></a>电商</h1><p>注意：需要剔除订单信息表中用户id不存在于现有的维表中的记录和剔除订单详细信息表中商品id不存在于现有的维表中的记录</p><h2 id="第一题"><a href="#第一题" class="headerlink" title="第一题"></a>第一题</h2><p>根据MySQL中dsdb中相关表计算出与用户id为6708的用户所购买相同商品种类最多的前10位用户（只考虑他俩购买过多少种相同的商品，不考虑相同的商品买了多少次），将10位用户id进行输出，将结果截图粘贴至【任务C提交结果.docx】中对应的任务序号下。</p><p>输出格式如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">-------------------相同种类前10的id结果展示为：--------------------</span><br><span class="line">1,2,901,4,5,21,32,91,14,52</span><br></pre></td></tr></table></figure><h2 id="第二题"><a href="#第二题" class="headerlink" title="第二题"></a>第二题</h2><p>根据MySQL中dsdb中的商品表，对price和weight进行规范化(StandardScaler)处理，对brand_id、three_category_id进行one-hot编码处理（若该商品属于该品牌则置为1，否则置为0），并按照id进行升序排序，在集群中输出第一条数据前10列（无需展示字段名），将结果截图粘贴至【任务C提交结果.docx】中对应的任务序号下。</p><table><thead><tr><th>字段</th><th>类型</th><th>中文含义</th><th>备注</th></tr></thead><tbody><tr><td>id</td><td>double</td><td>主键</td><td></td></tr><tr><td>price</td><td>double</td><td>价格</td><td></td></tr><tr><td>weight</td><td>double</td><td>重量</td><td></td></tr><tr><td>spu_id#1</td><td>double</td><td>spu_id 1</td><td>若属于该spu_id，则内容为1否则为0</td></tr><tr><td>spu_id#2</td><td>double</td><td>spu_id 2</td><td>若属于该spu_id，则内容为1否则为0</td></tr><tr><td>…..</td><td>double</td><td></td><td></td></tr><tr><td>tm_id#1</td><td>double</td><td>品牌1</td><td>若属于该品牌，则内容为1否则为0</td></tr><tr><td>tm_id#2</td><td>double</td><td>品牌2</td><td>若属于该品牌，则内容为1否则为0</td></tr><tr><td>……</td><td>double</td><td></td><td></td></tr><tr><td>category3_id#1</td><td>double</td><td>分类级别3 1</td><td>若属于该分类级别3，则内容为1否则为0</td></tr><tr><td>category3_id#2</td><td>double</td><td>分类级别3 2</td><td>若属于该分类级别3，则内容为1否则为0</td></tr><tr><td>……</td><td></td><td></td><td></td></tr></tbody></table><p>结果格式如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">--------------------第一条数据前10列结果展示为：---------------------</span><br><span class="line">1.0,0.892346,1.72568,0.0,0.0,0.0,0.0,1.0,0.0,0.0</span><br></pre></td></tr></table></figure><h2 id="第三题"><a href="#第三题" class="headerlink" title="第三题"></a>第三题</h2><p>根据第一题的结果，计算出与用户id为6708的用户所购买相同商品种类最多的前10位用户id（只考虑他俩购买过多少种相同的商品，不考虑相同的商品买了多少次），并根据MySQL数据库dsdb中相关表，获取到这10位用户已购买过的商品，并剔除用户6708已购买的商品，通过计算这10位用户已购买的商品（剔除用户6708已购买的商品）与用户6708已购买的商品数据集中商品的余弦相似度累加再求均值，输出均值前5商品id作为推荐使用，将执行结果截图粘贴至【任务C提交结果.docx】中对应的任务序号下。</p><p>结果格式如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">------------------------推荐Top5结果如下------------------------</span><br><span class="line">相似度top1(商品id：1，平均相似度：0.983456)</span><br><span class="line">相似度top2(商品id：71，平均相似度：0.782672)</span><br><span class="line">相似度top3(商品id：22，平均相似度：0.7635246)</span><br><span class="line">相似度top4(商品id：351，平均相似度：0.7335748)</span><br><span class="line">相似度top5(商品id：14，平均相似度：0.522356)</span><br></pre></td></tr></table></figure><h2 id="第四题"><a href="#第四题" class="headerlink" title="第四题"></a>第四题</h2><p>根据MySQL数据库dsdb中的相关表对用户购买过的商品进行去重，将其转换为以下格式：第一列为用户id mapping，第二列为用户购买过的商品id mapping，按照user_id与sku_id进行升序排序，输出前5行，将结果截图粘贴至【任务C提交结果.docx】中对应的任务序号下。</p><table><thead><tr><th>字段</th><th>类型</th><th>中文含义</th><th>备注</th></tr></thead><tbody><tr><td>user_id</td><td>int</td><td>用户id的mapping对应键</td><td></td></tr><tr><td>sku_id</td><td>int</td><td>商品id的mapping对应键</td><td></td></tr></tbody></table><p>提示：例如用户id：1、7、4，则做完mapping操作转为字典类型，键0对应用户id 1，键1对应用户id 4，键2对应用户id 7，商品id同理</p><p>结果格式如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">-------user_id_mapping与sku_id_mapping数据前5条如下：-------</span><br><span class="line">0:0</span><br><span class="line">0:89</span><br><span class="line">1:1</span><br><span class="line">1:2</span><br><span class="line">1:3</span><br></pre></td></tr></table></figure><h2 id="第五题"><a href="#第五题" class="headerlink" title="第五题"></a>第五题</h2><p>根据第四题的结果，对其进行聚合，其中对sku_id进行one-hot转换，将其转换为以下格式矩阵：第一列为用户id，其余列名为商品id，按照商品id进行升序排序，展示矩阵第一行前5列数据，将结果截图粘贴至【任务C提交结果.docx】中对应的任务序号下。</p><table><thead><tr><th>字段</th><th>类型</th><th>中文含义</th><th>备注</th></tr></thead><tbody><tr><td>user_id</td><td>double</td><td>客户key</td><td></td></tr><tr><td>sku_id0</td><td>double</td><td>用户是否购买过商品1</td><td>若用户购买过该商品，则值为1，否则为0</td></tr><tr><td>sku_id1</td><td>double</td><td>用户是否购买过商品2</td><td>若用户购买过该商品，则值为1，否则为0</td></tr><tr><td>sku_id2</td><td>double</td><td>用户是否购买过商品3</td><td>若用户购买过该商品，则值为1，否则为0</td></tr><tr><td>…..</td><td></td><td></td><td></td></tr></tbody></table><p>结果格式如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">---------------第一行前5列结果展示为---------------</span><br><span class="line">0.0,1.0,0.0,0.0,0.0</span><br></pre></td></tr></table></figure><h2 id="第六题"><a href="#第六题" class="headerlink" title="第六题"></a>第六题</h2><p>根据第四五题的结果，对其进行SVD分解，对数据进行降维保留前5个奇异值信息，根据该用户已购买的商品分别与未购买的商品计算余弦相似度再进行累加求均值，将均值最大的5件商品id进行输出作为推荐使用。将输出结果截图粘贴至【任务C提交结果.docx】中对应的任务序号下。</p><p>结果格式如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">------------------------推荐Top5结果如下------------------------</span><br><span class="line">相似度top1(商品id：1，平均相似度：0.983456)</span><br><span class="line">相似度top2(商品id：71，平均相似度：0.782672)</span><br><span class="line">相似度top3(商品id：22，平均相似度：0.7635246)</span><br><span class="line">相似度top4(商品id：351，平均相似度：0.7335748)</span><br><span class="line">相似度top5(商品id：14，平均相似度：0.522356)</span><br></pre></td></tr></table></figure><h1 id="工业"><a href="#工业" class="headerlink" title="工业"></a>工业</h1><h2 id="第一题-1"><a href="#第一题-1" class="headerlink" title="第一题"></a>第一题</h2><p>根据MySQL的shtd_industry库中MachineDataStudyTrain表，根据以下要求转换：首先解析列MachineRecordData的数据（数据格式为xml，采用dom4j解析），并获取每条数据的<strong>主轴转速，主轴倍率，主轴负载，进给倍率，进给速度，PMC程序号，循环时间，运行时间，有效轴数，总加工个数，已使用内存，未使用内存，可用程序量，注册程序量等相关的值</strong>（若该条数据没有相关值，则按下表设置默认值），同时转换MachineRecordState字段的值，若值为报警，则填写1，否则填写0，以下为表结构，将数据保存在study.fact_machine_learning_data，使用cli按照machine_record_id升序排序，查询前1条数据，将结果截图粘贴至【任务C提交结果.docx】中对应的任务序号下。</p><p>study.fact_machine_learning_data表结构：</p><table><thead><tr><th>字段</th><th>类型</th><th>中文含义</th><th>备注</th></tr></thead><tbody><tr><td>machine_record_id</td><td>int</td><td>主键</td><td></td></tr><tr><td>machine_id</td><td>double</td><td>设备id</td><td></td></tr><tr><td>machine_record_state</td><td>double</td><td>设备状态</td><td>默认0.0</td></tr><tr><td>machine_record_mainshaft_speed</td><td>double</td><td>主轴转速</td><td>默认0.0</td></tr><tr><td>machine_record_mainshaft_multiplerate</td><td>double</td><td>主轴倍率</td><td>默认0.0</td></tr><tr><td>machine_record_mainshaft_load</td><td>double</td><td>主轴负载</td><td>默认0.0</td></tr><tr><td>machine_record_feed_speed</td><td>double</td><td>进给倍率</td><td>默认0.0</td></tr><tr><td>machine_record_feed_multiplerate</td><td>double</td><td>进给速度</td><td>默认0.0</td></tr><tr><td>machine_record_pmc_code</td><td>double</td><td>PMC程序号</td><td>默认0.0</td></tr><tr><td>machine_record_circle_time</td><td>double</td><td>循环时间</td><td>默认0.0</td></tr><tr><td>machine_record_run_time</td><td>double</td><td>运行时间</td><td>默认0.0</td></tr><tr><td>machine_record_effective_shaft</td><td>double</td><td>有效轴数</td><td>默认0.0</td></tr><tr><td>machine_record_amount_process</td><td>double</td><td>总加工个数</td><td>默认0.0</td></tr><tr><td>machine_record_use_memory</td><td>double</td><td>已使用内存</td><td>默认0.0</td></tr><tr><td>machine_record_free_memory</td><td>double</td><td>未使用内存</td><td>默认0.0</td></tr><tr><td>machine_record_amount_use_code</td><td>double</td><td>可用程序量</td><td>默认0.0</td></tr><tr><td>machine_record_amount_free_code</td><td>double</td><td>注册程序量</td><td>默认0.0</td></tr><tr><td>machine_record_date</td><td>timestamp</td><td>记录日期</td><td></td></tr></tbody></table><h2 id="第二题-1"><a href="#第二题-1" class="headerlink" title="第二题"></a>第二题</h2><p>根据子任务一的结果，建立随机森林（随机森林相关参数可自定义，不做限制），使用子任务一的结果训练随机森林模型，然后再将MySQL的shtd_industry库中MachineDataStudyTest表转成向量（该表字段含义与dwd.fact_machine_learning_data表相同，machine_record_state列值为空，表结构自行查看），预测其是否报警将结果输出到MySQL数据库shtd_iresult中的ml_result表中（表结构如下）。在Linux的MySQL命令行中查询出machine_record_id为1、8、20、28和36的5条数据，将SQL语句复制并粘贴至【任务C提交结果.docx】中对应的任务序号下，将执行结果截图粘贴至【任务C提交结果.docx】中对应的任务序号下。</p><p>ml_result表结构：</p><table><thead><tr><th>字段</th><th>类型</th><th>中文含义</th><th>备注</th></tr></thead><tbody><tr><td>machine_record_id</td><td>int</td><td>主键</td><td></td></tr><tr><td>machine_record_state</td><td>double</td><td>设备状态</td><td>报警为1，其他状态则为0</td></tr></tbody></table>]]></content>
      
      
      <categories>
          
          <category> 大数据比赛 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 大数据 </tag>
            
            <tag> Spark </tag>
            
            <tag> Spark-ML </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hudi-Idea编程-增删改查</title>
      <link href="/2023/06/16/Hudi-Idea%E7%BC%96%E7%A8%8B/"/>
      <url>/2023/06/16/Hudi-Idea%E7%BC%96%E7%A8%8B/</url>
      
        <content type="html"><![CDATA[<p>版权：flyohh</p><h1 id="准备工作"><a href="#准备工作" class="headerlink" title="准备工作"></a>准备工作</h1><p>新建maven工程，新建hudi包，新建包文件，修改pom文件，新建log4j.properties文件，如下</p><p><strong>pom.xml</strong></p><p>其中复制<code>&lt;properties&gt;</code>到<code>&lt;/build&gt;</code>部分到你的pom文件覆盖原有的然后刷新即可</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version=<span class="string">&quot;1.0&quot;</span> encoding=<span class="string">&quot;UTF-8&quot;</span>?&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">project</span> <span class="attr">xmlns</span>=<span class="string">&quot;http://maven.apache.org/POM/4.0.0&quot;</span></span></span><br><span class="line"><span class="tag">         <span class="attr">xmlns:xsi</span>=<span class="string">&quot;http://www.w3.org/2001/XMLSchema-instance&quot;</span></span></span><br><span class="line"><span class="tag">         <span class="attr">xsi:schemaLocation</span>=<span class="string">&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">modelVersion</span>&gt;</span>4.0.0<span class="tag">&lt;/<span class="name">modelVersion</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>flyohh.cn<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>NationalCompetition<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.0-SNAPSHOT<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">properties</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">maven.compiler.source</span>&gt;</span>8<span class="tag">&lt;/<span class="name">maven.compiler.source</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">maven.compiler.target</span>&gt;</span>8<span class="tag">&lt;/<span class="name">maven.compiler.target</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">scala.version</span>&gt;</span>2.12<span class="tag">&lt;/<span class="name">scala.version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">hive.version</span>&gt;</span>3.1.2<span class="tag">&lt;/<span class="name">hive.version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">mysqlconnect.version</span>&gt;</span>5.1.47<span class="tag">&lt;/<span class="name">mysqlconnect.version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">clickhouse.version</span>&gt;</span>0.3.2<span class="tag">&lt;/<span class="name">clickhouse.version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">hdfs.version</span>&gt;</span>3.1.3<span class="tag">&lt;/<span class="name">hdfs.version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">spark.version</span>&gt;</span>3.1.1<span class="tag">&lt;/<span class="name">spark.version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">hbase.version</span>&gt;</span>2.2.3<span class="tag">&lt;/<span class="name">hbase.version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">lang3.version</span>&gt;</span>3.9<span class="tag">&lt;/<span class="name">lang3.version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">flink-connector-redis.verion</span>&gt;</span>1.1.5<span class="tag">&lt;/<span class="name">flink-connector-redis.verion</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">hudi.version</span>&gt;</span>0.12.0<span class="tag">&lt;/<span class="name">hudi.version</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">properties</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">dependencies</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.scala-lang<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>scala-reflect<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">version</span>&gt;</span>$&#123;scala.version&#125;.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.scala-lang<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>scala-compiler<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">version</span>&gt;</span>$&#123;scala.version&#125;.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.scala-lang<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>scala-library<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">version</span>&gt;</span>$&#123;scala.version&#125;.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">&lt;!--mysql连接器--&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>mysql<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>mysql-connector-java<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">version</span>&gt;</span>$&#123;mysqlconnect.version&#125;<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">&lt;!--spark处理离线--&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.spark<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spark-core_2.12<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">exclusions</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">exclusion</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.hive<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>hive-exec<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;/<span class="name">exclusion</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;/<span class="name">exclusions</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">version</span>&gt;</span>3.1.1<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.spark<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spark-sql_2.12<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">exclusions</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">exclusion</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.hive<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>hive-exec<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;/<span class="name">exclusion</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;/<span class="name">exclusions</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">version</span>&gt;</span>3.1.1<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.spark<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spark-hive_2.12<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">version</span>&gt;</span>3.1.1<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.hive<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>hive-jdbc<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">version</span>&gt;</span>$&#123;hive.version&#125;<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        <span class="comment">&lt;!-- hadoop相关--&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.hadoop<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>hadoop-client<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">version</span>&gt;</span>3.1.3<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.hadoop<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>hadoop-auth<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">version</span>&gt;</span>3.1.3<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">&lt;!-- hudi-spark3 --&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.hudi<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>hudi-spark3.1-bundle_2.12<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">version</span>&gt;</span> $&#123;hudi.version&#125;<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">dependencies</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">build</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">resources</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">resource</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">directory</span>&gt;</span>src/main/scala<span class="tag">&lt;/<span class="name">directory</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;/<span class="name">resource</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">resource</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">directory</span>&gt;</span>src/main/java<span class="tag">&lt;/<span class="name">directory</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;/<span class="name">resource</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">resource</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">directory</span>&gt;</span>src/main/resources<span class="tag">&lt;/<span class="name">directory</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;/<span class="name">resource</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">resources</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">plugins</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">plugin</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>net.alchim31.maven<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>scala-maven-plugin<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">version</span>&gt;</span>3.2.2<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">recompileMode</span>&gt;</span>incremental<span class="tag">&lt;/<span class="name">recompileMode</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">executions</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">execution</span>&gt;</span></span><br><span class="line">                        <span class="tag">&lt;<span class="name">goals</span>&gt;</span></span><br><span class="line">                            <span class="tag">&lt;<span class="name">goal</span>&gt;</span>compile<span class="tag">&lt;/<span class="name">goal</span>&gt;</span></span><br><span class="line">                            <span class="tag">&lt;<span class="name">goal</span>&gt;</span>testCompile<span class="tag">&lt;/<span class="name">goal</span>&gt;</span></span><br><span class="line">                        <span class="tag">&lt;/<span class="name">goals</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;/<span class="name">execution</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;/<span class="name">executions</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;/<span class="name">plugin</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">plugin</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.maven.plugins<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>maven-compiler-plugin<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">version</span>&gt;</span>3.1<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">source</span>&gt;</span>8<span class="tag">&lt;/<span class="name">source</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">target</span>&gt;</span>8<span class="tag">&lt;/<span class="name">target</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;/<span class="name">plugin</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">plugins</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">build</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;/<span class="name">project</span>&gt;</span></span><br></pre></td></tr></table></figure><p><strong>log4j.properties</strong></p><figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># Licensed to the Apache Software Foundation (ASF) under one or more</span></span><br><span class="line"><span class="comment"># contributor license agreements.  See the NOTICE file distributed with</span></span><br><span class="line"><span class="comment"># this work for additional information regarding copyright ownership.</span></span><br><span class="line"><span class="comment"># The ASF licenses this file to You under the Apache License, Version 2.0</span></span><br><span class="line"><span class="comment"># (the &quot;License&quot;); you may not use this file except in compliance with</span></span><br><span class="line"><span class="comment"># the License.  You may obtain a copy of the License at</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment">#    http://www.apache.org/licenses/LICENSE-2.0</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># Unless required by applicable law or agreed to in writing, software</span></span><br><span class="line"><span class="comment"># distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span></span><br><span class="line"><span class="comment"># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span></span><br><span class="line"><span class="comment"># See the License for the specific language governing permissions and</span></span><br><span class="line"><span class="comment"># limitations under the License.</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment"># Set everything to be logged to the console</span></span><br><span class="line"><span class="attr">log4j.rootCategory</span>=<span class="string">ERROR, console</span></span><br><span class="line"><span class="attr">log4j.appender.console</span>=<span class="string">org.apache.log4j.ConsoleAppender</span></span><br><span class="line"><span class="attr">log4j.appender.console.target</span>=<span class="string">System.err</span></span><br><span class="line"><span class="attr">log4j.appender.console.layout</span>=<span class="string">org.apache.log4j.PatternLayout</span></span><br><span class="line"><span class="attr">log4j.appender.console.layout.ConversionPattern</span>=<span class="string">%d&#123;yy/MM/dd HH:mm:ss&#125; %p %c&#123;1&#125;: %m%n</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment"># Set the default spark-shell log level to WARN. When running the spark-shell, the</span></span><br><span class="line"><span class="comment"># log level for this class is used to overwrite the root logger&#x27;s log level, so that</span></span><br><span class="line"><span class="comment"># the user can have different defaults for the shell and regular Spark apps.</span></span><br><span class="line"><span class="attr">log4j.logger.org.apache.spark.repl.Main</span>=<span class="string">WARN</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment"># Settings to quiet third party logs that are too verbose</span></span><br><span class="line"><span class="attr">log4j.logger.org.sparkproject.jetty</span>=<span class="string">WARN</span></span><br><span class="line"><span class="attr">log4j.logger.org.sparkproject.jetty.util.component.AbstractLifeCycle</span>=<span class="string">ERROR</span></span><br><span class="line"><span class="attr">log4j.logger.org.apache.spark.repl.SparkIMain$exprTyper</span>=<span class="string">INFO</span></span><br><span class="line"><span class="attr">log4j.logger.org.apache.spark.repl.SparkILoop$SparkILoopInterpreter</span>=<span class="string">INFO</span></span><br><span class="line"><span class="attr">log4j.logger.org.apache.parquet</span>=<span class="string">ERROR</span></span><br><span class="line"><span class="attr">log4j.logger.parquet</span>=<span class="string">ERROR</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment"># SPARK-9183: Settings to avoid annoying messages when looking up nonexistent UDFs in SparkSQL with Hive support</span></span><br><span class="line"><span class="attr">log4j.logger.org.apache.hadoop.hive.metastore.RetryingHMSHandler</span>=<span class="string">FATAL</span></span><br><span class="line"><span class="attr">log4j.logger.org.apache.hadoop.hive.ql.exec.FunctionRegistry</span>=<span class="string">ERROR</span></span><br></pre></td></tr></table></figure><p><strong>package.object</strong></p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.spark.sql.<span class="type">SparkSession</span></span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * @author Super小飞象 2023/6/16</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">package</span> <span class="class"><span class="keyword">object</span> <span class="title">hudi</span> </span>&#123;</span><br><span class="line">  <span class="keyword">val</span> spark: <span class="type">SparkSession</span> = <span class="type">SparkSession</span>.builder</span><br><span class="line">    .appName(<span class="keyword">this</span>.getClass.getName)</span><br><span class="line">    .master(<span class="string">&quot;local[*]&quot;</span>)</span><br><span class="line">    .config(<span class="string">&quot;spark.serializer&quot;</span>, <span class="string">&quot;org.apache.spark.serializer.KryoSerializer&quot;</span>)</span><br><span class="line">    .getOrCreate</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h1 id="插入数据"><a href="#插入数据" class="headerlink" title="插入数据"></a>插入数据</h1><p><strong>要素</strong></p><ul><li>设置format为hudi</li><li>传入getQuickstartWriteConfigs</li><li>设置主键、合并字段、分区字段、表名</li><li>多重主键或分区用英文逗号拼接</li></ul><p><strong>Demo1.object</strong></p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> hudi</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> hudi.spark.implicits._</span><br><span class="line"><span class="keyword">import</span> org.apache.hudi.<span class="type">DataSourceWriteOptions</span>.&#123;<span class="type">PARTITIONPATH_FIELD</span>, <span class="type">PRECOMBINE_FIELD</span>, <span class="type">RECORDKEY_FIELD</span>&#125;</span><br><span class="line"><span class="keyword">import</span> org.apache.hudi.<span class="type">QuickstartUtils</span>.getQuickstartWriteConfigs</span><br><span class="line"><span class="keyword">import</span> org.apache.hudi.config.<span class="type">HoodieWriteConfig</span>.<span class="type">TBL_NAME</span></span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * @author Super小飞象 2023/6/16</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">Demo1</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">run</span></span>():<span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="comment">// TODO 多主键多分区插入数据</span></span><br><span class="line">    <span class="type">Seq</span>(</span><br><span class="line">      (<span class="number">1</span>, <span class="string">&quot;zs&quot;</span>, <span class="string">&quot;csc&quot;</span>, <span class="string">&quot;sup&quot;</span>, <span class="string">&quot;20230616093645&quot;</span>, <span class="number">1</span>),</span><br><span class="line">      (<span class="number">2</span>, <span class="string">&quot;ls&quot;</span>, <span class="string">&quot;cdc&quot;</span>, <span class="string">&quot;cdc&quot;</span>, <span class="string">&quot;20230616093645&quot;</span>, <span class="number">1</span>),</span><br><span class="line">      (<span class="number">3</span>, <span class="string">&quot;ww&quot;</span>, <span class="string">&quot;csc&quot;</span>, <span class="string">&quot;dmg&quot;</span>, <span class="string">&quot;20230616093645&quot;</span>, <span class="number">1</span>),</span><br><span class="line">      (<span class="number">4</span>, <span class="string">&quot;zl&quot;</span>, <span class="string">&quot;cqc&quot;</span>, <span class="string">&quot;gosh&quot;</span>, <span class="string">&quot;20230616093645&quot;</span>, <span class="number">1</span>)</span><br><span class="line">    )</span><br><span class="line">      .toDF(<span class="string">&quot;uuid&quot;</span>, <span class="string">&quot;name&quot;</span>, <span class="string">&quot;city&quot;</span>, <span class="string">&quot;team&quot;</span>, <span class="string">&quot;ts&quot;</span>, <span class="string">&quot;num&quot;</span>)</span><br><span class="line">      .write</span><br><span class="line">      .format(<span class="string">&quot;hudi&quot;</span>)</span><br><span class="line">      .mode(<span class="string">&quot;overwrite&quot;</span>)</span><br><span class="line">      .options(getQuickstartWriteConfigs)</span><br><span class="line">      .option(<span class="type">RECORDKEY_FIELD</span>.key(), <span class="string">&quot;uuid,name&quot;</span>)</span><br><span class="line">      .option(<span class="type">PRECOMBINE_FIELD</span>.key(), <span class="string">&quot;ts&quot;</span>)</span><br><span class="line">      .option(<span class="type">PARTITIONPATH_FIELD</span>.key(), <span class="string">&quot;city,team&quot;</span>)</span><br><span class="line">      .option(<span class="type">TBL_NAME</span>.key(), <span class="string">&quot;hudi_demo&quot;</span>)</span><br><span class="line">      .save(<span class="string">&quot;hdfs://node:8020/user/hive/warehouse/hudi_demo&quot;</span>)</span><br><span class="line">    spark.read.format(<span class="string">&quot;hudi&quot;</span>).load(<span class="string">&quot;hdfs://node:8020/user/hive/warehouse/hudi_demo&quot;</span>).show</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    run()</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>结果</strong></p><p><img src="https://flyohh.cloud/blog_img/2023/06/16/648c4f1485489.png" alt="Demo1"></p><h1 id="追加写入数据"><a href="#追加写入数据" class="headerlink" title="追加写入数据"></a>追加写入数据</h1><p><strong>要素</strong></p><ul><li>写入数据前：根据预合并字段ts对待写入的数据进行去重，相同主键仅保留ts值最大的那条记录</li><li>写入数据时：无论新记录的ts值是否大于历史记录的ts值，都会覆盖写，直接更新旧数据</li><li>mode为append</li></ul><p><strong>Demo2.object</strong></p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> hudi</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> hudi.spark.implicits._</span><br><span class="line"><span class="keyword">import</span> org.apache.hudi.<span class="type">DataSourceWriteOptions</span>.&#123;<span class="type">PARTITIONPATH_FIELD</span>, <span class="type">PRECOMBINE_FIELD</span>, <span class="type">RECORDKEY_FIELD</span>&#125;</span><br><span class="line"><span class="keyword">import</span> org.apache.hudi.<span class="type">QuickstartUtils</span>.getQuickstartWriteConfigs</span><br><span class="line"><span class="keyword">import</span> org.apache.hudi.config.<span class="type">HoodieWriteConfig</span>.<span class="type">TBL_NAME</span></span><br><span class="line"><span class="keyword">import</span> <span class="type">Demo1</span>.run</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * @author Super小飞象 2023/6/16</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">Demo2</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// TODO 追加插入数据</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">task</span></span>(): <span class="type">Unit</span> = &#123;</span><br><span class="line">    run()</span><br><span class="line">    <span class="comment">// 制造提交时间的差额</span></span><br><span class="line">    <span class="type">Thread</span>.sleep(<span class="number">3000</span>)</span><br><span class="line">    <span class="type">Seq</span>(</span><br><span class="line">      (<span class="number">1</span>, <span class="string">&quot;zs&quot;</span>, <span class="string">&quot;csc&quot;</span>, <span class="string">&quot;sup&quot;</span>, <span class="string">&quot;20230616093642&quot;</span>, <span class="number">2</span>),</span><br><span class="line">      (<span class="number">1</span>, <span class="string">&quot;zs&quot;</span>, <span class="string">&quot;csc&quot;</span>, <span class="string">&quot;sup&quot;</span>, <span class="string">&quot;20230616093643&quot;</span>, <span class="number">3</span>),</span><br><span class="line">      (<span class="number">4</span>, <span class="string">&quot;dq&quot;</span>, <span class="string">&quot;zm&quot;</span>, <span class="string">&quot;dmg&quot;</span>, <span class="string">&quot;20230616093650&quot;</span>, <span class="number">1</span>)</span><br><span class="line">    )</span><br><span class="line">      .toDF(<span class="string">&quot;uuid&quot;</span>, <span class="string">&quot;name&quot;</span>, <span class="string">&quot;city&quot;</span>, <span class="string">&quot;team&quot;</span>, <span class="string">&quot;ts&quot;</span>, <span class="string">&quot;num&quot;</span>)</span><br><span class="line">      .write</span><br><span class="line">      .format(<span class="string">&quot;hudi&quot;</span>)</span><br><span class="line">      <span class="comment">// 追加模式</span></span><br><span class="line">      .mode(<span class="string">&quot;append&quot;</span>)</span><br><span class="line">      .options(getQuickstartWriteConfigs)</span><br><span class="line">      .option(<span class="type">RECORDKEY_FIELD</span>.key(), <span class="string">&quot;uuid,name&quot;</span>)</span><br><span class="line">      .option(<span class="type">PRECOMBINE_FIELD</span>.key(), <span class="string">&quot;ts&quot;</span>)</span><br><span class="line">      .option(<span class="type">PARTITIONPATH_FIELD</span>.key(), <span class="string">&quot;city,team&quot;</span>)</span><br><span class="line">      .option(<span class="type">TBL_NAME</span>.key(), <span class="string">&quot;hudi_demo&quot;</span>)</span><br><span class="line">      .save(<span class="string">&quot;hdfs://node:8020/user/hive/warehouse/hudi_demo&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 查询数据</span></span><br><span class="line">    spark.read.format(<span class="string">&quot;hudi&quot;</span>).load(<span class="string">&quot;hdfs://node:8020/user/hive/warehouse/hudi_demo&quot;</span>).show</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    task()</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>结果</strong></p><p><img src="https://flyohh.cloud/blog_img/2023/06/16/648c515d40864.png" alt="Demo2"></p><h1 id="查询数据"><a href="#查询数据" class="headerlink" title="查询数据"></a>查询数据</h1><p><strong>要素</strong></p><ol><li>增量查询<ul><li>指定QUERY_TYPE为QUERY_TYPE_INCREMENTAL_OPT_VAL</li><li>设置开始时间和结束时间(结束时间不强制)</li><li>增量查询规则：开始时间 &lt; 会被查询出来的数据的<code>_hoodie_commit_time</code> &lt; 结束时间</li><li>结束时间可以不设置，不设置时则 开始时间 &lt; 会被查询出来的数据的<code>_hoodie_commit_time</code></li></ul></li><li>时间旅行查询<ul><li>Hudi有一个时间轴(timeline)的概念，时间旅行则是来到时间轴的某个时间节点，查询该时间节点的数据</li><li>指定时间旅行的时间，支持三种格式<ul><li>yyyyMMddHHmmssSSS</li><li>yyyy-MM-dd HH:mm:ss.SSS</li><li>yyyy-MM-dd(等同于yyyy-MM-dd 00:00:00.000)</li></ul></li></ul></li></ol><p><strong>Demo3.object</strong></p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> hudi</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hudi.<span class="type">DataSourceReadOptions</span>.&#123;<span class="type">BEGIN_INSTANTTIME</span>, <span class="type">END_INSTANTTIME</span>, <span class="type">QUERY_TYPE</span>, <span class="type">QUERY_TYPE_INCREMENTAL_OPT_VAL</span>, <span class="type">TIME_TRAVEL_AS_OF_INSTANT</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * @author Super小飞象 2023/6/16</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">Demo3</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="comment">// 普通查询</span></span><br><span class="line">    spark.read.format(<span class="string">&quot;hudi&quot;</span>)</span><br><span class="line">      .load(<span class="string">&quot;hdfs://node:8020/user/hive/warehouse/hudi_demo&quot;</span>)</span><br><span class="line">      .orderBy(<span class="string">&quot;_hoodie_commit_time&quot;</span>)</span><br><span class="line">      .show</span><br><span class="line"></span><br><span class="line">    <span class="comment">// TODO 增量查询</span></span><br><span class="line">    <span class="comment">//  感觉就是加一条where语句过滤数据</span></span><br><span class="line">    <span class="comment">//  增量查询规则：begin_time &lt; 会被查询出来的数据的`_hoodie_commit_time` &lt; end_time</span></span><br><span class="line">    spark.read.format(<span class="string">&quot;hudi&quot;</span>)</span><br><span class="line">      <span class="comment">// 指定增量查询</span></span><br><span class="line">      .option(<span class="type">QUERY_TYPE</span>.key(), <span class="type">QUERY_TYPE_INCREMENTAL_OPT_VAL</span>)</span><br><span class="line">      <span class="comment">// 指定开始和结束时间</span></span><br><span class="line">      <span class="comment">// 结束时间可以不设置，不设置时则 begin_time &lt; 会被查询出来的数据的`_hoodie_commit_time`</span></span><br><span class="line">      .option(<span class="type">BEGIN_INSTANTTIME</span>.key(), <span class="string">&quot;20230616200308696&quot;</span>)</span><br><span class="line">      .option(<span class="type">END_INSTANTTIME</span>.key(), <span class="string">&quot;20230616200320430&quot;</span>)</span><br><span class="line">      .load(<span class="string">&quot;hdfs://node:8020/user/hive/warehouse/hudi_demo&quot;</span>)</span><br><span class="line">      .orderBy(<span class="string">&quot;_hoodie_commit_time&quot;</span>)</span><br><span class="line">      .show</span><br><span class="line">    <span class="comment">// 在数据中有 20230616200308696、20230616200320429 两个提交时间</span></span><br><span class="line">    <span class="comment">// 在查询中 begin_time=20230616200308696，end_time=20230616200320430</span></span><br><span class="line">    <span class="comment">// 满足 begin_time &lt; 会被查询出来的数据的`_hoodie_commit_time` &lt; end_time 的只有 20230616200320429 这个提交时间</span></span><br><span class="line">    <span class="comment">// 则 _hoodie_commit_time=20230616200320429 的数据被查询出来</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">// TODO 时间旅行查询</span></span><br><span class="line">    <span class="comment">//  Hudi有一个时间轴(timeline)的概念，时间旅行则是来到时间轴的某个时间节点，查询该时间节点的数据</span></span><br><span class="line">    <span class="comment">//  如 20230616200308696 时插入了数据， 20230616200308696 时更新了数据，如果想要查询到更新之前的数据就要使用时间旅行查询了</span></span><br><span class="line">    spark.read.format(<span class="string">&quot;hudi&quot;</span>)</span><br><span class="line">      <span class="comment">// 指定时间旅行的时间，支持三种格式：yyyyMMddHHmmssSSS、yyyy-MM-dd HH:mm:ss.SSS、yyyy-MM-dd(等同于yyyy-MM-dd 00:00:00.000)</span></span><br><span class="line">      <span class="comment">// TIME_TRAVEL_AS_OF_INSTANT = as.of.instant</span></span><br><span class="line">      <span class="comment">// TIME时间 TRAVEL穿越/旅行 AS_OF_INSTANT即时状态</span></span><br><span class="line">      .option(<span class="type">TIME_TRAVEL_AS_OF_INSTANT</span>.key(), <span class="string">&quot;20230616200320428&quot;</span>)</span><br><span class="line">      .load(<span class="string">&quot;hdfs://node:8020/user/hive/warehouse/hudi_demo&quot;</span>)</span><br><span class="line">      .show</span><br><span class="line">    <span class="comment">// 在数据中，20230616200308696 时插入了数据， 20230616200320429 时更新了数据</span></span><br><span class="line">    <span class="comment">// 此时我指定时间旅行的时间戳为 20230616200320428</span></span><br><span class="line">    <span class="comment">// 我穿越到了 20230616200320428 这个时刻，此时已经插入了第一次的数据，离更新数据(20230616200320429)还差一秒钟，下一秒才会更新数据</span></span><br><span class="line">    <span class="comment">// 此时插入了数据，还没有更新数据</span></span><br><span class="line">    <span class="comment">// 则，查询结果会查询出第一次插入的没有被更新的数据</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>结果</strong></p><p><img src="https://flyohh.cloud/blog_img/2023/06/16/648c56632e4db.png" alt="Demo3"></p><h1 id="覆盖数据"><a href="#覆盖数据" class="headerlink" title="覆盖数据"></a>覆盖数据</h1><p><strong>要素</strong></p><ul><li>可以用于某些操作任务，如修复指定的问题分区</li><li>mode还是append，增删改都是用append，没错删也是</li><li>指定OPERATION为 insert_overwrite 模式</li></ul><p><strong>Demo4.object</strong></p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> hudi</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> hudi.<span class="type">Demo1</span>.run</span><br><span class="line"><span class="keyword">import</span> hudi.spark.implicits._</span><br><span class="line"><span class="keyword">import</span> org.apache.hudi.<span class="type">DataSourceWriteOptions</span>.&#123;<span class="type">INSERT_OVERWRITE_OPERATION_OPT_VAL</span>, <span class="type">OPERATION</span>, <span class="type">PARTITIONPATH_FIELD</span>, <span class="type">PRECOMBINE_FIELD</span>, <span class="type">RECORDKEY_FIELD</span>&#125;</span><br><span class="line"><span class="keyword">import</span> org.apache.hudi.<span class="type">QuickstartUtils</span>.getQuickstartWriteConfigs</span><br><span class="line"><span class="keyword">import</span> org.apache.hudi.config.<span class="type">HoodieWriteConfig</span>.<span class="type">TBL_NAME</span></span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * @author Super小飞象 2023/6/16</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">Demo4</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// TODO 覆盖数据</span></span><br><span class="line">  <span class="comment">//  忽略现有的分区内数据，直接覆盖，例：待写入的数据中某行数据分区值为 csc/sup 那么该分区内所有数据都将被覆盖</span></span><br><span class="line">  <span class="comment">//  可以用于某些操作任务，如修复指定的问题分区。</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    run()</span><br><span class="line"></span><br><span class="line">    <span class="type">Seq</span>(</span><br><span class="line">      (<span class="number">11</span>, <span class="string">&quot;zss&quot;</span>, <span class="string">&quot;csc&quot;</span>, <span class="string">&quot;sup&quot;</span>, <span class="string">&quot;20230616093642&quot;</span>, <span class="number">2</span>),</span><br><span class="line">      (<span class="number">22</span>, <span class="string">&quot;lss&quot;</span>, <span class="string">&quot;csc&quot;</span>, <span class="string">&quot;sup&quot;</span>, <span class="string">&quot;20230616093642&quot;</span>, <span class="number">2</span>),</span><br><span class="line">      (<span class="number">22</span>, <span class="string">&quot;lss&quot;</span>, <span class="string">&quot;cdc&quot;</span>, <span class="string">&quot;cdc&quot;</span>, <span class="string">&quot;20230616093642&quot;</span>, <span class="number">2</span>)</span><br><span class="line">    )</span><br><span class="line">      .toDF(<span class="string">&quot;uuid&quot;</span>, <span class="string">&quot;name&quot;</span>, <span class="string">&quot;city&quot;</span>, <span class="string">&quot;team&quot;</span>, <span class="string">&quot;ts&quot;</span>, <span class="string">&quot;num&quot;</span>)</span><br><span class="line">      .write</span><br><span class="line">      .format(<span class="string">&quot;hudi&quot;</span>)</span><br><span class="line">      .mode(<span class="string">&quot;append&quot;</span>)</span><br><span class="line">      .options(getQuickstartWriteConfigs)</span><br><span class="line">      .option(<span class="type">RECORDKEY_FIELD</span>.key(), <span class="string">&quot;uuid,name&quot;</span>)</span><br><span class="line">      .option(<span class="type">PRECOMBINE_FIELD</span>.key(), <span class="string">&quot;ts&quot;</span>)</span><br><span class="line">      .option(<span class="type">PARTITIONPATH_FIELD</span>.key(), <span class="string">&quot;city,team&quot;</span>)</span><br><span class="line">      <span class="comment">// 指定为 insert_overwrite 模式</span></span><br><span class="line">      .option(<span class="type">OPERATION</span>.key(), <span class="type">INSERT_OVERWRITE_OPERATION_OPT_VAL</span>)</span><br><span class="line">      .option(<span class="type">TBL_NAME</span>.key(), <span class="string">&quot;hudi_demo&quot;</span>)</span><br><span class="line">      .save(<span class="string">&quot;hdfs://node:8020/user/hive/warehouse/hudi_demo&quot;</span>)</span><br><span class="line"></span><br><span class="line">    spark.read.format(<span class="string">&quot;hudi&quot;</span>).load(<span class="string">&quot;hdfs://node:8020/user/hive/warehouse/hudi_demo&quot;</span>).show</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>结果</strong></p><p><img src="https://flyohh.cloud/blog_img/2023/06/16/648c59617688a.png" alt="Demo4"></p><h1 id="删除数据"><a href="#删除数据" class="headerlink" title="删除数据"></a>删除数据</h1><p><strong>要素</strong></p><ul><li>将要删除的数据查询出来然后以<code>删除模式</code>写入</li><li>指定OPERATION为delete</li></ul><p><strong>Demo5.object</strong></p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> hudi</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> hudi.<span class="type">Demo1</span>.run</span><br><span class="line"><span class="keyword">import</span> org.apache.hudi.<span class="type">DataSourceWriteOptions</span>._</span><br><span class="line"><span class="keyword">import</span> org.apache.hudi.<span class="type">QuickstartUtils</span>.getQuickstartWriteConfigs</span><br><span class="line"><span class="keyword">import</span> org.apache.hudi.config.<span class="type">HoodieWriteConfig</span>.<span class="type">TBL_NAME</span></span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * @author Super小飞象 2023/6/16</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">Demo5</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// TODO 删除数据</span></span><br><span class="line">  <span class="comment">//  将要删除的数据查询出来然后以`删除模式`写入</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    run()</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 查询数据</span></span><br><span class="line">    spark.read.format(<span class="string">&quot;hudi&quot;</span>)</span><br><span class="line">      .load(<span class="string">&quot;hdfs://node:8020/user/hive/warehouse/hudi_demo&quot;</span>)</span><br><span class="line">      <span class="comment">// 比如我想删除 team=sup 的数据</span></span><br><span class="line">      .where(<span class="string">&quot;team = &#x27;sup&#x27;&quot;</span>)</span><br><span class="line">      .write</span><br><span class="line">      .format(<span class="string">&quot;hudi&quot;</span>)</span><br><span class="line">      .mode(<span class="string">&quot;append&quot;</span>)</span><br><span class="line">      .options(getQuickstartWriteConfigs)</span><br><span class="line">      .option(<span class="type">RECORDKEY_FIELD</span>.key(), <span class="string">&quot;uuid,name&quot;</span>)</span><br><span class="line">      .option(<span class="type">PRECOMBINE_FIELD</span>.key(), <span class="string">&quot;ts&quot;</span>)</span><br><span class="line">      .option(<span class="type">PARTITIONPATH_FIELD</span>.key(), <span class="string">&quot;city,team&quot;</span>)</span><br><span class="line">      <span class="comment">// 指定为 delete 模式</span></span><br><span class="line">      .option(<span class="type">OPERATION</span>.key(), <span class="type">DELETE_OPERATION_OPT_VAL</span>)</span><br><span class="line">      .option(<span class="type">TBL_NAME</span>.key(), <span class="string">&quot;hudi_demo&quot;</span>)</span><br><span class="line">      .save(<span class="string">&quot;hdfs://node:8020/user/hive/warehouse/hudi_demo&quot;</span>)</span><br><span class="line"></span><br><span class="line">    spark.read.format(<span class="string">&quot;hudi&quot;</span>).load(<span class="string">&quot;hdfs://node:8020/user/hive/warehouse/hudi_demo&quot;</span>).show</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>结果</strong></p><p><img src="https://flyohh.cloud/blog_img/2023/06/16/648c5b8a784b8.png" alt="Demo5"></p>]]></content>
      
      
      <categories>
          
          <category> 学习文档 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 大数据 </tag>
            
            <tag> Spark </tag>
            
            <tag> Hudi </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>国赛样题-离线部分整合版</title>
      <link href="/2023/06/09/%E5%9B%BD%E8%B5%9B%E6%A0%B7%E9%A2%98-%E7%A6%BB%E7%BA%BF%E9%83%A8%E5%88%86%E6%95%B4%E5%90%88%E7%89%88/"/>
      <url>/2023/06/09/%E5%9B%BD%E8%B5%9B%E6%A0%B7%E9%A2%98-%E7%A6%BB%E7%BA%BF%E9%83%A8%E5%88%86%E6%95%B4%E5%90%88%E7%89%88/</url>
      
        <content type="html"><![CDATA[<h1 id="工业数据"><a href="#工业数据" class="headerlink" title="工业数据"></a>工业数据</h1><h2 id="子任务一：数据抽取"><a href="#子任务一：数据抽取" class="headerlink" title="子任务一：数据抽取"></a>子任务一：数据抽取</h2><p>抽取MySQL的表的全量数据进入Hudi中，字段排序、类型不变，分区字段为etldate，类型为String，且值为当前比赛日的前一天日期（分区字段格式为yyyyMMdd）</p><ol><li><p>抽取 shtd_industry.EnvironmentData 进入 hudi_gy_ods.environmentdata</p><p>PRECOMBINE_FIELD使用 InPutTime，EnvoId 作为主键</p><p>使用spark-sql的cli执行 show partitions hudi_gy_ods.environmentdata; 命令，将结果截图粘贴至【任务B提交结果.docx】中对应的任务序号下；</p></li><li><p>抽取 shtd_industry.ChangeRecord 进入 hudi_gy_ods.changerecord</p><p>PRECOMBINE_FIELD使用 ChangeEndTime，ChangeID 和 ChangeMachineID 作为联合主键</p><p>使用spark-sql的cli执行 select count(1) from hudi_gy_ods.changerecord; 命令，将cli的执行结果分别截图粘贴至【任务B提交结果.docx】中对应的任务序号下；</p></li><li><p>抽取 shtd_industry.BaseMachine 进入 hudi_gy_ods.basemachine</p><p>PRECOMBINE_FIELD使用 MachineAddDate，BaseMachineID 为主键</p><p>使用spark-sql的cli执行 show partitions hudi_gy_ods.basemachine; 命令，将spark-sql的cli的执行结果分别截图粘贴至【任务B提交结果.docx】中对应的任务序号下；</p></li><li><p>抽取 shtd_industry.ProduceRecord 进入 hudi_gy_ods.producerecord，剔除 ProducePrgCode 字段</p><p>PRECOMBINE_FIELD使用 ProduceCodeEndTime，ProduceRecordID 和 ProduceMachineID 为联合主键</p><p>使用spark-sql的cli执行 show partitions hudi_gy_ods.producerecord; 命令，将spark-sql的cli的执行结果分别截图粘贴至【任务B提交结果.docx】中对应的任务序号下；</p></li><li><p>抽取 shtd_industry.MachineData 进入 hudi_gy_ods.machinedata</p><p>PRECOMBINE_FIELD使用 MachineRecordDate，MachineRecordID 为主键</p><p>使用spark-sql的cli执行 show partitions hudi_gy_ods.machinedata; 命令，将cli的执行结果分别截图粘贴至【任务B提交结果.docx】中对应的任务序号下。</p></li></ol><h2 id="子任务二：数据清洗"><a href="#子任务二：数据清洗" class="headerlink" title="子任务二：数据清洗"></a>子任务二：数据清洗</h2><p>抽取 hudi_gy_ods 库的全量数据进入 hudi_gy_dwd 库中，分区字段为etldate且值与 hudi_gy_ods  库的相对应表该值相等，并添加dwd_insert_user、dwd_insert_time、dwd_modify_user、dwd_modify_time四列,其中dwd_insert_user、dwd_modify_user均填写“user1”，dwd_insert_time、dwd_modify_time均填写当前操作时间，并进行数据类型转换。</p><ol><li><p>抽取 hudi_gy_ods.environmentdata 进入 hudi_gy_dwd.fact_environment_data</p><p>PRECOMBINE_FIELD使用 InPutTime，EnvoId 作为主键</p><p>使用spark-sql的cli按照 envoid 降序排序，查询前5条数据，将结果截图粘贴至【任务B提交结果.docx】中对应的任务序号下；</p></li><li><p>抽取 hudi_gy_ods.changerecord进入 hudi_gy_dwd.fact_change_record</p><p>PRECOMBINE_FIELD使用 ChangeEndTime，ChangeID 和 ChangeMachineID 作为联合主键</p><p>使用spark-sql的cli按照 changemachineid 降序排序，查询前1条数据，将结果截图粘贴至【任务B提交结果.docx】中对应的任务序号下；</p></li><li><p>抽取 hudi_gy_ods.basemachine进入 hudi_gy_dwd.dim_machine</p><p>PRECOMBINE_FIELD使用 MachineAddDate，BaseMachineID 为主键</p><p>使用spark-sql的cli按照 basemachineid 升序排序，查询 dim_machine 前2条数据，将结果截图粘贴至【任务B提交结果.docx】中对应的任务序号下；</p></li><li><p>抽取 hudi_gy_ods.producerecord进入 hudi_gy_dwd.fact_produce_record</p><p>PRECOMBINE_FIELD使用 ProduceCodeEndTime，ProduceRecordID 和 ProduceMachineID 为联合主键</p><p>使用spark-sql的cli按照 producemachineid 升序排序，查询 fact_produce_record 前2条数据，将结果截图粘贴至【任务B提交结果.docx】中对应的任务序号下；</p></li><li><p>抽取 hudi_gy_ods.machinedata进入 hudi_gy_dwd.fact_machine_data</p><p>PRECOMBINE_FIELD使用 MachineRecordDate，MachineRecordID 为主键</p><p>使用spark-sql的cli按照 machineid 降序排序，查询 fact_machine_data 前1条数据，将结果截图粘贴至【任务B提交结果.docx】中对应的任务序号下；</p></li></ol><h2 id="子任务三：指标计算"><a href="#子任务三：指标计算" class="headerlink" title="子任务三：指标计算"></a>子任务三：指标计算</h2><h3 id="第一题"><a href="#第一题" class="headerlink" title="第一题"></a>第一题</h3><p>本任务基于2、3、4小题完成，使用 <strong>Azkaban</strong> 完成第2、3、4题任务代码的调度。工作流要求，使用shell输出“开始”作为工作流的第一个job（job1），2、3、4题任务为并行任务且它们依赖job1的完成（命名为job2、job3、job4），job2、job3、job4完成之后使用shell输出“结束”作为工作流的最后一个job（endjob），endjob依赖job2、job3、job4</p><p>将最终任务调度完成后的工作流截图，将截图粘贴至【任务B提交结果.docx】中对应的任务序号下；</p><h3 id="第二题"><a href="#第二题" class="headerlink" title="第二题"></a>第二题</h3><p>根据 hudi_gy_dwd.fact_environment_data 表，统计检测设备（BaseID）每月的平均湿度（Humidity），然后将每个设备的每月平均湿度与厂内所有检测设备每月检测结果的平均湿度做比较</p><p>将计算结果存入MySQL的 shtd_result.machine_humidityAVG_compare 表中</p><p>在MySQL命令行中根据检测设备ID降序排序，查询出前5条，将SQL语句复制粘贴至【任务B提交结果.docx】中对应的任务序号下，将执行结果截图粘贴至【任务B提交结果.docx】中对应的任务序号下；</p><p><strong>shtd_result.machine_humidityAVG_compare</strong></p><table><thead><tr><th align="center">字段</th><th align="center">类型</th><th align="center">中文含义</th><th align="center">备注</th></tr></thead><tbody><tr><td align="center">base_id</td><td align="center">int</td><td align="center">检测设备ID</td><td align="center"></td></tr><tr><td align="center">machine_avg</td><td align="center">varchar</td><td align="center">单设备检测平均值</td><td align="center"></td></tr><tr><td align="center">factory_avg</td><td align="center">varchar</td><td align="center">厂内所有设备平均值</td><td align="center"></td></tr><tr><td align="center">comparison</td><td align="center">varchar</td><td align="center">比较结果</td><td align="center">高&#x2F;低&#x2F;相同</td></tr><tr><td align="center">env_date_year</td><td align="center">varchar</td><td align="center">检测年份</td><td align="center">如：2021</td></tr><tr><td align="center">env_date_month</td><td align="center">varchar</td><td align="center">检测月份</td><td align="center">如：12</td></tr></tbody></table><h3 id="第三题"><a href="#第三题" class="headerlink" title="第三题"></a>第三题</h3><p>根据 hudi_gy_dwd.fact_environment_data 表，统计检测设备（BaseID）每月的（PM10）的检测平均浓度，然后将每个设备的每月平均浓度与厂内所有检测设备每月检测结果的平均浓度做比较</p><p>将计算结果存入MySQL的 shtd_result.machine_PM10AVG_compare 表中</p><p>在MySQL命令行中根据检测设备ID降序排序，查询出前5条，将SQL语句复制粘贴至【任务B提交结果.docx】中对应的任务序号下，将执行结果截图粘贴至【任务B提交结果.docx】中对应的任务序号下；</p><p><strong>shtd_result.machine_PM10AVG_compare</strong></p><table><thead><tr><th align="center">字段</th><th align="center">类型</th><th align="center">中文含义</th><th align="center">备注</th></tr></thead><tbody><tr><td align="center">base_id</td><td align="center">int</td><td align="center">检测设备ID</td><td align="center"></td></tr><tr><td align="center">machine_avg</td><td align="center">varchar</td><td align="center">单设备检测平均值</td><td align="center"></td></tr><tr><td align="center">factory_avg</td><td align="center">varchar</td><td align="center">厂内所有设备平均值</td><td align="center"></td></tr><tr><td align="center">comparison</td><td align="center">varchar</td><td align="center">比较结果</td><td align="center">高&#x2F;低&#x2F;相同</td></tr><tr><td align="center">env_date_year</td><td align="center">varchar</td><td align="center">检测年份</td><td align="center">如：2021</td></tr><tr><td align="center">env_date_month</td><td align="center">varchar</td><td align="center">检测月份</td><td align="center">如：12</td></tr></tbody></table><h3 id="第四题"><a href="#第四题" class="headerlink" title="第四题"></a>第四题</h3><p>根据 hudi_gy_dwd.fact_change_record 表，统计每个月（changestarttime）、每个设备、每种状态的时长，若某状态当前未结束（即 changeendtime 值为空）则该状态不参与计算</p><p>将计算结果存入MySQL的 shtd_result.machine_state_time 表中</p><p>在MySQL命令行中根据设备id、状态持续时长均为降序排序，查询出前10条，将SQL语句复制粘贴至【任务B提交结果.docx】中对应的任务序号下，将执行结果截图粘贴至【任务B提交结果.docx】中对应的任务序号下；</p><p><strong>shtd_result.machine_state_time</strong></p><table><thead><tr><th align="center">字段</th><th align="center">类型</th><th align="center">中文含义</th><th align="center">备注</th></tr></thead><tbody><tr><td align="center">machine_id</td><td align="center">int</td><td align="center">设备id</td><td align="center"></td></tr><tr><td align="center">change_record_state</td><td align="center">varchar</td><td align="center">状态</td><td align="center"></td></tr><tr><td align="center">duration_time</td><td align="center">varchar</td><td align="center">持续时长（秒）</td><td align="center">当月该状态的时长和</td></tr><tr><td align="center">year</td><td align="center">int</td><td align="center">年</td><td align="center">状态产生的年</td></tr><tr><td align="center">month</td><td align="center">int</td><td align="center">月</td><td align="center">状态产生的月</td></tr></tbody></table><h3 id="第五题"><a href="#第五题" class="headerlink" title="第五题"></a>第五题</h3><p>根据 hudi_gy_dwd.fact_machine_data 表统计出每日每台设备，状态为“运行”的时长（若运行无结束时间，则需根据时间判断这个设备的运行状态的下一个状态是哪条数据，将下一个状态的数据的时间置为这个设备运行状态的结束时间，如果设备数据的运行状态不存在下一个状态，则该设备这个阶段数据的运行状态不参与计算，即该设备的这个阶段数据的运行状态时长按0计算）</p><p>将结果数据写入 hudi_gy_dws.machine_data_total_time 中</p><p>使用spark-sql的cli根据 machine_id 降序和 machine_record_date 升序排序查询 hudi_gy_dws.machine_data_total_time 表的 machine_id、machine_record_date、total_time 的前5条数据，将SQL语句复制粘贴至【任务B提交结果.docx】中对应的任务序号下，将执行结果截图粘贴至【任务B提交结果.docx】中对应的任务序号下；</p><p><strong>hudi_gy_dws.machine_data_total_time</strong></p><table><thead><tr><th align="center">字段</th><th align="center">类型</th><th align="center">中文含义</th><th align="center">备注</th></tr></thead><tbody><tr><td align="center">machine_id</td><td align="center">int</td><td align="center">设备id</td><td align="center">recordkey</td></tr><tr><td align="center">machine_record_date</td><td align="center">string</td><td align="center">状态日期</td><td align="center">partition，如：2021-10-01</td></tr><tr><td align="center">total_time</td><td align="center">int</td><td align="center">一天运行总时长</td><td align="center">combinekey，秒</td></tr></tbody></table><h3 id="第六题"><a href="#第六题" class="headerlink" title="第六题"></a>第六题</h3><p>根据 hudi_gy_dws.machine_data_total_time，计算每日运行时长前三的设备（若存在运行时长相同的数据时应全部输出，例如有两条并列第二，则第三名次不变，总共输出四条数据）</p><p>将计算结果写入ClickHouse数据库 shtd_result.machine_data_total_time_top3 </p><p>在ClickHouse命令行中根据查询所有数据，将SQL语句复制粘贴至【任务B提交结果.docx】中对应的任务序号下，将执行结果截图粘贴至【任务B提交结果.docx】中对应的任务序号下；</p><p><strong>shtd_result.machine_data_total_time_top3</strong></p><table><thead><tr><th align="center">字段</th><th align="center">类型</th><th align="center">中文含义</th><th align="center">备注</th></tr></thead><tbody><tr><td align="center">date_day</td><td align="center">varchar</td><td align="center">日期</td><td align="center">如：2021-10-01</td></tr><tr><td align="center">first_id</td><td align="center">int</td><td align="center">第一</td><td align="center">一天运行总时长第一</td></tr><tr><td align="center">second_id</td><td align="center">int</td><td align="center">第二</td><td align="center">一天运行总时长第二</td></tr><tr><td align="center">tertiary_id</td><td align="center">int</td><td align="center">第三</td><td align="center">一天运行总时长第二</td></tr><tr><td align="center">first_time</td><td align="center">int</td><td align="center">第一的时长</td><td align="center">秒</td></tr><tr><td align="center">second_time</td><td align="center">int</td><td align="center">第二的时长</td><td align="center">秒</td></tr><tr><td align="center">tertiary_time</td><td align="center">int</td><td align="center">第三的时长</td><td align="center">秒</td></tr></tbody></table><h3 id="第七题"><a href="#第七题" class="headerlink" title="第七题"></a>第七题</h3><p>根据 hudi_gy_dwd.fact_produce_record 表，基于全量历史数据计算各设备生产一个产品的平均耗时，producecodeendtime 值为 1900-01-01 00:00:00 的数据为脏数据，需要剔除，并以 producerecordid 和ProduceMachineID 为联合主键进行去重（注：fact_produce_record表中，一条数据代表加工一个产品，  producecodestarttime 字段为开始加工时间，producecodeendtime 字段为完成加工时间），将设备每个产品的耗时与该设备平均耗时作比较，保留耗时高于平均值的产品数据</p><p>将计算结果以Hive的方式写入 hudi_gy_dws.machine_produce_per_avgtime</p><p>使用spark-sql的cli根据设备id降序排序查询前3条数据，将SQL语句复制粘贴至客【任务B提交结果.docx】中对应的任务序号下，将执行结果截图粘贴至【任务B提交结果.docx】中对应的任务序号下；</p><p><strong>hudi_gy_dws.machine_produce_per_avgtime</strong></p><table><thead><tr><th align="center">字段</th><th align="center">类型</th><th align="center">中文含义</th><th align="center">备注</th></tr></thead><tbody><tr><td align="center">produce_record_id</td><td align="center">int</td><td align="center">生产记录id</td><td align="center">每生产一件产品产生一条数据</td></tr><tr><td align="center">produce_machine_id</td><td align="center">int</td><td align="center">设备id</td><td align="center"></td></tr><tr><td align="center">producetime</td><td align="center">int</td><td align="center">该产品耗时</td><td align="center"></td></tr><tr><td align="center">produce_per_avgtime</td><td align="center">int</td><td align="center">设备生产一个产品平均耗时</td><td align="center">单位：秒</td></tr></tbody></table><h3 id="第八题"><a href="#第八题" class="headerlink" title="第八题"></a>第八题</h3><p>根据 hudi_gy_dws.machine_produce_per_avgtime 表，获取各设备生产耗时最长的两个产品的用时</p><p>将计算结果存入MySQL的 shtd_industry.machine_produce_timetop2 表中</p><p>在MySQL命令行中根据设备id降序排序，查询出前2条，将SQL语句复制粘贴至【任务B提交结果.docx】中对应的任务序号下，将执行结果截图粘贴至【任务B提交结果.docx】中对应的任务序号下；</p><p><strong>shtd_result.machine_produce_timetop2</strong></p><table><thead><tr><th align="center">字段</th><th align="center">类型</th><th align="center">中文含义</th></tr></thead><tbody><tr><td align="center">machine_id</td><td align="center">int</td><td align="center">设备id</td></tr><tr><td align="center">first_time</td><td align="center">int</td><td align="center">耗时最长</td></tr><tr><td align="center">second_time</td><td align="center">int</td><td align="center">耗时次长</td></tr></tbody></table><h3 id="第九题"><a href="#第九题" class="headerlink" title="第九题"></a>第九题</h3><p>根据 hudi_gy_dwd.fact_change_record 表关联 dim_machine 表，统计每个车间中所有设备运行时长（即设备状态为“运行”）的中位数在哪个设备（为偶数时，两条数据原样保留输出），若某个设备运行状态当前未结束（即changeendtime值为空）则该状态不参与计算</p><p>将计算结果存入MySQL的 shtd_result.machine_running_median 表中</p><p>在MySQL命令行中根据所属车间、设备id均为降序排序，查询出前5条数据，将SQL语句复制粘贴至【任务B提交结果.docx】中对应的任务序号下，将执行结果截图粘贴至【任务B提交结果.docx】中对应的任务序号下；</p><p><strong>shtd_result.machine_running_median</strong></p><table><thead><tr><th align="center">字段</th><th align="center">类型</th><th align="center">中文含义</th><th align="center">备注</th></tr></thead><tbody><tr><td align="center">machine_id</td><td align="center">int</td><td align="center">设备id</td><td align="center"></td></tr><tr><td align="center">machine_factory</td><td align="center">int</td><td align="center">所属车间</td><td align="center"></td></tr><tr><td align="center">total_running_time</td><td align="center">int</td><td align="center">运行总时长</td><td align="center">结果以秒为单位</td></tr></tbody></table><h3 id="第十题"><a href="#第十题" class="headerlink" title="第十题"></a>第十题</h3><p>根据 hudi_gy_dwd.fact_change_record 表关联 dim_machine 表，计算每个车间设备的月平均运行时长与所有设备的月平均运行时长对比结果（即设备状态为“运行”，结果值为：高&#x2F;低&#x2F;相同），月份取值使用状态开始时间的月份，若某设备的运行状态当前未结束（即changeendtime值为空）则该状态不参与计算</p><p>将计算结果存入MySQL的 shtd_result.machine_running_compare 表中</p><p>在MySQL命令行中根据车间号降序排序，查询出前2条，将SQL语句复制粘贴至【任务B提交结果.docx】中对应的任务序号下，将执行结果截图粘贴至【任务B提交结果.docx】中对应的任务序号下；</p><p><strong>shtd_result.machine_running_compare</strong></p><table><thead><tr><th align="center">字段</th><th align="center">类型</th><th align="center">中文含义</th><th align="center">备注</th></tr></thead><tbody><tr><td align="center">start_month</td><td align="center">varchar</td><td align="center">月份</td><td align="center">如：2021-12</td></tr><tr><td align="center">machine_factory</td><td align="center">int</td><td align="center">车间号</td><td align="center"></td></tr><tr><td align="center">comparison</td><td align="center">varchar</td><td align="center">比较结果</td><td align="center">高&#x2F;低&#x2F;相同</td></tr><tr><td align="center">factory_avg</td><td align="center">varchar</td><td align="center">车间平均时长</td><td align="center"></td></tr><tr><td align="center">company_avg</td><td align="center">varchar</td><td align="center">所有设备平均时长</td><td align="center"></td></tr></tbody></table><h3 id="第十一题"><a href="#第十一题" class="headerlink" title="第十一题"></a>第十一题</h3><p>根据 hudi_gy_dwd.fact_change_record 表，展示每一个设备最近第二次的状态（倒数第二次），时间字段选用changestarttime，如果设备仅有一种状态，返回该状态（一个设备不会同时拥有两种状态）</p><p>将计算结果存入MySQL的 shtd_result.recent_state 表中</p><p>在MySQL命令行中根据设备id降序排序，查询出前5条，将SQL语句复制粘贴至【任务B提交结果.docx】中对应的任务序号下，将执行结果截图粘贴至【任务B提交结果.docx】中对应的任务序号下；</p><p><strong>shtd_result.recent_state</strong></p><table><thead><tr><th align="center">字段</th><th align="center">类型</th><th align="center">中文含义</th><th align="center">备注</th></tr></thead><tbody><tr><td align="center">machine_id</td><td align="center">int</td><td align="center">设备id</td><td align="center"></td></tr><tr><td align="center">record_state</td><td align="center">varchar</td><td align="center">状态信息</td><td align="center">最近第二次的状态</td></tr><tr><td align="center">change_start_time</td><td align="center">varchar</td><td align="center">状态开始时间</td><td align="center"></td></tr><tr><td align="center">change_end_time</td><td align="center">varchar</td><td align="center">状态结束时间</td><td align="center"></td></tr></tbody></table><h1 id="电商数据"><a href="#电商数据" class="headerlink" title="电商数据"></a>电商数据</h1><h2 id="子任务一：数据抽取-1"><a href="#子任务一：数据抽取-1" class="headerlink" title="子任务一：数据抽取"></a>子任务一：数据抽取</h2><p>抽取MySQL的表的增量数据进入Hudi中，字段排序、类型不变，分区字段为etldate，类型为String，且值为当前比赛日的前一天日期（分区字段格式为yyyyMMdd）。</p><ol><li><p>抽取 <strong>shtd_store.user_info</strong> 的增量数据进入 <strong>ods_ds_hudi.user_info</strong> </p><p>根据ods_ds_hudi.user_info表中operate_time或create_time作为增量字段(即MySQL中每条数据取这两个时间中较大的那个时间作为增量字段去和ods里的这两个字段中较大的时间进行比较)，只将新增的数据抽入。若operate_time为空，则用create_time填充。</p><p>id作为primaryKey，operate_time作为preCombineField</p><p>使用spark-shell执行 show partitions ods_ds_hudi.user_info 命令，将结果截图粘贴至【任务B提交结果.docx】中对应的任务序号下；</p></li><li><p>抽取 <strong>shtd_store.sku_info</strong> 的增量数据进入 <strong>ods_ds_hudi.sku_info</strong></p><p>根据ods_ds_hudi.sku_info表中create_time作为增量字段，只将新增的数据抽入。</p><p>id作为primaryKey，create_time作为preCombineField</p><p>使用spark-shell执行 show partitions ods_ds_hudi.sku_info 命令，将结果截图粘贴至【任务B提交结果.docx】中对应的任务序号下；</p></li><li><p>抽取 <strong>shtd_store.base_province</strong> 的增量数据进入 <strong>ods_ds_hudi.base_province</strong></p><p>根据ods_ds_hudi.base_province表中id作为增量字段，只将新增的数据抽入，并添加字段create_time取当前时间</p><p>id作为primaryKey，create_time作为preCombineField</p><p>使用spark-shell执行 show partitions ods_ds_hudi.base_province 命令，将结果截图粘贴至【任务B提交结果.docx】中对应的任务序号下；</p></li><li><p>抽取 <strong>shtd_store.base_region</strong> 的增量数据进入 <strong>ods_ds_hudi.base_region</strong></p><p>根据ods_ds_hudi.base_region表中id作为增量字段，只将新增的数据抽入，并添加字段create_time取当前时间</p><p>id作为primaryKey，create_time作为preCombineField</p><p>使用spark-shell执行 show partitions ods_ds_hudi.base_region 命令，将结果截图粘贴至【任务B提交结果.docx】中对应的任务序号下；</p></li><li><p>抽取 <strong>shtd_store.order_info</strong> 的增量数据进入 <strong>ods_ds_hudi.order_info</strong></p><p>根据 ods_ds_hudi.order_info 表中 operate_time 或 create_time 作为增量字段(即MySQL中每条数据取这两个时间中较大的那个时间作为增量字段去和ods里的这两个字段中较大的时间进行比较)，只将新增的数据抽入。</p><p>id作为primaryKey，operate_time作为preCombineField</p><p>使用spark-shell执行 show partitions ods_ds_hudi.order_info 命令，将结果截图粘贴至【任务B提交结果.docx】中对应的任务序号下；</p></li><li><p>抽取 <strong>shtd_store.order_detail</strong> 的增量数据进入 <strong>ods_ds_hudi.order_detail</strong></p><p>根据ods_ds_hudi.order_detail表中create_time作为增量字段，只将新增的数据抽入。</p><p>id作为primaryKey，create_time作为preCombineField</p><p>使用spark-shell执行 show partitions ods_ds_hudi.order_detail 命令，将结果截图粘贴至【任务B提交结果.docx】中对应的任务序号下；</p></li></ol><h2 id="子任务二：数据清洗-1"><a href="#子任务二：数据清洗-1" class="headerlink" title="子任务二：数据清洗"></a>子任务二：数据清洗</h2><p>抽取 ods_ds_hudi 库的增量数据进入 dwd_ds_hudi 库中，并添加dwd_insert_user、dwd_insert_time、dwd_modify_user、dwd_modify_time四列,其中dwd_insert_user、dwd_modify_user均填写“user1”，dwd_insert_time、dwd_modify_time均填写当前操作时间，并进行数据类型转换。</p><ol><li><p>抽取ods_ds_hudi.user_info表中昨天的分区（子任务一生成的分区）数据，并结合dim_user_info最新分区现有的数据，根据id合并数据到dwd_ds_hudi.dim_user_info的分区表（合并是指对dwd层数据进行插入或修改，需修改的数据以id为合并字段，根据operate_time排序取最新的一条）。若该条记录第一次进入数仓dwd层则dwd_insert_time、dwd_modify_time均存当前操作时间，并进行数据类型转换。若该数据在进入dwd层时发生了合并修改，则dwd_insert_time时间不变，dwd_modify_time存当前操作时间，其余列存最新的值。</p><p>id作为primaryKey，operate_time作为preCombineField。</p><p>使用spark-shell执行 show partitions dwd_ds_hudi.dim_user_info 命令，将结果截图粘贴至【任务B提交结果.docx】中对应的任务序号下；</p></li><li><p>抽取ods_ds_hudi.sku_info表中昨天的分区（子任务一生成的分区）数据，并结合dim_sku_info最新分区现有的数据，根据id合并数据到dwd_ds_hudi库中dim_sku_info的分区表（合并是指对dwd层数据进行插入或修改，需修改的数据以id为合并字段，根据create_time排序取最新的一条）。若该条数据第一次进入数仓dwd层则dwd_insert_time、dwd_modify_time均填写当前操作时间，并进行数据类型转换。若该数据在进入dwd层时发生了合并修改，则dwd_insert_time时间不变，dwd_modify_time存当前操作时间，其余列存最新的值。</p><p>id作为primaryKey，dwd_modify_time作为preCombineField。</p><p>使用spark-shell查询表 dim_sku_info 的字段 id, sku_desc, dwd_insert_user, dwd_modify_time, etl_date，条件为最新分区的数据，id大于等于15且小于等于20，并且按照id升序排序，将结果截图粘贴至【任务B提交结果.docx】中对应的任务序号下；</p></li><li><p>抽取ods_ds_hudi.base_province表中昨天的分区（子任务一生成的分区）数据，并结合dim_province最新分区现有的数据，根据id合并数据到dwd_ds_hudi.dim_province的分区表（合并是指对dwd层数据进行插入或修改，需修改的数据以id为合并字段，根据create_time排序取最新的一条）。若该条数据第一次进入数仓dwd层则dwd_insert_time、dwd_modify_time均填写当前操作时间，并进行数据类型转换。若该数据在进入dwd层时发生了合并修改，则dwd_insert_time时间不变，dwd_modify_time存当前操作时间，其余列存最新的值。</p><p>id作为primaryKey，dwd_modify_time作为preCombineField。</p><p>使用spark-shell在表dwd.dim_province最新分区中，查询该分区中数据的条数，将结果截图粘贴至【任务B提交结果.docx】中对应的任务序号下；</p></li><li><p>抽取ods_ds_hudi.base_region表中昨天的分区（子任务一生成的分区）数据，并结合dim_region最新分区现有的数据，根据 id 合并数据到dwd_ds_hudi库中 dim_region 的分区表（合并是指对dwd层数据进行插入或修改，需修改的数据以id为合并字段，根据create_time排序取最新的一条）。若该条数据第一次进入数仓dwd层则dwd_insert_time、dwd_modify_time均填写当前操作时间，并进行数据类型转换。若该数据在进入dwd层时发生了合并修改，则dwd_insert_time时间不变，dwd_modify_time存当前操作时间，其余列存最新的值。</p><p>id作为primaryKey，dwd_modify_time作为preCombineField。</p><p>使用spark-shell在表dwd.dim_region最新分区中，查询该分区中数据的条数，将结果截图粘贴至【任务B提交结果.docx】中对应的任务序号下；</p></li><li><p>将ods_ds_hudi.order_info表昨天的分区（子任务一生成的分区）数据抽取到dwd_ds_hudi.fact_order_info的动态分区表，分区字段为etl_date，类型为String，取create_time值并将格式转换为yyyyMMdd，同时若operate_time为空，则用create_time填充</p><p>id作为primaryKey，operate_time作为preCombineField</p><p>使用spark-shell执行 show partitions dwd.fact_order_info 命令，将结果截图粘贴至【任务B提交结果.docx】中对应的任务序号下；</p></li><li><p>将ods_ds_hudi.order_detail表昨天的分区（子任务一中生成的分区）数据抽取到dwd_ds_hudi.fact_order_detail的动态分区表，分区字段为etl_date，类型为String，取create_time值并将格式转换为yyyyMMdd</p><p>id作为primaryKey，dwd_modify_time作为preCombineField</p><p>使用spark-shell执行 show partitions dwd_ds_hudi.fact_order_detail 命令，将结果截图粘贴至【任务B提交结果.docx】中对应的任务序号下。</p></li></ol><h2 id="子任务三：指标计算-1"><a href="#子任务三：指标计算-1" class="headerlink" title="子任务三：指标计算"></a>子任务三：指标计算</h2><p><strong>注：在指标计算中，不考虑订单信息表中 order_status 字段的值，将所有订单视为有效订单。计算订单金额或订单总金额时只使用 final_total_amount 字段</strong></p><h3 id="第一题-1"><a href="#第一题-1" class="headerlink" title="第一题"></a>第一题</h3><p>本任务基于2、3、4小题完成，使用 <strong>DolphinScheduler</strong> 完成第2、3、4题任务代码的调度。工作流要求，使用shell输出“开始”作为工作流的第一个job（job1），2、3、4题任务为并行任务且它们依赖job1的完成（命名为job2、job3、job4），job2、job3、job4完成之后使用shell输出“结束”作为工作流的最后一个job（endjob），endjob依赖job2、job3、job4</p><p>将最终任务调度完成后的工作流截图，将截图粘贴至【任务B提交结果.docx】中对应的任务序号下；</p><h3 id="第二题-1"><a href="#第二题-1" class="headerlink" title="第二题"></a>第二题</h3><p>根据dwd_ds_hudi层表统计每个省每月下单的数量和下单的总金额，并按照year，month，region_id进行分组，按照total_amount降序排序，形成sequence值，将计算结果存入 <strong>Hive</strong> 的dws_ds_hudi.province_consumption_day_aggr表中</p><p>使用hive cli根据订单总数、订单总金额、省份表主键均为降序排序，查询出前5条，在查询时对于订单总金额字段将其转为bigint类型（避免用科学计数法展示），将SQL语句复制粘贴至【任务B提交结果.docx】中对应的任务序号下，将执行结果截图粘贴至【任务B提交结果.docx】中对应的任务序号下;</p><p><strong>dws_ds_hudi.province_consumption_day_aggr</strong></p><table><thead><tr><th align="center">字段</th><th align="center">类型</th><th align="center">中文含义</th><th align="center">备注</th></tr></thead><tbody><tr><td align="center">province_id</td><td align="center">int</td><td align="center">省份表主键</td><td align="center"></td></tr><tr><td align="center">province_name</td><td align="center">string</td><td align="center">省份名称</td><td align="center"></td></tr><tr><td align="center">region_id</td><td align="center">int</td><td align="center">地区主键</td><td align="center"></td></tr><tr><td align="center">region_name</td><td align="center">string</td><td align="center">地区名称</td><td align="center"></td></tr><tr><td align="center">total_amount</td><td align="center">double</td><td align="center">订单总金额</td><td align="center">当月订单总金额</td></tr><tr><td align="center">total_count</td><td align="center">int</td><td align="center">订单总数</td><td align="center">当月订单总数</td></tr><tr><td align="center">sequence</td><td align="center">int</td><td align="center">次序</td><td align="center"></td></tr><tr><td align="center">year</td><td align="center">int</td><td align="center">年</td><td align="center">订单产生的年,为动态分区字段</td></tr><tr><td align="center">month</td><td align="center">int</td><td align="center">月</td><td align="center">订单产生的月,为动态分区字段</td></tr></tbody></table><h3 id="第三题-1"><a href="#第三题-1" class="headerlink" title="第三题"></a>第三题</h3><p>根据dwd_ds_hudi层表统计每人每天下单的数量和下单的总金额，存入 <em><strong>Hudi</strong></em> 的dws_ds_hudi.user_consumption_day_aggr表中（表结构如下）</p><p>使用spark -shell按照客户主键、订单总金额均为降序排序，查询出前5条，将SQL语句复制粘贴至【任务B提交结果.docx】中对应的任务序号下，将执行结果截图粘贴至【任务B提交结果.docx】中对应的任务序号下；</p><p><strong>dws_ds_hudi.user_consumption_day_aggr</strong></p><table><thead><tr><th align="center">字段</th><th align="center">类型</th><th align="center">中文含义</th><th align="center">备注</th></tr></thead><tbody><tr><td align="center">uuid</td><td align="center">string</td><td align="center">随机字符</td><td align="center">随机字符，保证不同即可，作为primaryKey</td></tr><tr><td align="center">user_id</td><td align="center">int</td><td align="center">客户主键</td><td align="center"></td></tr><tr><td align="center">user_name</td><td align="center">string</td><td align="center">客户名称</td><td align="center"></td></tr><tr><td align="center">total_amount</td><td align="center">double</td><td align="center">订单总金额</td><td align="center">当天订单总金额。</td></tr><tr><td align="center">total_count</td><td align="center">int</td><td align="center">订单总数</td><td align="center">作为preCombineField</td></tr><tr><td align="center">year</td><td align="center">int</td><td align="center">年</td><td align="center">订单产生的年,为动态分区字段</td></tr><tr><td align="center">month</td><td align="center">int</td><td align="center">月</td><td align="center">订单产生的月,为动态分区字段</td></tr><tr><td align="center">day</td><td align="center">int</td><td align="center">日</td><td align="center">订单产生的日,为动态分区字段</td></tr></tbody></table><h3 id="第四题-1"><a href="#第四题-1" class="headerlink" title="第四题"></a>第四题</h3><p>根据dwd_ds_hudi层的相关表，计算2020年销售量前10的商品，销售额前10的商品，存入ClickHouse数据库 shtd_result.topten 表中</p><p>在ClickHouse命令行中根据排名升序排序，查询出前5条，将SQL语句复制粘贴至【任务B提交结果.docx】中对应的任务序号下，将执行结果截图粘贴至【任务B提交结果.docx】中对应的任务序号下;</p><p><strong>shtd_result.topten</strong></p><table><thead><tr><th align="center">字段</th><th align="center">类型</th><th align="center">中文含义</th><th align="center">备注</th></tr></thead><tbody><tr><td align="center">topquantityid</td><td align="center">int</td><td align="center">商品id</td><td align="center">销售量前10的商品</td></tr><tr><td align="center">topquantityname</td><td align="center">text</td><td align="center">商品名称</td><td align="center">销售量前10的商品</td></tr><tr><td align="center">topquantity</td><td align="center">int</td><td align="center">该商品销售量</td><td align="center">销售量前10的商品</td></tr><tr><td align="center">toppriceid</td><td align="center">text</td><td align="center">商品id</td><td align="center">销售额前10的商品</td></tr><tr><td align="center">toppricename</td><td align="center">text</td><td align="center">商品名称</td><td align="center">销售额前10的商品</td></tr><tr><td align="center">topprice</td><td align="center">decimal</td><td align="center">该商品销售额</td><td align="center">销售额前10的商品</td></tr><tr><td align="center">sequence</td><td align="center">int</td><td align="center">排名</td><td align="center">所属排名</td></tr></tbody></table><h3 id="第五题-1"><a href="#第五题-1" class="headerlink" title="第五题"></a>第五题</h3><p>请根据dwd_ds_hudi层的相关表，计算出每个省份2020年4月的平均订单金额和该省所在地区平均订单金额相比较结果（“高&#x2F;低&#x2F;相同”），存入MySQL数据库shtd_result.provinceavgcmpregion表中</p><p>在MySQL命令行中根据省份表主键、省平均订单金额、地区平均订单金额均为降序排序，查询出前5条，将SQL语句复制粘贴至【任务B提交结果.docx】中对应的任务序号下，将执行结果截图粘贴至【任务B提交结果.docx】中对应的任务序号下;</p><p> <strong>shtd_result.provinceavgcmpregion</strong></p><table><thead><tr><th align="center">字段</th><th align="center">类型</th><th align="center">中文含义</th><th align="center">备注</th></tr></thead><tbody><tr><td align="center">provinceid</td><td align="center">int</td><td align="center">省份表主键</td><td align="center"></td></tr><tr><td align="center">provincename</td><td align="center">text</td><td align="center">省份名称</td><td align="center"></td></tr><tr><td align="center">provinceavgconsumption</td><td align="center">double</td><td align="center">该省平均订单金额</td><td align="center"></td></tr><tr><td align="center">regionid</td><td align="center">int</td><td align="center">地区表主键</td><td align="center"></td></tr><tr><td align="center">regionname</td><td align="center">text</td><td align="center">地区名称</td><td align="center"></td></tr><tr><td align="center">regionavgconsumption</td><td align="center">double</td><td align="center">地区平均订单金额</td><td align="center">该省所在地区平均订单金额</td></tr><tr><td align="center">comparison</td><td align="center">text</td><td align="center">比较结果</td><td align="center">省平均订单金额和该省所在地区平均订单金额比较结果，值为：高&#x2F;低&#x2F;相同</td></tr></tbody></table><h3 id="第六题-1"><a href="#第六题-1" class="headerlink" title="第六题"></a>第六题</h3><p>根据dws_ds_hudi.province_consumption_day_aggr来计算每个地区2020年订单金额前3省份，依次存入MySQL数据库shtd_result.regiontopthree表中</p><p>在MySQL命令行中根据地区表主键升序排序，查询出前5条，将SQL语句复制粘贴至【任务B提交结果.docx】中对应的任务序号下，将执行结果截图粘贴至【任务B提交结果.docx】中对应的任务序号下；</p><p><strong>shtd_result.regiontopthree</strong></p><table><thead><tr><th align="center">字段</th><th align="center">类型</th><th align="center">中文含义</th><th align="center">备注</th></tr></thead><tbody><tr><td align="center">regionid</td><td align="center">int</td><td align="center">地区表主键</td><td align="center"></td></tr><tr><td align="center">regionname</td><td align="center">text</td><td align="center">地区名称</td><td align="center"></td></tr><tr><td align="center">provinceids</td><td align="center">text</td><td align="center">省份表主键</td><td align="center">用,分割显示前三省份的id</td></tr><tr><td align="center">provincenames</td><td align="center">text</td><td align="center">省份名称</td><td align="center">用,分割显示前三省份的name</td></tr><tr><td align="center">provinceamount</td><td align="center">text</td><td align="center">省份名称</td><td align="center">用,分割显示前三省份的订单金额（需要去除小数部分，使用四舍五入）</td></tr></tbody></table><p>例如：</p><table><thead><tr><th>3</th><th>华东地区</th><th>21,27,11</th><th>上海市,江苏省,浙江省</th><th>100000,100,10</th></tr></thead></table><h3 id="第七题-1"><a href="#第七题-1" class="headerlink" title="第七题"></a>第七题</h3><p>根据 dwd_ds_hudi 层的相关表，计算出2020年每个省份所在地区的订单金额的中位数，存入ClickHouse数据库 shtd_result.nationmedian 表中</p><p>在ClickHouse命令行中根据地区表主键，省份表主键均为升序排序，查询出前5条，将SQL语句复制粘贴至桌面【任务B提交结果.docx】中对应的任务序号下，将执行结果截图粘贴至【任务B提交结果.docx】中对应的任务序号下</p><p><em><strong>提示：可用percentile函数求取中位数</strong></em></p><p><strong>shtd_result.nationmedian</strong></p><table><thead><tr><th align="center">字段</th><th align="center">类型</th><th align="center">中文含义</th><th align="center">备注</th></tr></thead><tbody><tr><td align="center">provinceid</td><td align="center">int</td><td align="center">省份表主键</td><td align="center"></td></tr><tr><td align="center">provincename</td><td align="center">text</td><td align="center">省份名称</td><td align="center"></td></tr><tr><td align="center">regionid</td><td align="center">int</td><td align="center">地区表主键</td><td align="center"></td></tr><tr><td align="center">regionname</td><td align="center">text</td><td align="center">地区名称</td><td align="center"></td></tr><tr><td align="center">provincemedian</td><td align="center">double</td><td align="center">该省份中位数</td><td align="center">该省份订单金额中位数</td></tr><tr><td align="center">regionmedian</td><td align="center">double</td><td align="center">该省所在地区中位数</td><td align="center">该省所在地区订单金额中位数</td></tr></tbody></table><h3 id="第八题-1"><a href="#第八题-1" class="headerlink" title="第八题"></a>第八题</h3><p>根据 dwd_ds_hudi  层的数据，请计算连续两天下单的用户与已下单用户的占比，将结果存入MySQL数据库 shtd_result.userrepurchasedrate 表中</p><p>在MySQL命令行中查询结果数据，将SQL语句复制粘贴至【任务B提交结果.docx】中对应的任务序号下，将执行结果截图粘贴至【任务B提交结果.docx】中对应的任务序号下；</p><p><strong>shtd_result.userrepurchasedrate</strong></p><table><thead><tr><th align="center">字段</th><th align="center">类型</th><th align="center">中文含义</th><th align="center">备注</th></tr></thead><tbody><tr><td align="center">purchaseduser</td><td align="center">int</td><td align="center">下单人数</td><td align="center">已下单人数</td></tr><tr><td align="center">repurchaseduser</td><td align="center">int</td><td align="center">连续下单人数</td><td align="center">连续两天下单的人数</td></tr><tr><td align="center">repurchaserate</td><td align="center">text</td><td align="center">百占比</td><td align="center">连续两天下单人数&#x2F;已下单人数百分比（保留1位小数，四舍五入，不足的补0）例如21.1%，或者32.0%</td></tr></tbody></table><h3 id="第九题-1"><a href="#第九题-1" class="headerlink" title="第九题"></a>第九题</h3><p>根据 dwd_ds_hudi  层的数据，请计算每个省份累计订单量（订单信息表一条算一个记录）</p><p>根据每个省份订单量从高到低排列，将结果打印到控制台（使用spark中的show算子，同时需要显示列名），将执行结果复制并粘贴至【任务B提交结果.docx】中对应的任务序号下；</p><p>例如：可以考虑首先生成类似的临时表A：</p><table><thead><tr><th align="center">province_name</th><th align="center">Amount（订单量）</th></tr></thead><tbody><tr><td align="center">A省</td><td align="center">10122</td></tr><tr><td align="center">B省</td><td align="center">301</td></tr><tr><td align="center">C省</td><td align="center">2333333</td></tr></tbody></table><p>然后生成结果类似如下：其中C省销量最高，排在第一列，A省次之，以此类推。</p><table><thead><tr><th align="center">C省</th><th align="center">A省</th><th align="center">B省</th></tr></thead><tbody><tr><td align="center">2333333</td><td align="center">10122</td><td align="center">301</td></tr></tbody></table><p><strong>提示：可用str_to_map函数减轻工作量</strong></p><h3 id="第十题-1"><a href="#第十题-1" class="headerlink" title="第十题"></a>第十题</h3><p>根据 dwd_ds_hudi  层的数据，统计在两天内连续下单并且下单金额保持增长的用户，存入MySQL数据库 shtd_result.usercontinueorder 表</p><p>在MySQL命令行中根据订单总数、订单总金额、客户主键均为降序排序，查询出前5条，将SQL语句复制粘贴至【任务B提交结果.docx】中对应的任务序号下，将执行结果截图粘贴至【任务B提交结果.docx】中对应的任务序号下；</p><p> <strong>shtd_result.usercontinueorder</strong></p><table><thead><tr><th align="center">字段</th><th align="center">类型</th><th align="center">中文含义</th><th align="center">备注</th></tr></thead><tbody><tr><td align="center">userid</td><td align="center">int</td><td align="center">客户主键</td><td align="center"></td></tr><tr><td align="center">username</td><td align="center">text</td><td align="center">客户名称</td><td align="center"></td></tr><tr><td align="center">day</td><td align="center">text</td><td align="center">日</td><td align="center">记录下单日的时间，格式为yyyyMMdd_yyyyMMdd例如： 20220101_20220102</td></tr><tr><td align="center">totalconsumption</td><td align="center">double</td><td align="center">订单总金额</td><td align="center">连续两天的订单总金额</td></tr><tr><td align="center">totalorder</td><td align="center">int</td><td align="center">订单总数</td><td align="center">连续两天的订单总数</td></tr></tbody></table>]]></content>
      
      
      <categories>
          
          <category> 大数据比赛 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 大数据 </tag>
            
            <tag> Azkaban </tag>
            
            <tag> Spark </tag>
            
            <tag> DolphinScheduler </tag>
            
            <tag> Hive </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Spark调优笔记</title>
      <link href="/2023/06/09/Spark%E8%B0%83%E4%BC%98%E7%AC%94%E8%AE%B0/"/>
      <url>/2023/06/09/Spark%E8%B0%83%E4%BC%98%E7%AC%94%E8%AE%B0/</url>
      
        <content type="html"><![CDATA[<h1 id="关于持久化"><a href="#关于持久化" class="headerlink" title="关于持久化"></a>关于持久化</h1><p><strong>persist</strong></p><p>允许用户选择一个特定的存储级别来持久化数据集。</p><p>Spark提供了多种存储级别，包括<code>MEMORY_LONY</code>、<code>MEMORY_AND_DISK</code>、<code>MEMORY_ONLY_SER</code>、<code>MEMORY_AND_DISK_SER</code>、<code>DISK_ONLY</code>、<code>OFF_HEAP</code>等</p><p><strong>cache</strong></p><p>persist的一种特殊用法，从cache将数据集以默认的存储级别<code>MEMORY_AND_DISK</code>进行持久化，即：如果内存不足存放数据集那么Spark会将数据溢出到磁盘</p><p><strong>checkpoint</strong></p><p>一种特殊的数据持久化机制，目的是通过在稳定的存储系统(如HDFS)上来保存数据切断RDD的线性依赖链。</p><p>checkpoint会使RDD的依赖关系被完全丢弃，并且涉及到磁盘I&#x2F;O，开销较大。通常我们只在必要的时候使用checkpoint，比如迭代计算和图计算。</p><p><strong>总的来说</strong></p><ul><li>persist和cache：通常用于持久化跨多个操作重用的中间数据以减少计算时间，主要目的是优化计算性能</li><li>checkpoint：通常用于防止由于RDD的依赖链过长导致的问题，主要目的是优化RDD的依赖链长度和计算的可靠性。</li></ul><p><strong>面试题：为什么要持久化？一般什么场景进行persist操作？</strong></p><p>在Spark中转换操作是惰性执行的，只有调用行动操作时才会被执行，这意味着每次调用动作操作都会重新计算转换操作。这在需要多次复用同一个数据集时会导致性能损失。持久化可以帮助我们将经常使用的数据存储在内存或磁盘以便可以在之后的计算中直接使用，而不需要重新进行所有的转换操作，这可以极大地提高计算效率节省计算资源。</p><p>在以下场景中，通常会进行persist操作：</p><ol><li>某个步骤计算非常耗时</li><li>计算链条非常长，重新恢复需要很多步骤</li><li>checkpoint之前，提前进行cache或persist将数据保存再进行checkpoint这样就不用重新计算</li><li>shuffle之后要persist，shuffle要进行网络传输，风险很大，数据丢失重来恢复代价很大</li><li>shuffle之前会自动进行persist，这是Spark自动做的，为了防止内存溢出Spark会将shuffle的数据临时存储在磁盘上，shuffle结束后数据将被删除。</li></ol>]]></content>
      
      
      <categories>
          
          <category> 学习文档 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 大数据 </tag>
            
            <tag> Spark </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>DolphinScheduler学习文档-尚硅谷版</title>
      <link href="/2023/05/28/DolphinScheduler%E5%AD%A6%E4%B9%A0%E6%96%87%E6%A1%A3/"/>
      <url>/2023/05/28/DolphinScheduler%E5%AD%A6%E4%B9%A0%E6%96%87%E6%A1%A3/</url>
      
        <content type="html"><![CDATA[<p>原视频：【尚硅谷】DolphinScheduler2.x安装到优化（工作流调度平台）</p><p>网址：<a href="https://www.bilibili.com/video/BV1sa411x7Ep/?p=1">https://www.bilibili.com/video/BV1sa411x7Ep/?p=1</a></p><h1 id="核心架构"><a href="#核心架构" class="headerlink" title="核心架构"></a>核心架构</h1><h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p>Apache DolphinScheduler 是一个分布式、易扩展的可视化 DAG 工作流任务调度平台。致力于解决数据处理流程中错综复杂的依赖关系，使调度系统在数据处理流程中开箱即用。</p><h2 id="主要结构"><a href="#主要结构" class="headerlink" title="主要结构"></a>主要结构</h2><ul><li><p>MasterServer</p><p>采用分布式无中心设计理念，MasterServer主要负责DAG任务切分、任务提交、任务监控，同时借助Zookeeper监听其他MasterServer和WorkerServer的健康状态</p></li><li><p>WorkerServer</p><p>采用分布式无中心设计理念，WorkerServer主要负责任务的执行和提供日志服务</p></li><li><p>Zookeeper</p><p>MasterServer和WorkerServer通过Zookeeper来进行集群管理和容错</p></li><li><p>Alert</p><p>提供告警相关服务</p></li><li><p>API</p><p>负责处理前端UI层的请求</p></li><li><p>UI</p><p>系统的前端页面，提供系统的各种可视化操作界面</p></li></ul><h2 id="架构图"><a href="#架构图" class="headerlink" title="架构图"></a>架构图</h2><p><img src="https://flyohh.cloud/blog_img/2023/05/28/6472fd05d4aed.png" alt="架构图"></p><h2 id="执行流程"><a href="#执行流程" class="headerlink" title="执行流程"></a>执行流程</h2><ol><li>用户在UI中配置好调度需求后，UI调用API接口</li><li>API生成工作流元数据存储至数据库</li><li>由于Master无中心所以其实是若干Master监听着Database看有没有需要执行的任务，谁先监听到就有谁负责该工作流</li><li>抢到工作流的Master先进行DAG任务切分随后发送给Worker</li><li>Worker收到之后ack回复一个收到任何开始执行任务</li><li>Worker返回Master任务的执行状态</li><li>Master将任务执行状态返回到Database</li><li>每个WorkerServer都有LoggerServer，UI可以调用API接口查看日志，API这边会自动找到对应的LoggerServer节点查询出日志信息</li><li>出错时Alter会将告警信息存储到Database</li></ol><h1 id="安装部署"><a href="#安装部署" class="headerlink" title="安装部署"></a>安装部署</h1><p><strong>集群规划</strong></p><p>集群模式通常配置2~3个Master+若干个Worker，由于资源有限，我们只配置1个Master和3个Worker</p><h2 id="前置环境"><a href="#前置环境" class="headerlink" title="前置环境"></a>前置环境</h2><ul><li><p>JDK 1.8+</p></li><li><p>MySQL 5.7+</p></li><li><p>Zookeeper 3.4.6+</p></li><li><p>三台节点均安装进程树分析工具 psmisc</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum install -y psmisc</span><br></pre></td></tr></table></figure></li><li><p>下载dolphinScheduler、mysql连接驱动、commons-cli</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">https://archive.apache.org/dist/dolphinscheduler/3.1.4/apache-dolphinscheduler-3.1.4-bin.tar.gz</span><br><span class="line">https://repo1.maven.org/maven2/mysql/mysql-connector-java/8.0.16/mysql-connector-java-8.0.16.jar</span><br><span class="line">https://repo1.maven.org/maven2/commons-cli/commons-cli/1.3.1/commons-cli-1.3.1.jar</span><br></pre></td></tr></table></figure></li></ul><h2 id="解压"><a href="#解压" class="headerlink" title="解压"></a>解压</h2><p>按照惯例，安装组件就是解压然后改一堆配置文件，但是dolphinscheduler考虑到这点所以提供了一个一键部署脚本。所以应该是先解压然后找到一键部署脚本，配置一堆参数，如：master在哪个节点、安装目录指定哪里等，最后一键部署。</p><p>创建ds目录，解压</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">mkdir</span> /opt/ds</span><br><span class="line">tar -zxvf apache-dolphinscheduler-3.1.4-bin.tar.gz -C /opt/ds</span><br></pre></td></tr></table></figure><h2 id="拷贝"><a href="#拷贝" class="headerlink" title="拷贝"></a>拷贝</h2><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cp</span> mysql-connector-java-8.0.16.jar /opt/ds/apache-dolphinscheduler-3.1.4-bin/tools/libs/</span><br><span class="line"><span class="built_in">cp</span> mysql-connector-java-8.0.16.jar /opt/ds/apache-dolphinscheduler-3.1.4-bin/alert-server/libs/</span><br><span class="line"><span class="built_in">cp</span> mysql-connector-java-8.0.16.jar /opt/ds/apache-dolphinscheduler-3.1.4-bin/api-server/libs/</span><br><span class="line"><span class="built_in">cp</span> mysql-connector-java-8.0.16.jar /opt/ds/apache-dolphinscheduler-3.1.4-bin/master-server/libs/</span><br><span class="line"><span class="built_in">cp</span> mysql-connector-java-8.0.16.jar /opt/ds/apache-dolphinscheduler-3.1.4-bin/standalone-server/libs/</span><br><span class="line"><span class="built_in">cp</span> mysql-connector-java-8.0.16.jar /opt/ds/apache-dolphinscheduler-3.1.4-bin/worker-server/libs/</span><br></pre></td></tr></table></figure><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cp</span> commons-cli-1.3.1.jar /opt/ds/apache-dolphinscheduler-3.1.4-bin/tools/libs/</span><br><span class="line"><span class="built_in">cp</span> commons-cli-1.3.1.jar /opt/ds/apache-dolphinscheduler-3.1.4-bin/alert-server/libs/</span><br><span class="line"><span class="built_in">cp</span> commons-cli-1.3.1.jar /opt/ds/apache-dolphinscheduler-3.1.4-bin/api-server/libs/</span><br><span class="line"><span class="built_in">cp</span> commons-cli-1.3.1.jar /opt/ds/apache-dolphinscheduler-3.1.4-bin/master-server/libs/</span><br><span class="line"><span class="built_in">cp</span> commons-cli-1.3.1.jar /opt/ds/apache-dolphinscheduler-3.1.4-bin/standalone-server/libs/</span><br><span class="line"><span class="built_in">cp</span> commons-cli-1.3.1.jar /opt/ds/apache-dolphinscheduler-3.1.4-bin/worker-server/libs/</span><br></pre></td></tr></table></figure><h2 id="创建元数据用户"><a href="#创建元数据用户" class="headerlink" title="创建元数据用户"></a>创建元数据用户</h2><p>进入MySQL</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mysql -uroot -p</span><br></pre></td></tr></table></figure><p>降低密码安全等级、创建用户、赋予权限、创建数据库、刷新</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">set</span> <span class="keyword">global</span> validate_password_policy<span class="operator">=</span><span class="number">0</span>;</span><br><span class="line"><span class="keyword">set</span> <span class="keyword">global</span> validate_password_length<span class="operator">=</span><span class="number">4</span>;</span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">USER</span> <span class="string">&#x27;dolphinscheduler&#x27;</span>@<span class="string">&#x27;%&#x27;</span> IDENTIFIED <span class="keyword">BY</span> <span class="string">&#x27;dolphinscheduler&#x27;</span>;</span><br><span class="line"><span class="keyword">grant</span> <span class="keyword">all</span> privileges <span class="keyword">on</span> dolphinscheduler.<span class="operator">*</span> <span class="keyword">to</span> <span class="string">&#x27;dolphinscheduler&#x27;</span>@<span class="string">&#x27;%&#x27;</span> ;</span><br><span class="line"><span class="keyword">CREATE</span> DATABASE dolphinscheduler <span class="keyword">DEFAULT</span> <span class="type">CHARACTER</span> <span class="keyword">SET</span> utf8 <span class="keyword">DEFAULT</span> <span class="keyword">COLLATE</span> utf8_general_ci;</span><br><span class="line">flush privileges;</span><br></pre></td></tr></table></figure><h2 id="修改配置文件"><a href="#修改配置文件" class="headerlink" title="修改配置文件"></a>修改配置文件</h2><p>一键部署脚本在这里<code>/opt/ds/apache-dolphinscheduler-3.1.4-bin/bin/install.sh</code></p><p>一键部署脚本的配置文件在这里<code>/opt/ds/apache-dolphinscheduler-3.1.4-bin/bin/env/install_env.sh </code></p><p>使用该脚本之前，需要配置好配置文件</p><h3 id="dolphinscheduler-env-sh"><a href="#dolphinscheduler-env-sh" class="headerlink" title="dolphinscheduler_env.sh"></a>dolphinscheduler_env.sh</h3><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim /opt/ds/apache-dolphinscheduler-3.1.4-bin/bin/env/dolphinscheduler_env.sh</span><br></pre></td></tr></table></figure><p>内容如下</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># Licensed to the Apache Software Foundation (ASF) under one or more</span></span><br><span class="line"><span class="comment"># contributor license agreements.  See the NOTICE file distributed with</span></span><br><span class="line"><span class="comment"># this work for additional information regarding copyright ownership.</span></span><br><span class="line"><span class="comment"># The ASF licenses this file to You under the Apache License, Version 2.0</span></span><br><span class="line"><span class="comment"># (the &quot;License&quot;); you may not use this file except in compliance with</span></span><br><span class="line"><span class="comment"># the License.  You may obtain a copy of the License at</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment">#     http://www.apache.org/licenses/LICENSE-2.0</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># Unless required by applicable law or agreed to in writing, software</span></span><br><span class="line"><span class="comment"># distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span></span><br><span class="line"><span class="comment"># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span></span><br><span class="line"><span class="comment"># See the License for the specific language governing permissions and</span></span><br><span class="line"><span class="comment"># limitations under the License.</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># JAVA_HOME, will use it to start DolphinScheduler server</span></span><br><span class="line"><span class="built_in">export</span> JAVA_HOME=<span class="variable">$&#123;JAVA_HOME:-/opt/jdk1.8&#125;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Database related configuration, set database type, username and password</span></span><br><span class="line"><span class="comment"># 数据库类型、url、用户、密码</span></span><br><span class="line"><span class="built_in">export</span> DATABASE=<span class="variable">$&#123;DATABASE:-mysql&#125;</span></span><br><span class="line"><span class="built_in">export</span> SPRING_PROFILES_ACTIVE=<span class="variable">$&#123;DATABASE&#125;</span></span><br><span class="line"><span class="built_in">export</span> SPRING_DATASOURCE_URL=<span class="string">&quot;jdbc:mysql://node:3306/dolphinscheduler?useUnicode=true&amp;characterEncoding=UTF-8&amp;useSSL=false&quot;</span></span><br><span class="line"><span class="built_in">export</span> SPRING_DATASOURCE_USERNAME=<span class="variable">$&#123;SPRING_DATASOURCE_USERNAME:-&quot;dolphinscheduler&quot;&#125;</span></span><br><span class="line"><span class="built_in">export</span> SPRING_DATASOURCE_PASSWORD=<span class="variable">$&#123;SPRING_DATASOURCE_PASSWORD:-&quot;dolphinscheduler&quot;&#125;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># DolphinScheduler server related configuration</span></span><br><span class="line"><span class="built_in">export</span> SPRING_CACHE_TYPE=<span class="variable">$&#123;SPRING_CACHE_TYPE:-none&#125;</span></span><br><span class="line"><span class="built_in">export</span> SPRING_JACKSON_TIME_ZONE=<span class="variable">$&#123;SPRING_JACKSON_TIME_ZONE:-Asia/Shanghai&#125;</span></span><br><span class="line"><span class="built_in">export</span> MASTER_FETCH_COMMAND_NUM=<span class="variable">$&#123;MASTER_FETCH_COMMAND_NUM:-10&#125;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Registry center configuration, determines the type and link of the registry center</span></span><br><span class="line"><span class="built_in">export</span> REGISTRY_TYPE=<span class="variable">$&#123;REGISTRY_TYPE:-zookeeper&#125;</span></span><br><span class="line"><span class="built_in">export</span> REGISTRY_ZOOKEEPER_CONNECT_STRING=<span class="variable">$&#123;REGISTRY_ZOOKEEPER_CONNECT_STRING:-node:2181,node1:2181,node2:2181&#125;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Tasks related configurations, need to change the configuration if you use the related tasks.</span></span><br><span class="line"><span class="built_in">export</span> HADOOP_HOME=<span class="variable">$&#123;HADOOP_HOME:-/opt/hadoop-3.1.3&#125;</span></span><br><span class="line"><span class="built_in">export</span> HADOOP_CONF_DIR=<span class="variable">$&#123;HADOOP_CONF_DIR:-/opt/hadoop-3.1.3/etc/hadoop&#125;</span></span><br><span class="line"><span class="built_in">export</span> SPARK_HOME1=<span class="variable">$&#123;SPARK_HOME1:-/opt/soft/spark1&#125;</span></span><br><span class="line"><span class="built_in">export</span> SPARK_HOME2=<span class="variable">$&#123;SPARK_HOME2:-/opt/spark-3.1.1&#125;</span></span><br><span class="line"><span class="comment"># export PYTHON_HOME=$&#123;PYTHON_HOME:-/opt/soft/python&#125;</span></span><br><span class="line"><span class="built_in">export</span> HIVE_HOME=<span class="variable">$&#123;HIVE_HOME:-/opt/hive-3.1.2&#125;</span></span><br><span class="line"><span class="comment"># export FLINK_HOME=$&#123;FLINK_HOME:-/opt/soft/flink&#125;</span></span><br><span class="line"><span class="comment"># export DATAX_HOME=$&#123;DATAX_HOME:-/opt/soft/datax&#125;</span></span><br><span class="line"><span class="comment"># export SEATUNNEL_HOME=$&#123;SEATUNNEL_HOME:-/opt/soft/seatunnel&#125;</span></span><br><span class="line"><span class="comment"># export CHUNJUN_HOME=$&#123;CHUNJUN_HOME:-/opt/soft/chunjun&#125;</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$HADOOP_HOME</span>/bin:<span class="variable">$SPARK_HOME1</span>/bin:<span class="variable">$SPARK_HOME2</span>/bin:<span class="variable">$JAVA_HOME</span>/bin:<span class="variable">$HIVE_HOME</span>/bin:<span class="variable">$PATH</span></span><br></pre></td></tr></table></figure><h3 id="install-env-sh"><a href="#install-env-sh" class="headerlink" title="install_env.sh"></a>install_env.sh</h3><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim /opt/ds/apache-dolphinscheduler-3.1.4-bin/bin/env/install_env.sh</span><br></pre></td></tr></table></figure><p>内容如下</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># Licensed to the Apache Software Foundation (ASF) under one or more</span></span><br><span class="line"><span class="comment"># contributor license agreements.  See the NOTICE file distributed with</span></span><br><span class="line"><span class="comment"># this work for additional information regarding copyright ownership.</span></span><br><span class="line"><span class="comment"># The ASF licenses this file to You under the Apache License, Version 2.0</span></span><br><span class="line"><span class="comment"># (the &quot;License&quot;); you may not use this file except in compliance with</span></span><br><span class="line"><span class="comment"># the License.  You may obtain a copy of the License at</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment">#     http://www.apache.org/licenses/LICENSE-2.0</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># Unless required by applicable law or agreed to in writing, software</span></span><br><span class="line"><span class="comment"># distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span></span><br><span class="line"><span class="comment"># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span></span><br><span class="line"><span class="comment"># See the License for the specific language governing permissions and</span></span><br><span class="line"><span class="comment"># limitations under the License.</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># ---------------------------------------------------------</span></span><br><span class="line"><span class="comment"># INSTALL MACHINE</span></span><br><span class="line"><span class="comment"># ---------------------------------------------------------</span></span><br><span class="line"><span class="comment"># A comma separated list of machine hostname or IP would be installed DolphinScheduler,</span></span><br><span class="line"><span class="comment"># including master, worker, api, alert. If you want to deploy in pseudo-distributed</span></span><br><span class="line"><span class="comment"># mode, just write a pseudo-distributed hostname</span></span><br><span class="line"><span class="comment"># Example for hostnames: ips=&quot;ds1,ds2,ds3,ds4,ds5&quot;, Example for IPs: ips=&quot;192.168.8.1,192.168.8.2,192.168.8.3,192.168.8.4,192.168.8.5&quot;</span></span><br><span class="line"><span class="comment"># 待部署的所有主机名</span></span><br><span class="line">ips=<span class="variable">$&#123;ips:-&quot;node,node1,node2&quot;&#125;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Port of SSH protocol, default value is 22. For now we only support same port in all `ips` machine</span></span><br><span class="line"><span class="comment"># modify it if you use different ssh port</span></span><br><span class="line">sshPort=<span class="variable">$&#123;sshPort:-&quot;22&quot;&#125;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># A comma separated list of machine hostname or IP would be installed Master server, it</span></span><br><span class="line"><span class="comment"># must be a subset of configuration `ips`.</span></span><br><span class="line"><span class="comment"># Example for hostnames: masters=&quot;ds1,ds2&quot;, Example for IPs: masters=&quot;192.168.8.1,192.168.8.2&quot;</span></span><br><span class="line"><span class="comment"># masterServer主机名列表</span></span><br><span class="line">masters=<span class="variable">$&#123;masters:-&quot;node&quot;&#125;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># A comma separated list of machine &lt;hostname&gt;:&lt;workerGroup&gt; or &lt;IP&gt;:&lt;workerGroup&gt;.All hostname or IP must be a</span></span><br><span class="line"><span class="comment"># subset of configuration `ips`, And workerGroup have default value as `default`, but we recommend you declare behind the hosts</span></span><br><span class="line"><span class="comment"># Example for hostnames: workers=&quot;ds1:default,ds2:default,ds3:default&quot;, Example for IPs: workers=&quot;192.168.8.1:default,192.168.8.2:default,192.168.8.3:default&quot;</span></span><br><span class="line"><span class="comment"># workerServer主机名列表</span></span><br><span class="line">workers=<span class="variable">$&#123;workers:-&quot;node:default,node1:default,node2:default&quot;&#125;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># A comma separated list of machine hostname or IP would be installed Alert server, it</span></span><br><span class="line"><span class="comment"># must be a subset of configuration `ips`.</span></span><br><span class="line"><span class="comment"># Example for hostname: alertServer=&quot;ds3&quot;, Example for IP: alertServer=&quot;192.168.8.3&quot;</span></span><br><span class="line"><span class="comment"># 告警服务所在服务器主机名</span></span><br><span class="line">alertServer=<span class="variable">$&#123;alertServer:-&quot;node&quot;&#125;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># A comma separated list of machine hostname or IP would be installed API server, it</span></span><br><span class="line"><span class="comment"># must be a subset of configuration `ips`.</span></span><br><span class="line"><span class="comment"># Example for hostname: apiServers=&quot;ds1&quot;, Example for IP: apiServers=&quot;192.168.8.1&quot;</span></span><br><span class="line"><span class="comment"># API服务所在服务器主机名</span></span><br><span class="line">apiServers=<span class="variable">$&#123;apiServers:-&quot;node&quot;&#125;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># The directory to install DolphinScheduler for all machine we config above. It will automatically be created by `install.sh` script if not exists.</span></span><br><span class="line"><span class="comment"># Do not set this configuration same as the current path (pwd). Do not add quotes to it if you using related path.</span></span><br><span class="line"><span class="comment"># 安装目录</span></span><br><span class="line">installPath=<span class="variable">$&#123;installPath:-&quot;/opt/dolphinscheduler&quot;&#125;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># The user to deploy DolphinScheduler for all machine we config above. For now user must create by yourself before running `install.sh`</span></span><br><span class="line"><span class="comment"># script. The user needs to have sudo privileges and permissions to operate hdfs. If hdfs is enabled than the root directory needs</span></span><br><span class="line"><span class="comment"># to be created by this user</span></span><br><span class="line"><span class="comment"># 部署用户</span></span><br><span class="line">deployUser=<span class="variable">$&#123;deployUser:-&quot;root&quot;&#125;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># The root of zookeeper, for now DolphinScheduler default registry server is zookeeper.</span></span><br><span class="line">zkRoot=<span class="variable">$&#123;zkRoot:-&quot;/dolphinscheduler&quot;&#125;</span></span><br></pre></td></tr></table></figure><h2 id="初始化数据库"><a href="#初始化数据库" class="headerlink" title="初始化数据库"></a>初始化数据库</h2><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bash /opt/ds/apache-dolphinscheduler-3.1.4-bin/tools/bin/upgrade-schema.sh</span><br></pre></td></tr></table></figure><h2 id="部署"><a href="#部署" class="headerlink" title="部署"></a>部署</h2><p>开启zk、一键部署</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">zk start</span><br><span class="line">bash /opt/ds/apache-dolphinscheduler-3.1.4-bin/bin/install.sh</span><br></pre></td></tr></table></figure><h2 id="查看部署情况"><a href="#查看部署情况" class="headerlink" title="查看部署情况"></a>查看部署情况</h2><p>部署结束会自动开启进程，查看进程</p><p><img src="https://flyohh.cloud/blog_img/2023/05/29/6474613aa8ce2.png" alt="jpsall"></p><p>进入UI界面，<a href="http://node:12345/dolphinscheduler/ui">网址点我</a>，默认账号密码为 <strong>admin 和 dolphinscheduler123</strong></p><p><img src="https://flyohh.cloud/blog_img/2023/05/29/647461b3cb72a.png" alt="UI页面"></p><h2 id="启停命令"><a href="#启停命令" class="headerlink" title="启停命令"></a>启停命令</h2><ul><li><p>开启集群所有服务</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sh /opt/dolphinscheduler/bin/start-all.sh</span><br></pre></td></tr></table></figure></li><li><p>停止集群所有服务</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sh /opt/dolphinscheduler/bin/stop-all.sh</span><br></pre></td></tr></table></figure></li><li><p>启 Master</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sh /opt/dolphinscheduler/bin/dolphinscheduler-daemon.sh start master-server</span><br></pre></td></tr></table></figure></li><li><p>停 Master</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sh /opt/dolphinscheduler/bin/dolphinscheduler-daemon.sh stop master-server</span><br></pre></td></tr></table></figure></li><li><p>启 Worker</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sh /opt/dolphinscheduler/bin/dolphinscheduler-daemon.sh start worker-server</span><br></pre></td></tr></table></figure></li><li><p>停 Worker</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sh /opt/dolphinscheduler/bin/dolphinscheduler-daemon.sh stop worker-server</span><br></pre></td></tr></table></figure></li><li><p>启 Api</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sh /opt/dolphinscheduler/bin/dolphinscheduler-daemon.sh start api-server</span><br></pre></td></tr></table></figure></li><li><p>停 Api</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sh /opt/dolphinscheduler/bin/dolphinscheduler-daemon.sh stop api-server</span><br></pre></td></tr></table></figure></li><li><p>启 Logger</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sh /opt/dolphinscheduler/bin/dolphinscheduler-daemon.sh start logger-server</span><br></pre></td></tr></table></figure></li><li><p>停 Logger</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sh /opt/dolphinscheduler/bin/dolphinscheduler-daemon.sh stop logger-server</span><br></pre></td></tr></table></figure></li><li><p>启 Alert</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sh /opt/dolphinscheduler/bin/dolphinscheduler-daemon.sh start alert-server</span><br></pre></td></tr></table></figure></li><li><p>停 Alert</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sh /opt/dolphinscheduler/bin/dolphinscheduler-daemon.sh stop alert-server</span><br></pre></td></tr></table></figure></li></ul><h2 id="配置资源中心"><a href="#配置资源中心" class="headerlink" title="配置资源中心"></a>配置资源中心</h2><p>当需要使用资源中心进行相关文件的创建或者上传操作时，所有的文件和资源都会被存储在分布式文件系统HDFS或者远端的对象存储。所以需要进行以下配置。</p><p><strong>配置 common.properties 文件</strong></p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim /opt/dolphinscheduler/api-server/conf/common.properties</span><br></pre></td></tr></table></figure><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim /opt/dolphinscheduler/worker-server/conf/common.properties</span><br></pre></td></tr></table></figure><p>均修改如下</p><figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># user data local directory path, please make sure the directory exists and have read write permissions</span></span><br><span class="line"><span class="attr">data.basedir.path</span>=<span class="string">/opt/dolphinscheduler/data</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment"># resource view suffixs</span></span><br><span class="line"><span class="comment">#resource.view.suffixs=txt,log,sh,bat,conf,cfg,py,java,sql,xml,hql,properties,json,yml,yaml,ini,js</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment"># resource storage type: HDFS, S3, OSS, NONE</span></span><br><span class="line"><span class="attr">resource.storage.type</span>=<span class="string">HDFS</span></span><br><span class="line"><span class="comment"># resource store on HDFS/S3 path, resource file will store to this base path, self configuration, please make sure the directory exists on hdfs and have read write permissions. &quot;/dolphinscheduler&quot; is recommended</span></span><br><span class="line"><span class="attr">resource.storage.upload.base.path</span>=<span class="string">/dolphinscheduler</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment"># if resource.storage.type=HDFS, the user must have the permission to create directories under the HDFS root path</span></span><br><span class="line"><span class="attr">resource.hdfs.root.user</span>=<span class="string">root</span></span><br><span class="line"><span class="comment"># if resource.storage.type=S3, the value like: s3a://dolphinscheduler; if resource.storage.type=HDFS and namenode HA is enabled, you need to copy core-site.xml and hdfs-site.xml to conf dir</span></span><br><span class="line"><span class="attr">resource.hdfs.fs.defaultFS</span>=<span class="string">hdfs://node:8020</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment"># resourcemanager port, the default value is 8088 if not specified</span></span><br><span class="line"><span class="attr">resource.manager.httpaddress.port</span>=<span class="string">8088</span></span><br><span class="line"><span class="comment"># if resourcemanager HA is enabled, please set the HA IPs; if resourcemanager is single, keep this value empty</span></span><br><span class="line"><span class="attr">yarn.resourcemanager.ha.rm.ids</span>=<span class="string"></span></span><br><span class="line"><span class="comment"># if resourcemanager HA is enabled or not use resourcemanager, please keep the default value; If resourcemanager is single, you only need to replace ds1 to actual resourcemanager hostname</span></span><br><span class="line"><span class="attr">yarn.application.status.address</span>=<span class="string">http://node:%s/ws/v1/cluster/apps/%s</span></span><br><span class="line"><span class="comment"># job history status url when application number threshold is reached(default 10000, maybe it was set to 1000)</span></span><br><span class="line"><span class="attr">yarn.job.history.status.address</span>=<span class="string">http://node:19888/ws/v1/history/mapreduce/jobs/%s</span></span><br></pre></td></tr></table></figure><p><strong>将修改的文件分发到其它服务器</strong></p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">xsync /opt/dolphinscheduler/api-server/conf/common.properties</span><br><span class="line">xsync /opt/dolphinscheduler/worker-server/conf/common.properties</span><br></pre></td></tr></table></figure><p><strong>创建存储数据的目录</strong></p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 在HDFS上创建目录</span></span><br><span class="line">hdfs dfs -<span class="built_in">mkdir</span> /dolphinscheduler</span><br><span class="line"><span class="comment"># 本地每一台服务器创建目录，注意，这条命令是每个节点都要</span></span><br><span class="line"><span class="built_in">mkdir</span> /opt/dolphinscheduler/data</span><br></pre></td></tr></table></figure><p><strong>重启服务</strong></p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sh /opt/dolphinscheduler/bin/stop-all.sh</span><br><span class="line">sh /opt/dolphinscheduler/bin/start-all.sh</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 学习文档 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 大数据 </tag>
            
            <tag> DolphinScheduler </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Azkaban学习文档-尚硅谷版</title>
      <link href="/2023/05/17/Azkaban%E5%AD%A6%E4%B9%A0%E6%96%87%E6%A1%A3/"/>
      <url>/2023/05/17/Azkaban%E5%AD%A6%E4%B9%A0%E6%96%87%E6%A1%A3/</url>
      
        <content type="html"><![CDATA[<p>原视频：尚硅谷大数据Azkaban 3.x教程（全新发布）</p><p>网址：<a href="https://www.bilibili.com/video/BV1y54y18713/?p=1">https://www.bilibili.com/video/BV1y54y18713/?p=1</a></p><h1 id="安装部署"><a href="#安装部署" class="headerlink" title="安装部署"></a>安装部署</h1><h2 id="Azkaban概述"><a href="#Azkaban概述" class="headerlink" title="Azkaban概述"></a>Azkaban概述</h2><p><strong>为什么需要工作流调度系统</strong></p><p>一个完整的数据分析系统通常都是由大量任务单元组成：shell脚本程序、java程序、mapreduce程序、spark程序、hive脚本等等，<code>各个任务单元之间存在时间先后以及前后依赖关系</code>。</p><p><code>为了很好的组织起这样复杂的执行计划</code>，需要一个工作流调度系统来调度执行任务单元。</p><p><img src="https://flyohh.cloud/blog_img/2023/05/16/6462e65b0f041.png" alt="为什么需要工作流调度系统"><strong>Azkaban架构图</strong></p><p><img src="https://flyohh.cloud/blog_img/2023/05/16/6462e7f34eb27.png" alt="架构图"></p><p>单机模式是将web server和executor server在一个进程里启动</p><p>集群模式是分开的进程</p><p>下面的规划是：node节点部署web进程，node、node1、node2节点都部署execuor进程</p><h2 id="上传解压"><a href="#上传解压" class="headerlink" title="上传解压"></a>上传解压</h2><p><a href="https://pan.baidu.com/s/1Yq2_CrEjSLZ49wcWN355IQ?pwd=2181">安装包下载点我</a></p><p>下载好之后将三个安装包上传到node节点</p><p><img src="https://flyohh.cloud/blog_img/2023/05/16/6462f39a4cecd.png" alt="上传"></p><p>其中web和exec需要单独部署，db存放的则是有关mysql的建表语句</p><p>提前建一个文件夹，解压安装包，重命名</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">mkdir /opt/azkaban</span><br><span class="line">tar -zxvf azkaban-db-3.84.4.tar.gz -C /opt/azkaban/</span><br><span class="line">tar -zxvf azkaban-exec-server-3.84.4.tar.gz -C /opt/azkaban/</span><br><span class="line">tar -zxvf azkaban-web-server-3.84.4.tar.gz -C /opt/azkaban/</span><br><span class="line">cd /opt/azkaban/</span><br><span class="line">mv azkaban-exec-server-3.84.4/ azkaban-exec</span><br><span class="line">mv azkaban-web-server-3.84.4/ azkaban-web</span><br></pre></td></tr></table></figure><h2 id="配置MYSQL"><a href="#配置MYSQL" class="headerlink" title="配置MYSQL"></a>配置MYSQL</h2><p>进入MYSQL命令行，创建azkaban数据库</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">create</span> database azkaban;</span><br></pre></td></tr></table></figure><p>创建azkaban使用的用户</p><ol><li><p>创建 Azkaban 用户，任何主机都可以访问 Azkaban，密码是 000000</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">USER</span> <span class="string">&#x27;azkaban&#x27;</span>@<span class="string">&#x27;%&#x27;</span> IDENTIFIED <span class="keyword">BY</span> <span class="string">&#x27;000000&#x27;</span>;</span><br></pre></td></tr></table></figure></li><li><p>赋予 Azkaban 用户增删改查权限</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">GRANT</span> <span class="keyword">SELECT</span>,<span class="keyword">INSERT</span>,<span class="keyword">UPDATE</span>,<span class="keyword">DELETE</span> <span class="keyword">ON</span> azkaban.<span class="operator">*</span> <span class="keyword">to</span> <span class="string">&#x27;azkaban&#x27;</span>@<span class="string">&#x27;%&#x27;</span> <span class="keyword">WITH</span> <span class="keyword">GRANT</span> OPTION;</span><br></pre></td></tr></table></figure></li><li><p>创建 Azkaban 表，完成后退出 MySQL</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">use azkaban;</span><br><span class="line">source <span class="operator">/</span>opt<span class="operator">/</span>azkaban<span class="operator">/</span>azkaban<span class="operator">-</span>db<span class="number">-3.84</span><span class="number">.4</span><span class="operator">/</span><span class="keyword">create</span><span class="operator">-</span><span class="keyword">all</span><span class="operator">-</span><span class="keyword">sql</span><span class="number">-3.84</span><span class="number">.4</span>.<span class="keyword">sql</span></span><br><span class="line">quit;</span><br></pre></td></tr></table></figure></li></ol><p>更改 MySQL 包大小；防止 Azkaban 连接 MySQL 阻塞</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim <span class="operator">/</span>etc<span class="operator">/</span>my.cnf</span><br></pre></td></tr></table></figure><p>在[mysqld]下面加一行 max_allowed_packet&#x3D;1024M</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[mysqld]</span><br><span class="line">max_allowed_packet=1024M</span><br></pre></td></tr></table></figure><p>重启 MySQL</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">systemctl restart mysqld</span><br></pre></td></tr></table></figure><h2 id="配置ExecutorServer"><a href="#配置ExecutorServer" class="headerlink" title="配置ExecutorServer"></a>配置ExecutorServer</h2><p>编辑 azkaban.properties</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim /opt/azkaban/azkaban-exec/conf/azkaban.properties</span><br></pre></td></tr></table></figure><p>修改如下配置项</p><ul><li><p>default.timezone.id&#x3D;<code>Asia/Shanghai</code></p></li><li><p>azkaban.webserver.url&#x3D;http:&#x2F;&#x2F;<code>node</code>:8081</p></li><li><p>mysql.host&#x3D;<code>node</code></p></li><li><p>mysql.password&#x3D;<code>000000</code></p></li><li><p><code>executor.port=12321</code></p><p>没这个配置，在文件末尾加上就行</p></li></ul><p>分发到其他节点，没有xsync命令的使用scp传到其他节点</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">xsync /opt/azkaban/azkaban-exec</span><br></pre></td></tr></table></figure><p><strong>三台主机都</strong>cd进入到exec目录下</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cd /opt/azkaban/azkaban-exec/</span><br></pre></td></tr></table></figure><p><strong>三台主机都</strong>执行命令启动executor-server，注意，必须先cd到exec目录下</p><p>这里启动要加载全局配置文件，使用的是相对路径，只有来到&#x2F;opt&#x2F;azkaban&#x2F;azkaban-exec&#x2F;，才能通过该相对路径找到全局配置文件，才能成功启动进程。</p><p>可以在azkaban.properties文件中修改配置，将<code>executor.global.properties=conf/global.properties</code>中的相对路径修改为绝对路径即可在任意位置启动进程</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/start-exec.sh</span><br></pre></td></tr></table></figure><p>注意：如果在&#x2F;opt&#x2F;azkaban&#x2F;azkaban-exec 目录下出现 <strong>executor.port</strong> 文件，说明启动成功</p><p>激活executor，<code>注意主机名</code>，结果都是 {“status”:”success”}，则激活成功</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">curl -G &quot;node:12321/executor?action=activate&quot; &amp;&amp; echo</span><br><span class="line">curl -G &quot;node1:12321/executor?action=activate&quot; &amp;&amp; echo</span><br><span class="line">curl -G &quot;node2:12321/executor?action=activate&quot; &amp;&amp; echo</span><br></pre></td></tr></table></figure><p>查看进程</p><p><img src="https://flyohh.cloud/blog_img/2023/05/16/64633418b7290.png" alt="jps查看进程"></p><h2 id="配置WebServer"><a href="#配置WebServer" class="headerlink" title="配置WebServer"></a>配置WebServer</h2><p>编辑 azkaban.properties</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim /opt/azkaban/azkaban-web/conf/azkaban.properties</span><br></pre></td></tr></table></figure><p>修改如下配置项</p><ul><li><p>default.timezone.id&#x3D;<code>Asia/Shanghai</code></p></li><li><p>mysql.host&#x3D;<code>node</code></p></li><li><p>mysql.password&#x3D;<code>000000</code></p></li><li><p>azkaban.executorselector.filters&#x3D;StaticRemainingFlowSize,CpuStatus</p><p>这里是删掉<strong>MinimumFreeMemory</strong>，否则它会认为集群资源不够，不执行操作</p></li></ul><p>编辑azkaban-users.xml</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim /opt/azkaban/azkaban-web/conf/azkaban-users.xml</span><br></pre></td></tr></table></figure><p>加入root用户，密码333，角色管理员</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">user</span> <span class="attr">password</span>=<span class="string">&quot;333&quot;</span> <span class="attr">roles</span>=<span class="string">&quot;admin&quot;</span> <span class="attr">username</span>=<span class="string">&quot;root&quot;</span>/&gt;</span></span><br></pre></td></tr></table></figure><p>来到&#x2F;opt&#x2F;azkaban&#x2F;azkaban-web目录，启动进程</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cd /opt/azkaban/azkaban-web</span><br><span class="line">./bin/start-web.sh</span><br></pre></td></tr></table></figure><p>访问<a href="http://node:8081/">网页</a>，并用root用户登陆</p><p><code>友情提示，每次启动executor服务之后，都要进行激活，否则web起不起来</code></p><h1 id="基本使用"><a href="#基本使用" class="headerlink" title="基本使用"></a>基本使用</h1><h2 id="HelloWorld-案例"><a href="#HelloWorld-案例" class="headerlink" title="HelloWorld 案例"></a>HelloWorld 案例</h2><ol><li><p>新建两个文件</p><p>在windows环境新建一个 azkaban.project 文件，内容如下，注意冒号是英文，冒号后面有空格</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">azkaban-flow-version: 2.0</span><br></pre></td></tr></table></figure><p>指定flow版本为2.0，2.0则是下面这种yaml格式，1.0是key&#x3D;value的格式</p><p>在windows环境新建一个 basic.flow 文件，内容如下，注意冒号是英文，冒号后面有空格</p><p>不懂这种格式的点击 <a href="https://www.runoob.com/w3cnote/yaml-intro.html">YAML 入门教程 | 菜鸟教程 (runoob.com)</a>)</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">nodes:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">jobA</span></span><br><span class="line">    <span class="attr">type:</span> <span class="string">command</span></span><br><span class="line">    <span class="attr">config:</span></span><br><span class="line">      <span class="attr">command:</span> <span class="string">echo</span> <span class="string">&quot;HELLO WORLD&quot;</span></span><br></pre></td></tr></table></figure><ul><li>name：job名称</li><li>type：job类型，command表示命令类型</li><li>config：job配置项</li></ul></li><li><p>将两个文件压缩到zip文件，文件名称必须英文</p><p><img src="https://flyohh.cloud/blog_img/2023/05/17/64643593776a6.png" alt="压缩包"></p></li><li><p>创建新项目，指定项目名称和介绍</p><p><img src="https://flyohh.cloud/blog_img/2023/05/17/64643621d80b7.png" alt="添加项目"></p><p>这里也要写英文，中文报错</p></li><li><p>上传压缩文件</p><p><img src="https://flyohh.cloud/blog_img/2023/05/17/64643724dc2a5.png" alt="上传压缩文件"></p></li><li><p>执行任务流</p><p><img src="https://flyohh.cloud/blog_img/2023/05/17/64643c967120b.png" alt="执行任务流"></p><p><img src="https://flyohh.cloud/blog_img/2023/05/17/64643d1f61289.png" alt="执行"></p><p><img src="https://flyohh.cloud/blog_img/2023/05/17/64643cfb850b4.png" alt="执行"></p></li><li><p>查看运行结果</p></li></ol><p><img src="https://flyohh.cloud/blog_img/2023/05/17/64643d89f1853.png" alt="查看日志"></p><p><img src="https://flyohh.cloud/blog_img/2023/05/17/64643db281481.png" alt="运行结果"></p><h2 id="作业依赖案例"><a href="#作业依赖案例" class="headerlink" title="作业依赖案例"></a>作业依赖案例</h2><p><code>需求：三个作业，第三个作业需要依赖前两个作业</code></p><ol><li><p>修改basic.flow文件内容</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">nodes:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">jobA</span></span><br><span class="line">    <span class="attr">type:</span> <span class="string">command</span></span><br><span class="line">    <span class="attr">config:</span></span><br><span class="line">      <span class="attr">command:</span> <span class="string">echo</span> <span class="string">&quot;HELLO WORLD AAA&quot;</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">jobB</span></span><br><span class="line">    <span class="attr">type:</span> <span class="string">command</span></span><br><span class="line">    <span class="attr">config:</span></span><br><span class="line">      <span class="attr">command:</span> <span class="string">echo</span> <span class="string">&quot;HELLO WORLD BBB&quot;</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">jobC</span></span><br><span class="line">    <span class="attr">type:</span> <span class="string">command</span></span><br><span class="line">    <span class="attr">dependsOn:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">jobA</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">jobB</span></span><br><span class="line">    <span class="attr">config:</span></span><br><span class="line">      <span class="attr">command:</span> <span class="string">echo</span> <span class="string">&quot;HELLO WORLD CCC&quot;</span></span><br></pre></td></tr></table></figure><p>第三个作业加上dependsOn参数，指定该作业依赖的其他作业的名称</p><p>看不懂的看下转换成json格式是啥样，如下</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;nodes&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span><span class="punctuation">&#123;</span></span><br><span class="line">            <span class="attr">&quot;name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;jobA&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;type&quot;</span><span class="punctuation">:</span> <span class="string">&quot;command&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;config&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span><span class="attr">&quot;command&quot;</span><span class="punctuation">:</span> <span class="string">&quot;echo \&quot;HELLO WORLD AAA\&quot;&quot;</span><span class="punctuation">&#125;</span></span><br><span class="line">        <span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="punctuation">&#123;</span></span><br><span class="line">            <span class="attr">&quot;name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;jobB&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;type&quot;</span><span class="punctuation">:</span> <span class="string">&quot;command&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;config&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span><span class="attr">&quot;command&quot;</span><span class="punctuation">:</span> <span class="string">&quot;echo \&quot;HELLO WORLD BBB\&quot;&quot;</span><span class="punctuation">&#125;</span></span><br><span class="line">        <span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="punctuation">&#123;</span></span><br><span class="line">            <span class="attr">&quot;name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;jobC&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;type&quot;</span><span class="punctuation">:</span> <span class="string">&quot;command&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;dependsOn&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span><span class="string">&quot;jobA&quot;</span><span class="punctuation">,</span> <span class="string">&quot;jobB&quot;</span><span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;config&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span><span class="attr">&quot;command&quot;</span><span class="punctuation">:</span> <span class="string">&quot;echo \&quot;HELLO WORLD CCC\&quot;&quot;</span><span class="punctuation">&#125;</span></span><br><span class="line">        <span class="punctuation">&#125;</span><span class="punctuation">]</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure><p>还是不懂的，去学下yaml语法，<a href="https://www.runoob.com/w3cnote/yaml-intro.html">YAML 入门教程 | 菜鸟教程 (runoob.com)</a>)</p></li><li><p>写好之后还是把两个文件打包，创建新项目，上传压缩文件，结果如图</p><p><img src="https://flyohh.cloud/blog_img/2023/05/17/64644c877a9e9.png" alt="上传文件结果"></p></li><li><p>运行和运行结果如图</p><p><img src="https://flyohh.cloud/blog_img/2023/05/17/64646d67c998d.png" alt="运行"></p><p><img src="https://flyohh.cloud/blog_img/2023/05/17/64646e19f27b1.png" alt="执行结果"></p></li></ol><h2 id="自动失败重试案例"><a href="#自动失败重试案例" class="headerlink" title="自动失败重试案例"></a>自动失败重试案例</h2><p><code>需求：作业A正常执行，作业B搞个报错的然后自动重试3次，作业C依赖作业B，作业D搞个报错的没有重试机制然后依赖作业C</code></p><ol><li><p>修改basic.flow文件内容</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">nodes:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">jobA</span></span><br><span class="line">    <span class="attr">type:</span> <span class="string">command</span></span><br><span class="line">    <span class="attr">config:</span></span><br><span class="line">      <span class="attr">command:</span> <span class="string">echo</span> <span class="string">&quot;HELLO WORLD AAA&quot;</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">jobB</span></span><br><span class="line">    <span class="attr">type:</span> <span class="string">command</span></span><br><span class="line">    <span class="attr">config:</span></span><br><span class="line">      <span class="attr">command:</span> <span class="string">sh</span> <span class="string">/not_exists.sh</span>  <span class="comment"># 该脚本根本不存在所以肯定错误</span></span><br><span class="line">      <span class="attr">retries:</span> <span class="number">3</span>  <span class="comment"># 重试次数</span></span><br><span class="line">      <span class="attr">retry.backoff:</span> <span class="number">3000</span>  <span class="comment"># 重试时间间隔3000ms</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">jobC</span></span><br><span class="line">    <span class="attr">type:</span> <span class="string">command</span></span><br><span class="line">    <span class="attr">dependsOn:</span> </span><br><span class="line">      <span class="bullet">-</span> <span class="string">jobB</span>  <span class="comment"># 作业C依赖作业B</span></span><br><span class="line">    <span class="attr">config:</span></span><br><span class="line">      <span class="attr">command:</span> <span class="string">echo</span> <span class="string">&quot;HELLO WORLD CCC&quot;</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">jobD</span></span><br><span class="line">    <span class="attr">type:</span> <span class="string">command</span></span><br><span class="line">    <span class="attr">dependsOn:</span> </span><br><span class="line">      <span class="bullet">-</span> <span class="string">jobC</span>  <span class="comment"># 依赖作业C</span></span><br><span class="line">    <span class="attr">config:</span></span><br><span class="line">      <span class="attr">command:</span> <span class="string">sh</span> <span class="string">/not_exists.sh</span></span><br></pre></td></tr></table></figure><p>也可以在全局配置对象中配置重试策略，那么就会应用到所有作业中</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">nodes:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">jobA</span></span><br><span class="line">    <span class="attr">type:</span> <span class="string">command</span></span><br><span class="line">    <span class="attr">config:</span></span><br><span class="line">      <span class="attr">command:</span> <span class="string">echo</span> <span class="string">&quot;HELLO WORLD AAA&quot;</span></span><br><span class="line"><span class="comment"># 和nodes同级的config为全局配置项</span></span><br><span class="line"><span class="attr">config:</span></span><br><span class="line">  <span class="attr">retries:</span> <span class="number">3</span> </span><br><span class="line">  <span class="attr">retry.backoff:</span> <span class="number">3000</span></span><br></pre></td></tr></table></figure></li><li><p>重新打包，创建项目，提交压缩包，执行图如下</p><p><img src="https://flyohh.cloud/blog_img/2023/05/17/646481c2b9082.png" alt="执行流程图"></p></li><li><p>执行结果</p><p><img src="https://flyohh.cloud/blog_img/2023/05/17/6464840067615.png" alt="执行结果"></p></li></ol><h2 id="手动失败重试案例"><a href="#手动失败重试案例" class="headerlink" title="手动失败重试案例"></a>手动失败重试案例</h2><ol><li><p>来到web页面</p><p><img src="https://flyohh.cloud/blog_img/2023/05/17/64648806e2553.png" alt="历史记录"></p></li><li><p>重新执行</p><p><img src="https://flyohh.cloud/blog_img/2023/05/17/646488563d7a8.png" alt="重新执行"></p></li><li><p>跳过JobB</p><p><img src="https://flyohh.cloud/blog_img/2023/05/17/6464893edbf5c.png" alt="跳过JobB"></p></li><li><p>执行结果</p><p><img src="https://flyohh.cloud/blog_img/2023/05/17/64648a1b25184.png" alt="执行结果"></p></li></ol><p><strong>手动失败重试的灵魂在于：</strong><code>手动disable或enable某些作业，可以跳过那些已经执行成功的作业，从上次失败的位置开始再重新执行</code></p><h1 id="进阶使用"><a href="#进阶使用" class="headerlink" title="进阶使用"></a>进阶使用</h1><h2 id="JavaProcess-类型案例"><a href="#JavaProcess-类型案例" class="headerlink" title="JavaProcess 类型案例"></a>JavaProcess 类型案例</h2><ol><li><p>想办法弄个jar包来运行</p><p><img src="https://flyohh.cloud/blog_img/2023/05/17/6464c328c7003.png" alt="打jar包"></p></li><li><p>修改basic.flow文件内容</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">nodes:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">JavaDemo</span></span><br><span class="line">    <span class="attr">type:</span> <span class="string">javaprocess</span></span><br><span class="line">    <span class="attr">config:</span></span><br><span class="line">      <span class="attr">Xms:</span> <span class="string">96M</span></span><br><span class="line">      <span class="attr">Xmx:</span> <span class="string">200M</span></span><br><span class="line">      <span class="attr">java.class:</span> <span class="string">azkaban.AzkabanDemo</span></span><br><span class="line">      <span class="attr">main.args:</span> <span class="literal">no</span> <span class="string">张三</span></span><br></pre></td></tr></table></figure><p>type 类型为 javaprocess，可用的配置为：</p><ul><li>Xms：最小堆</li><li>Xmx：最大堆</li><li>classpath：类路径，不指定时为以basic.flow文件为当前路径</li><li>java.class：要运行的 Java 对象，其中必须包含 Main 方法</li><li>main.args：main 方法的参数，多个参数用空格隔开</li></ul></li><li><p><strong>将azkaban.project、basic.flow和jar包打成压缩包</strong>，上传到web页面新项目，运行项目，查看结果没有任何问题</p></li></ol><p><img src="https://flyohh.cloud/blog_img/2023/05/17/6464c51b11ca3.png" alt="查看结果"></p><h2 id="条件工作流案例"><a href="#条件工作流案例" class="headerlink" title="条件工作流案例"></a>条件工作流案例</h2><p><strong>条件工作流功能允许用户自定义执行条件来决定是否运行某些Job，条件工作流的关键字是condition</strong></p><h3 id="运行时参数案例"><a href="#运行时参数案例" class="headerlink" title="运行时参数案例"></a>运行时参数案例</h3><p><strong>原理</strong></p><ol><li>父 Job 将参数写入 JOB_OUTPUT_PROP_FILE 环境变量所指向的文件</li><li>子 Job 使用 <code>$&#123;jobName:param&#125;</code>来获取父 Job 输出的参数并判断是否执行</li></ol><p><strong>需求</strong></p><ol><li>JobA 执行一个 shell 脚本。</li><li>JobB 执行一个 shell 脚本，但 JobB 不需要每天都执行，而只需要每个周一执行。</li></ol><p><strong>开始</strong></p><ol><li><p>新建JobA.sh</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">!/bin/bash</span></span><br><span class="line">echo &quot;JobA 业务代码执行&quot;</span><br><span class="line">wk=`date +%w`  # 这里可以获取今天是星期几，如周一返回1、周日返回0</span><br><span class="line">echo &quot;$wk&quot;</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">写入必须是json格式的，这里双引号按照语法肯定是要转义的所以加上斜杠</span></span><br><span class="line">echo &quot;&#123;\&quot;wk\&quot;:$wk&#125;&quot; &gt; $JOB_OUTPUT_PROP_FILE</span><br></pre></td></tr></table></figure></li><li><p>新建JobB.sh</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">!/bin/bash</span></span><br><span class="line">echo &quot;JobB 业务代码执行&quot;</span><br></pre></td></tr></table></figure></li><li><p>修改basic.flow文件内容</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">nodes:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">JobA</span></span><br><span class="line">    <span class="attr">type:</span> <span class="string">command</span></span><br><span class="line">    <span class="attr">config:</span></span><br><span class="line">      <span class="attr">command:</span> <span class="string">sh</span> <span class="string">JobA.sh</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">JobB</span></span><br><span class="line">    <span class="attr">type:</span> <span class="string">command</span></span><br><span class="line">    <span class="attr">config:</span></span><br><span class="line">      <span class="attr">command:</span> <span class="string">sh</span> <span class="string">JobB.sh</span></span><br><span class="line">    <span class="attr">dependsOn:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">JobA</span></span><br><span class="line">    <span class="comment"># 使用 condition 关键词，指定是否执行JobB的条件</span></span><br><span class="line">    <span class="comment"># $&#123;job名称:参数名&#125; 获取写入的值</span></span><br><span class="line">    <span class="attr">condition:</span> <span class="string">$&#123;JobA:wk&#125;</span> <span class="string">==</span> <span class="number">1</span></span><br></pre></td></tr></table></figure></li><li><p><code>将azkaban.project、basic.flow、JobA.sh和JobB.sh打成压缩包</code>，新建项目上传执行结果和JobA日志</p><p><img src="https://flyohh.cloud/blog_img/2023/05/17/6464d6dcbcfee.png" alt="执行结果"></p><p><img src="https://flyohh.cloud/blog_img/2023/05/17/6464d70c1b5d3.png" alt="Job日志"></p></li></ol><h3 id="预定义宏案例"><a href="#预定义宏案例" class="headerlink" title="预定义宏案例"></a>预定义宏案例</h3><p>Azkaban 中预置了几个特殊的判断条件，称为预定义宏。<code>预定义宏会根据所有父 Job 的完成情况进行判断，再决定是否执行</code>。可用的预定义宏如下：</p><ul><li>all_success: 表示父 Job 全部成功才执行(默认)</li><li>all_done：表示父 Job 全部完成才执行</li><li>all_failed：表示父 Job 全部失败才执行</li><li>one_success：表示父 Job 至少一个成功才执行</li><li>one_failed：表示父 Job 至少一个失败才执行</li></ul><p><strong>需求</strong></p><p>JobC依赖JobAB，AB成功一个就可以执行C</p><p><strong>开始</strong></p><ol><li><p>修改basic.flow文件内容</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">nodes:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">JobA</span></span><br><span class="line">    <span class="attr">type:</span> <span class="string">command</span></span><br><span class="line">    <span class="attr">config:</span></span><br><span class="line">      <span class="attr">command:</span> <span class="string">echo</span> <span class="string">&quot;JobA OK&quot;</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">JobB</span></span><br><span class="line">    <span class="attr">type:</span> <span class="string">command</span></span><br><span class="line">    <span class="attr">config:</span></span><br><span class="line">      <span class="attr">command:</span> <span class="string">sh</span> <span class="string">no.sh</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">JobC</span></span><br><span class="line">    <span class="attr">type:</span> <span class="string">command</span></span><br><span class="line">    <span class="attr">config:</span></span><br><span class="line">      <span class="attr">command:</span> <span class="string">echo</span> <span class="string">&quot;JobC OK&quot;</span></span><br><span class="line">    <span class="attr">dependsOn:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">JobA</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">JobB</span></span><br><span class="line">    <span class="attr">condition:</span> <span class="string">one_success</span></span><br></pre></td></tr></table></figure></li><li><p><code>将azkaban.project和basic.flow打成压缩包</code>，新建项目上传执行结果</p><p><img src="https://flyohh.cloud/blog_img/2023/05/18/6465773b199f1.png" alt="预定义宏的结果"></p></li></ol><h2 id="定时执行案例"><a href="#定时执行案例" class="headerlink" title="定时执行案例"></a>定时执行案例</h2><p>Azkaban 可以定时执行工作流。在执行工作流时候，选择左下角 Schedule</p><p><img src="https://flyohh.cloud/blog_img/2023/05/18/64657ac8db80d.png" alt="定时工作流"></p><p>自己可以多玩玩，试试，下面会根据你写的告诉你什么时候会执行工作，这里给点我的测试供参考</p><p><img src="https://flyohh.cloud/blog_img/2023/05/18/64657a8f6b4ef.png" alt="demo"></p><p>选好执行规则之后<strong>滑到最下面点击绿色的schedule</strong>，我的执行结果如下</p><p><img src="https://flyohh.cloud/blog_img/2023/05/18/64657ec61ac9b.png" alt="执行结果"></p><h2 id="多-Executor-模式注意事项"><a href="#多-Executor-模式注意事项" class="headerlink" title="多 Executor 模式注意事项"></a>多 Executor 模式注意事项</h2><p>Azkaban 多 Executor 模式是指，在集群中多个节点部署 Executor。在这种模式下，Azkaban web Server 会根据策略，选取其中一个 Executor 去执行任务。</p><p>但是有个情况是，如果我要运行的jar包在node节点，而实际执行的时候选取的是其他节点，那么就必然不会执行成功。</p><p><strong>解决方案</strong></p><p><code>方案一</code>：指定特定的 ExecutorID 执行任务。</p><p>在 MySQL 中 azkaban 数据库 executors 表中，查询 node 的 ExecutorId。</p><p><img src="https://flyohh.cloud/blog_img/2023/05/18/646582534b92b.png" alt="查询id"></p><p>执行前加入useExecutor属性，指定id为上面查询出来的</p><p><img src="https://flyohh.cloud/blog_img/2023/05/18/6465837343958.png" alt="加入useExecutor属性"></p><p><code>方案二</code>：在 Executor 所在所有节点部署任务所需脚本和应用。</p>]]></content>
      
      
      <categories>
          
          <category> 学习文档 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 大数据 </tag>
            
            <tag> Azkaban </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>离线数据处理部分的教学</title>
      <link href="/2023/03/12/%E7%94%B5%E5%95%86%E4%BE%8B%E9%A2%98%E6%96%87%E6%A1%A3/"/>
      <url>/2023/03/12/%E7%94%B5%E5%95%86%E4%BE%8B%E9%A2%98%E6%96%87%E6%A1%A3/</url>
      
        <content type="html"><![CDATA[<p>2023年楚怡杯湖南省高职院校技能竞赛大数据赛项关于电商例题中离线数据处理部分的解题思路和代码<br>版权：flyohh</p><h1 id="模拟Hive存量数据"><a href="#模拟Hive存量数据" class="headerlink" title="模拟Hive存量数据"></a>模拟Hive存量数据</h1><h2 id="模拟ODS层"><a href="#模拟ODS层" class="headerlink" title="模拟ODS层"></a>模拟ODS层</h2><ol><li><p>思路</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">1、共有 customer_inf、product_info、order_master、order_detail 四张表。</span><br><span class="line">2、每张表选择一个 modified_time 值，将这个值作为分割的时间节点。</span><br><span class="line">3、小于等于这个时间节点的数据全部提前抽取出来做ods层的存量表。</span><br><span class="line">4、大于这个时间节点的数据，作为题目要求的增量抽取的数据。</span><br></pre></td></tr></table></figure></li><li><p>spark对象</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> spark: <span class="type">SparkSession</span> = <span class="type">SparkSession</span>.builder()</span><br><span class="line">    .master(<span class="string">&quot;local[*]&quot;</span>)</span><br><span class="line">    .appName(<span class="string">&quot;mock&quot;</span>)</span><br><span class="line">    <span class="comment">// 使用旧的格式化写入器，新版的和hive cli不兼容</span></span><br><span class="line">    <span class="comment">// 如果不设置，那么无法在hive cli查询数据</span></span><br><span class="line">    .config(<span class="string">&quot;spark.sql.parquet.writeLegacyFormat&quot;</span>, <span class="string">&quot;true&quot;</span>)</span><br><span class="line">    .enableHiveSupport</span><br><span class="line">    .getOrCreate</span><br></pre></td></tr></table></figure></li><li><p>先定义一个mysql的基本配置项对象，用Map装</p><ul><li><p>因为spark读取写入的options()方法接受的是Map对象，源码如下</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">options</span></span>(options: <span class="type">Map</span>[<span class="type">String</span>, <span class="type">String</span>]): <span class="type">DataFrameReader</span> = &#123;</span><br><span class="line">   <span class="keyword">this</span>.extraOptions ++= options</span><br><span class="line">   <span class="keyword">this</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>基本配置有三项：url、user、password，如下</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="keyword">val</span> m_opt = <span class="type">Map</span>(</span><br><span class="line">   <span class="string">&quot;url&quot;</span> -&gt; <span class="string">&quot;jdbc:mysql://bigdata1:3306/ds_db01?useSSL=false&quot;</span>,</span><br><span class="line">   <span class="string">&quot;user&quot;</span> -&gt; <span class="string">&quot;root&quot;</span>,</span><br><span class="line">   <span class="string">&quot;password&quot;</span> -&gt; <span class="string">&quot;123456&quot;</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure></li><li><p>据我所知，query和dbtable为二选一(还有没有别的就不知道了)，query和dbtable不能同时传进options方法中，否则报错</p><p>query：指定查询语句即sql语句</p><p>dbtable：指定数据库和表名，在url已经定义里数据库名，所以直接传入表名即可</p></li></ul></li><li><p>spark读取mysql数据</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 存量数据 &lt; 2022-08-22 00:00:00 &lt;= 增量数据 </span></span><br><span class="line"><span class="keyword">val</span> sql: <span class="type">String</span> = <span class="string">&quot;select * from customer_inf where modified_time &lt; &#x27;2022-08-22 00:00:00&#x27;&quot;</span></span><br><span class="line"><span class="comment">// Map是不可变集，无法直接给 m_opt 对象添加键值对</span></span><br><span class="line"><span class="comment">// 使用 ++ 连接两个Map组合成一个新的Map</span></span><br><span class="line"><span class="keyword">val</span> opts = <span class="type">Map</span>(<span class="string">&quot;query&quot;</span> -&gt; sql) ++ m_opt</span><br><span class="line"><span class="comment">// 指定jdbc格式，传入配置项，执行加载</span></span><br><span class="line"><span class="keyword">val</span> df: <span class="type">DataFrame</span> = spark</span><br><span class="line">  .read</span><br><span class="line">  .format(<span class="string">&quot;jdbc&quot;</span>)</span><br><span class="line">  .options(opts)</span><br><span class="line">  .load</span><br></pre></td></tr></table></figure></li><li><p>存入hive的ods层</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">df</span><br><span class="line">  <span class="comment">// 新增列，值为最大时间的年月日</span></span><br><span class="line">  .withColumn(<span class="string">&quot;etl_date&quot;</span>, lit(<span class="string">&quot;20220821&quot;</span>))</span><br><span class="line">  <span class="comment">// 写入</span></span><br><span class="line">  .write</span><br><span class="line">  <span class="comment">// 指定分区</span></span><br><span class="line">  .partitionBy(<span class="string">&quot;etl_date&quot;</span>)</span><br><span class="line">  <span class="comment">// 覆盖写入</span></span><br><span class="line">  .mode(<span class="string">&quot;overwrite&quot;</span>)</span><br><span class="line">  <span class="comment">// 数据库.</span></span><br><span class="line">  .saveAsTable(<span class="string">&quot;ods.customer_inf&quot;</span>)</span><br></pre></td></tr></table></figure></li><li><p>代码如下</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> mock</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.sql.functions.lit</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">MockODS</span> </span>&#123;</span><br><span class="line">    </span><br><span class="line">  <span class="comment">// 定义好mysql的基本配置项</span></span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">val</span> m_opt = <span class="type">Map</span>(</span><br><span class="line">    <span class="string">&quot;url&quot;</span> -&gt; <span class="string">&quot;jdbc:mysql://bigdata1:3306/ds_db01?useSSL=false&quot;</span>,</span><br><span class="line">    <span class="string">&quot;user&quot;</span> -&gt; <span class="string">&quot;root&quot;</span>,</span><br><span class="line">    <span class="string">&quot;password&quot;</span> -&gt; <span class="string">&quot;123456&quot;</span></span><br><span class="line">  )</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="keyword">val</span> spark: <span class="type">SparkSession</span> = <span class="type">SparkSession</span>.builder()</span><br><span class="line">      .master(<span class="string">&quot;local[*]&quot;</span>)</span><br><span class="line">      .appName(<span class="string">&quot;mock&quot;</span>)</span><br><span class="line">      <span class="comment">// 使用旧的格式化写入器，新版的和hive cli不兼容</span></span><br><span class="line">      <span class="comment">// 如果不设置，那么无法在hive cli查询数据</span></span><br><span class="line">      .config(<span class="string">&quot;spark.sql.parquet.writeLegacyFormat&quot;</span>, <span class="string">&quot;true&quot;</span>)</span><br><span class="line">      .enableHiveSupport</span><br><span class="line">      .getOrCreate</span><br><span class="line">    <span class="comment">// 如果没有数据库则创建</span></span><br><span class="line">    spark.sql(<span class="string">&quot;create database if not exists ods&quot;</span>)</span><br><span class="line">    spark.sql(<span class="string">&quot;create database if not exists dwd&quot;</span>)</span><br><span class="line">    spark.sql(<span class="string">&quot;create database if not exists dws&quot;</span>)</span><br><span class="line"></span><br><span class="line">    spark</span><br><span class="line">      .read</span><br><span class="line">      .format(<span class="string">&quot;jdbc&quot;</span>)</span><br><span class="line">      .options(<span class="type">Map</span>(<span class="string">&quot;query&quot;</span> -&gt; <span class="string">&quot;select * from customer_inf where modified_time &lt; &#x27;2022-08-22 00:00:00&#x27;&quot;</span> ) ++ m_opt)</span><br><span class="line">      .load</span><br><span class="line">      .withColumn(<span class="string">&quot;etl_date&quot;</span>, lit(<span class="string">&quot;20220821&quot;</span>))</span><br><span class="line">      .write</span><br><span class="line">      .partitionBy(<span class="string">&quot;etl_date&quot;</span>)</span><br><span class="line">      .mode(<span class="string">&quot;overwrite&quot;</span>)</span><br><span class="line">      .saveAsTable(<span class="string">&quot;ods.customer_inf&quot;</span>)</span><br><span class="line"></span><br><span class="line">    spark</span><br><span class="line">      .read</span><br><span class="line">      .format(<span class="string">&quot;jdbc&quot;</span>)</span><br><span class="line">      .options(<span class="type">Map</span>(<span class="string">&quot;query&quot;</span> -&gt; <span class="string">&quot;select * from product_info where modified_time &lt; &#x27;2022-09-05 00:00:00&#x27;&quot;</span> ) ++ m_opt)</span><br><span class="line">      .load</span><br><span class="line">      .withColumn(<span class="string">&quot;etl_date&quot;</span>, lit(<span class="string">&quot;20220904&quot;</span>))</span><br><span class="line">      .write</span><br><span class="line">      .partitionBy(<span class="string">&quot;etl_date&quot;</span>)</span><br><span class="line">      .mode(<span class="string">&quot;overwrite&quot;</span>)</span><br><span class="line">      .saveAsTable(<span class="string">&quot;ods.product_info&quot;</span>)</span><br><span class="line"></span><br><span class="line">    spark</span><br><span class="line">      .read</span><br><span class="line">      .format(<span class="string">&quot;jdbc&quot;</span>)</span><br><span class="line">      .options(<span class="type">Map</span>(<span class="string">&quot;query&quot;</span> -&gt; <span class="string">&quot;select * from order_master where modified_time &lt; &#x27;2022-05-23 00:00:00&#x27;&quot;</span> ) ++ m_opt)</span><br><span class="line">      .load</span><br><span class="line">      .withColumn(<span class="string">&quot;etl_date&quot;</span>, lit(<span class="string">&quot;20220522&quot;</span>))</span><br><span class="line">      .write</span><br><span class="line">      .partitionBy(<span class="string">&quot;etl_date&quot;</span>)</span><br><span class="line">      .mode(<span class="string">&quot;overwrite&quot;</span>)</span><br><span class="line">      .saveAsTable(<span class="string">&quot;ods.order_master&quot;</span>)</span><br><span class="line"></span><br><span class="line">    spark</span><br><span class="line">      .read</span><br><span class="line">      .format(<span class="string">&quot;jdbc&quot;</span>)</span><br><span class="line">      .options(<span class="type">Map</span>(<span class="string">&quot;query&quot;</span> -&gt; <span class="string">&quot;select * from order_detail where modified_time &lt; &#x27;2022-03-20 00:00:00&#x27;&quot;</span> ) ++ m_opt)</span><br><span class="line">      .load</span><br><span class="line">      .withColumn(<span class="string">&quot;etl_date&quot;</span>, lit(<span class="string">&quot;20220319&quot;</span>))</span><br><span class="line">      .write</span><br><span class="line">      .partitionBy(<span class="string">&quot;etl_date&quot;</span>)</span><br><span class="line">      .mode(<span class="string">&quot;overwrite&quot;</span>)</span><br><span class="line">      .saveAsTable(<span class="string">&quot;ods.order_detail&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 6601</span></span><br><span class="line">    spark.sql(<span class="string">&quot;select count(1) from ods.customer_inf&quot;</span>).show</span><br><span class="line">    <span class="comment">// 2648</span></span><br><span class="line">    spark.sql(<span class="string">&quot;select count(1) from ods.product_info&quot;</span>).show</span><br><span class="line">    <span class="comment">// 325861</span></span><br><span class="line">    spark.sql(<span class="string">&quot;select count(1) from ods.order_master&quot;</span>).show</span><br><span class="line">    <span class="comment">// 259</span></span><br><span class="line">    spark.sql(<span class="string">&quot;select count(1) from ods.order_detail&quot;</span>).show</span><br><span class="line">      </span><br><span class="line">    <span class="comment">/*</span></span><br><span class="line"><span class="comment">      | max(modified_time) 2022-08-21 23:59:44|</span></span><br><span class="line"><span class="comment">      | max(modified_time) 2022-09-04 23:59:45|</span></span><br><span class="line"><span class="comment">      | max(modified_time) 2022-05-22 23:54:18|</span></span><br><span class="line"><span class="comment">      | max(modified_time) 2022-03-19 23:44:53|</span></span><br><span class="line"><span class="comment">    */</span></span><br><span class="line">    spark.sql(<span class="string">&quot;select max(modified_time) from ods.customer_inf&quot;</span>).show</span><br><span class="line">    spark.sql(<span class="string">&quot;select max(modified_time) from ods.product_info&quot;</span>).show</span><br><span class="line">    spark.sql(<span class="string">&quot;select max(modified_time) from ods.order_master&quot;</span>).show</span><br><span class="line">    spark.sql(<span class="string">&quot;select max(modified_time) from ods.order_detail&quot;</span>).show</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ol><h2 id="模拟DWD层"><a href="#模拟DWD层" class="headerlink" title="模拟DWD层"></a>模拟DWD层</h2><ol><li><p>思路</p><ul><li>题目中有：抽取ods库中customer_inf表中任务一生成的分区数据，并结合dim_customer_inf最新分区现有的数据，根据customer_id合并数据到dwd库中dim_customer_inf的分区表</li><li>即：dwd层已有dim_customer_inf表，有若干分区，只需要拿出最新的那个分区数据，ods层拿出任务一生成的分区，这两个分区进行合并然后插入到dwd层dim_customer_inf表</li><li>那么以下要做的就是，抽取ods层旧分区的数据(就是上面模拟的分区数据)，再抽取ods层除了旧分区以外的所有数据进行抽样添加分区字段且值为任务一生成的分区字段的值，然后将两部分数据联合起来，作为dwd的模拟数据。</li></ul></li><li><p>spark对象</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> spark: <span class="type">SparkSession</span> = <span class="type">SparkSession</span>.builder()</span><br><span class="line">    .master(<span class="string">&quot;local[*]&quot;</span>)</span><br><span class="line">    .appName(<span class="string">&quot;mock&quot;</span>)</span><br><span class="line">    <span class="comment">// 使用旧的格式化写入器，新版的和hive cli不兼容</span></span><br><span class="line">    <span class="comment">// 如果不设置，那么无法在hive cli查询数据</span></span><br><span class="line">    .config(<span class="string">&quot;spark.sql.parquet.writeLegacyFormat&quot;</span>, <span class="string">&quot;true&quot;</span>)</span><br><span class="line">    .enableHiveSupport</span><br><span class="line">    .getOrCreate</span><br></pre></td></tr></table></figure></li><li><p>写好mysql基本配置</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="keyword">val</span> m_opt = <span class="type">Map</span>(</span><br><span class="line">  <span class="string">&quot;url&quot;</span> -&gt; <span class="string">&quot;jdbc:mysql://bigdata1:3306/ds_db01?useSSL=false&quot;</span>,</span><br><span class="line">  <span class="string">&quot;user&quot;</span> -&gt; <span class="string">&quot;root&quot;</span>,</span><br><span class="line">  <span class="string">&quot;password&quot;</span> -&gt; <span class="string">&quot;123456&quot;</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure></li><li><p>抽取旧分区数据</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> customer_inf = spark.table(<span class="string">&quot;ods.customer_inf&quot;</span>).where($<span class="string">&quot;etl_date&quot;</span> === <span class="string">&quot;20220821&quot;</span>)</span><br></pre></td></tr></table></figure></li><li><p>取出ods层旧分区中最大的时间</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> t1 = spark.sql(<span class="string">&quot;select max(modified_time) from ods.customer_inf where etl_date = &#x27;20220821&#x27;&quot;</span>).first.getTimestamp(<span class="number">0</span>)</span><br></pre></td></tr></table></figure></li><li><p>取出除了旧分区以外的所有数据进行抽样并联合旧分区数据</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> df: <span class="type">DataFrame</span> = spark</span><br><span class="line">  .read</span><br><span class="line">  .format(<span class="string">&quot;jdbc&quot;</span>)</span><br><span class="line">  .options(<span class="type">Map</span>(<span class="string">&quot;query&quot;</span> -&gt; <span class="string">s&quot;select * from customer_inf where modified_time &gt; &#x27;<span class="subst">$t1</span>&#x27;&quot;</span>) ++ m_opt)</span><br><span class="line">  .load</span><br><span class="line">  <span class="comment">// 添加分区列</span></span><br><span class="line">  .withColumn(<span class="string">&quot;etl_date&quot;</span>, lit(<span class="string">&quot;20230217&quot;</span>))</span><br><span class="line">  <span class="comment">// 抽取50%的数据</span></span><br><span class="line">  .sample(<span class="number">0.5</span>)</span><br><span class="line">  <span class="comment">// 根据列名联合数据</span></span><br><span class="line">  .unionByName(customer_inf)</span><br></pre></td></tr></table></figure></li><li><p>dwd层存量表的数据一定是要干净的，这里的数据要按照题目清洗的要求来</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">df</span><br><span class="line">  .withColumn(<span class="string">&quot;dwd_insert_user&quot;</span>, lit(<span class="string">&quot;user1&quot;</span>))</span><br><span class="line">  .withColumn(<span class="string">&quot;dwd_insert_time&quot;</span>, date_trunc(<span class="string">&quot;second&quot;</span>, current_timestamp()))</span><br><span class="line">  .withColumn(<span class="string">&quot;dwd_modify_user&quot;</span>, lit(<span class="string">&quot;user1&quot;</span>))</span><br><span class="line">  .withColumn(<span class="string">&quot;dwd_modify_time&quot;</span>, date_trunc(<span class="string">&quot;second&quot;</span>, current_timestamp()))</span><br><span class="line">  .write</span><br><span class="line">  .partitionBy(<span class="string">&quot;etl_date&quot;</span>)</span><br><span class="line">  .mode(<span class="string">&quot;overwrite&quot;</span>)</span><br><span class="line">  .saveAsTable(<span class="string">&quot;dwd.dim_customer_inf&quot;</span>)</span><br></pre></td></tr></table></figure></li><li><p>参照代码可以再模拟出dwd层dim_product_info的数据</p></li><li><p>至此，还剩两张表需要模拟，题目中有：将ods库中order_master表昨天的分区（任务一生成的分区）数据抽取到dwd库中fact_order_master的动态分区表。只看题目是没有说要合并操作的，那么我理解为：dwd层有若干分区数据但是没有最新分区的数据，需要从ods层抽取最新分区的数据并进行简单的数据清洗(没有数据合并操作)然后插入到dwd层表。</p></li><li><p>抽取order_master旧分区数据</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> order_master = spark.table(<span class="string">&quot;ods.order_master&quot;</span>).where($<span class="string">&quot;etl_date&quot;</span> === <span class="string">&quot;20220522&quot;</span>)</span><br></pre></td></tr></table></figure></li><li><p>dwd层数据应该是干净的所以应该做清洗再存进去</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">order_master</span><br><span class="line">  <span class="comment">// 取 create_time 值并将格式转换为 yyyyMMdd</span></span><br><span class="line">  .withColumn(<span class="string">&quot;create_time&quot;</span>, from_unixtime(unix_timestamp($<span class="string">&quot;create_time&quot;</span>, <span class="string">&quot;yyyyMMddHHmmss&quot;</span>), <span class="string">&quot;yyyyMMdd&quot;</span>))</span><br><span class="line">  <span class="comment">// 若ods表中有涉及到有时间类型，在dwd中都需转为timestamp类型</span></span><br><span class="line">  .withColumn(<span class="string">&quot;shipping_time&quot;</span>, from_unixtime(unix_timestamp($<span class="string">&quot;shipping_time&quot;</span>, <span class="string">&quot;yyyyMMddHHmmss&quot;</span>)))</span><br><span class="line">  .withColumn(<span class="string">&quot;pay_time&quot;</span>, from_unixtime(unix_timestamp($<span class="string">&quot;pay_time&quot;</span>, <span class="string">&quot;yyyyMMddHHmmss&quot;</span>)))</span><br><span class="line">  .withColumn(<span class="string">&quot;receive_time&quot;</span>, from_unixtime(unix_timestamp($<span class="string">&quot;receive_time&quot;</span>, <span class="string">&quot;yyyyMMddHHmmss&quot;</span>)))</span><br><span class="line">  <span class="comment">// 需要过滤掉city字段长度大于8</span></span><br><span class="line">  .where(length($<span class="string">&quot;city&quot;</span>) &lt;= <span class="number">8</span>)</span><br><span class="line">  <span class="comment">// 数据清洗</span></span><br><span class="line">  .withColumn(<span class="string">&quot;dwd_insert_user&quot;</span>, lit(<span class="string">&quot;user1&quot;</span>))</span><br><span class="line">  .withColumn(<span class="string">&quot;dwd_insert_time&quot;</span>, date_trunc(<span class="string">&quot;second&quot;</span>, current_timestamp()))</span><br><span class="line">  .withColumn(<span class="string">&quot;dwd_modify_user&quot;</span>, lit(<span class="string">&quot;user1&quot;</span>))</span><br><span class="line">  .withColumn(<span class="string">&quot;dwd_modify_time&quot;</span>, date_trunc(<span class="string">&quot;second&quot;</span>, current_timestamp()))</span><br><span class="line">  .write</span><br><span class="line">  .partitionBy(<span class="string">&quot;etl_date&quot;</span>)</span><br><span class="line">  .mode(<span class="string">&quot;overwrite&quot;</span>)</span><br><span class="line">  .saveAsTable(<span class="string">&quot;dwd.fact_order_master&quot;</span>)</span><br></pre></td></tr></table></figure></li><li><p>代码</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> mock</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.sql.functions._</span><br><span class="line"><span class="keyword">import</span> spark.implicits._</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">MockDWD</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">val</span> m_opt = <span class="type">Map</span>(</span><br><span class="line">    <span class="string">&quot;url&quot;</span> -&gt; <span class="string">&quot;jdbc:mysql://bigdata1:3306/ds_db01?useSSL=false&quot;</span>,</span><br><span class="line">    <span class="string">&quot;user&quot;</span> -&gt; <span class="string">&quot;root&quot;</span>,</span><br><span class="line">    <span class="string">&quot;password&quot;</span> -&gt; <span class="string">&quot;123456&quot;</span></span><br><span class="line">  )</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="keyword">val</span> spark: <span class="type">SparkSession</span> = <span class="type">SparkSession</span>.builder()</span><br><span class="line">      .master(<span class="string">&quot;local[*]&quot;</span>)</span><br><span class="line">      .appName(<span class="string">&quot;mock&quot;</span>)</span><br><span class="line">      <span class="comment">// 使用旧的格式化写入器，新版的和hive cli不兼容</span></span><br><span class="line">      <span class="comment">// 如果不设置，那么无法在hive cli查询数据</span></span><br><span class="line">      .config(<span class="string">&quot;spark.sql.parquet.writeLegacyFormat&quot;</span>, <span class="string">&quot;true&quot;</span>)</span><br><span class="line">      .enableHiveSupport</span><br><span class="line">      .getOrCreate</span><br><span class="line">    <span class="comment">// 模拟dwd层数据=ods层旧分区+ods层新分区的抽样数据</span></span><br><span class="line">    <span class="keyword">val</span> customer_inf = spark.table(<span class="string">&quot;ods.customer_inf&quot;</span>).where($<span class="string">&quot;etl_date&quot;</span> === <span class="string">&quot;20220821&quot;</span>)</span><br><span class="line">    <span class="keyword">val</span> product_info = spark.table(<span class="string">&quot;ods.product_info&quot;</span>).where($<span class="string">&quot;etl_date&quot;</span> === <span class="string">&quot;20220904&quot;</span>)</span><br><span class="line">    <span class="keyword">val</span> order_master = spark.table(<span class="string">&quot;ods.order_master&quot;</span>).where($<span class="string">&quot;etl_date&quot;</span> === <span class="string">&quot;20220522&quot;</span>)</span><br><span class="line">    <span class="keyword">val</span> order_detail = spark.table(<span class="string">&quot;ods.order_detail&quot;</span>).where($<span class="string">&quot;etl_date&quot;</span> === <span class="string">&quot;20220319&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> t1 = spark.sql(<span class="string">&quot;select max(modified_time) from ods.customer_inf where etl_date = &#x27;20220821&#x27;&quot;</span>).first.getTimestamp(<span class="number">0</span>)</span><br><span class="line">    <span class="keyword">val</span> t2 = spark.sql(<span class="string">&quot;select max(modified_time) from ods.product_info where etl_date = &#x27;20220904&#x27;&quot;</span>).first.getTimestamp(<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">    spark</span><br><span class="line">      .read</span><br><span class="line">      .format(<span class="string">&quot;jdbc&quot;</span>)</span><br><span class="line">      .options(<span class="type">Map</span>(<span class="string">&quot;query&quot;</span> -&gt; <span class="string">s&quot;select * from customer_inf where modified_time &gt; &#x27;<span class="subst">$t1</span>&#x27;&quot;</span>) ++ m_opt)</span><br><span class="line">      .load</span><br><span class="line">    .withColumn(<span class="string">&quot;etl_date&quot;</span>, lit(<span class="string">&quot;20230217&quot;</span>))</span><br><span class="line">      .sample(<span class="number">0.5</span>)</span><br><span class="line">      .unionByName(customer_inf)</span><br><span class="line">      .withColumn(<span class="string">&quot;dwd_insert_user&quot;</span>, lit(<span class="string">&quot;user1&quot;</span>))</span><br><span class="line">      .withColumn(<span class="string">&quot;dwd_insert_time&quot;</span>, date_trunc(<span class="string">&quot;second&quot;</span>, current_timestamp()))</span><br><span class="line">      .withColumn(<span class="string">&quot;dwd_modify_user&quot;</span>, lit(<span class="string">&quot;user1&quot;</span>))</span><br><span class="line">      .withColumn(<span class="string">&quot;dwd_modify_time&quot;</span>, date_trunc(<span class="string">&quot;second&quot;</span>, current_timestamp()))</span><br><span class="line">      .write</span><br><span class="line">      .partitionBy(<span class="string">&quot;etl_date&quot;</span>)</span><br><span class="line">      .mode(<span class="string">&quot;overwrite&quot;</span>)</span><br><span class="line">      .saveAsTable(<span class="string">&quot;dwd.dim_customer_inf&quot;</span>)</span><br><span class="line"></span><br><span class="line">    spark</span><br><span class="line">      .read</span><br><span class="line">      .format(<span class="string">&quot;jdbc&quot;</span>)</span><br><span class="line">      .options(<span class="type">Map</span>(<span class="string">&quot;query&quot;</span> -&gt; <span class="string">s&quot;select * from product_info where modified_time &gt; &#x27;<span class="subst">$t2</span>&#x27;&quot;</span>) ++ m_opt)</span><br><span class="line">      .load</span><br><span class="line">    .withColumn(<span class="string">&quot;etl_date&quot;</span>, lit(<span class="string">&quot;20230217&quot;</span>))</span><br><span class="line">      .sample(<span class="number">0.5</span>)</span><br><span class="line">      .unionByName(product_info)</span><br><span class="line">      .withColumn(<span class="string">&quot;dwd_insert_user&quot;</span>, lit(<span class="string">&quot;user1&quot;</span>))</span><br><span class="line">      .withColumn(<span class="string">&quot;dwd_insert_time&quot;</span>, date_trunc(<span class="string">&quot;second&quot;</span>, current_timestamp()))</span><br><span class="line">      .withColumn(<span class="string">&quot;dwd_modify_user&quot;</span>, lit(<span class="string">&quot;user1&quot;</span>))</span><br><span class="line">      .withColumn(<span class="string">&quot;dwd_modify_time&quot;</span>, date_trunc(<span class="string">&quot;second&quot;</span>, current_timestamp()))</span><br><span class="line">      .write</span><br><span class="line">      .partitionBy(<span class="string">&quot;etl_date&quot;</span>)</span><br><span class="line">      .mode(<span class="string">&quot;overwrite&quot;</span>)</span><br><span class="line">      .saveAsTable(<span class="string">&quot;dwd.dim_product_info&quot;</span>)</span><br><span class="line"></span><br><span class="line">    order_master</span><br><span class="line">      <span class="comment">// 取 create_time 值并将格式转换为 yyyyMMdd</span></span><br><span class="line">      .withColumn(<span class="string">&quot;create_time&quot;</span>, from_unixtime(unix_timestamp($<span class="string">&quot;create_time&quot;</span>, <span class="string">&quot;yyyyMMddHHmmss&quot;</span>), <span class="string">&quot;yyyyMMdd&quot;</span>))</span><br><span class="line">      <span class="comment">// 若ods表中有涉及到有时间类型，在dwd中都需转为timestamp类型</span></span><br><span class="line">      .withColumn(<span class="string">&quot;shipping_time&quot;</span>, from_unixtime(unix_timestamp($<span class="string">&quot;shipping_time&quot;</span>, <span class="string">&quot;yyyyMMddHHmmss&quot;</span>)))</span><br><span class="line">      .withColumn(<span class="string">&quot;pay_time&quot;</span>, from_unixtime(unix_timestamp($<span class="string">&quot;pay_time&quot;</span>, <span class="string">&quot;yyyyMMddHHmmss&quot;</span>)))</span><br><span class="line">      .withColumn(<span class="string">&quot;receive_time&quot;</span>, from_unixtime(unix_timestamp($<span class="string">&quot;receive_time&quot;</span>, <span class="string">&quot;yyyyMMddHHmmss&quot;</span>)))</span><br><span class="line">      <span class="comment">// 需要过滤掉city字段长度大于8</span></span><br><span class="line">      .where(length($<span class="string">&quot;city&quot;</span>) &lt;= <span class="number">8</span>)</span><br><span class="line">      .withColumn(<span class="string">&quot;dwd_insert_user&quot;</span>, lit(<span class="string">&quot;user1&quot;</span>))</span><br><span class="line">      .withColumn(<span class="string">&quot;dwd_insert_time&quot;</span>, date_trunc(<span class="string">&quot;second&quot;</span>, current_timestamp()))</span><br><span class="line">      .withColumn(<span class="string">&quot;dwd_modify_user&quot;</span>, lit(<span class="string">&quot;user1&quot;</span>))</span><br><span class="line">      .withColumn(<span class="string">&quot;dwd_modify_time&quot;</span>, date_trunc(<span class="string">&quot;second&quot;</span>, current_timestamp()))</span><br><span class="line">      .write</span><br><span class="line">      .partitionBy(<span class="string">&quot;etl_date&quot;</span>)</span><br><span class="line">      .mode(<span class="string">&quot;overwrite&quot;</span>)</span><br><span class="line">      .saveAsTable(<span class="string">&quot;dwd.fact_order_master&quot;</span>)</span><br><span class="line"></span><br><span class="line">    order_detail</span><br><span class="line">      <span class="comment">// 取 create_time 值并将格式转换为 yyyyMMdd</span></span><br><span class="line">      .withColumn(<span class="string">&quot;create_time&quot;</span>, from_unixtime(unix_timestamp($<span class="string">&quot;create_time&quot;</span>, <span class="string">&quot;yyyyMMddHHmmss&quot;</span>), <span class="string">&quot;yyyyMMdd&quot;</span>))</span><br><span class="line">      .withColumn(<span class="string">&quot;dwd_insert_user&quot;</span>, lit(<span class="string">&quot;user1&quot;</span>))</span><br><span class="line">      .withColumn(<span class="string">&quot;dwd_insert_time&quot;</span>, date_trunc(<span class="string">&quot;second&quot;</span>, current_timestamp()))</span><br><span class="line">      .withColumn(<span class="string">&quot;dwd_modify_user&quot;</span>, lit(<span class="string">&quot;user1&quot;</span>))</span><br><span class="line">      .withColumn(<span class="string">&quot;dwd_modify_time&quot;</span>, date_trunc(<span class="string">&quot;second&quot;</span>, current_timestamp()))</span><br><span class="line">      .write</span><br><span class="line">      .partitionBy(<span class="string">&quot;etl_date&quot;</span>)</span><br><span class="line">      .mode(<span class="string">&quot;overwrite&quot;</span>)</span><br><span class="line">      .saveAsTable(<span class="string">&quot;dwd.fact_order_detail&quot;</span>)</span><br><span class="line">      </span><br><span class="line">  <span class="comment">/*</span></span><br><span class="line"><span class="comment">    |count(1) 13328|</span></span><br><span class="line"><span class="comment">    |count(1) 8658|</span></span><br><span class="line"><span class="comment">    |count(1) 319952|</span></span><br><span class="line"><span class="comment">    |count(1) 81321|</span></span><br><span class="line"><span class="comment">    前两个，是抽样，所以每次执行数据量会有些许差异</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line">    spark.sql(<span class="string">&quot;select count(1) from dwd.dim_customer_inf&quot;</span>).show</span><br><span class="line">    spark.sql(<span class="string">&quot;select count(1) from dwd.dim_product_info&quot;</span>).show</span><br><span class="line">    spark.sql(<span class="string">&quot;select count(1) from dwd.fact_order_master&quot;</span>).show</span><br><span class="line">    spark.sql(<span class="string">&quot;select count(1) from dwd.fact_order_detail&quot;</span>).show</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ol><h1 id="任务一：数据抽取"><a href="#任务一：数据抽取" class="headerlink" title="任务一：数据抽取"></a>任务一：数据抽取</h1><p>开局先写包文件，写完了事半功倍</p><h2 id="包文件"><a href="#包文件" class="headerlink" title="包文件"></a>包文件</h2><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.spark.sql.functions.lit</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.sql.&#123;<span class="type">DataFrame</span>, <span class="type">SparkSession</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.<span class="type">Properties</span></span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Created By `Super小飞象` on 2023/2/15 16:03</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">package</span> <span class="class"><span class="keyword">object</span> <span class="title">commerce</span> </span>&#123;</span><br><span class="line">  </span><br><span class="line">  <span class="comment">// spark对象</span></span><br><span class="line">  <span class="keyword">val</span> spark: <span class="type">SparkSession</span> = <span class="type">SparkSession</span>.builder()</span><br><span class="line">    .master(<span class="string">&quot;local[*]&quot;</span>)</span><br><span class="line">    .appName(<span class="string">&quot;commerce&quot;</span>)</span><br><span class="line">    .config(<span class="string">&quot;spark.sql.parquet.writeLegacyFormat&quot;</span>, <span class="string">&quot;true&quot;</span>)</span><br><span class="line">    .enableHiveSupport</span><br><span class="line">    .getOrCreate</span><br><span class="line">  </span><br><span class="line">  <span class="comment">// mysql基本配置项</span></span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">val</span> m_opt = <span class="type">Map</span>(</span><br><span class="line">    <span class="string">&quot;url&quot;</span> -&gt; <span class="string">&quot;jdbc:mysql://bigdata1:3306/ds_db01?useSSL=false&quot;</span>,</span><br><span class="line">    <span class="string">&quot;user&quot;</span> -&gt; <span class="string">&quot;root&quot;</span>,</span><br><span class="line">    <span class="string">&quot;password&quot;</span> -&gt; <span class="string">&quot;123456&quot;</span></span><br><span class="line">  )</span><br><span class="line">  </span><br><span class="line">  <span class="comment">// clickhouse的配置对象</span></span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">val</span> c_pro = <span class="keyword">new</span> <span class="type">Properties</span>()</span><br><span class="line">  c_pro.setProperty(<span class="string">&quot;url&quot;</span>, <span class="string">&quot;jdbc:clickhouse://bigdata1:8123/shtd_result&quot;</span>)</span><br><span class="line">  c_pro.setProperty(<span class="string">&quot;user&quot;</span>, <span class="string">&quot;default&quot;</span>)</span><br><span class="line">  c_pro.setProperty(<span class="string">&quot;password&quot;</span>, <span class="string">&quot;123456&quot;</span>)</span><br><span class="line">  c_pro.setProperty(<span class="string">&quot;driver&quot;</span>, <span class="string">&quot;ru.yandex.clickhouse.ClickHouseDriver&quot;</span>)</span><br><span class="line">  <span class="comment">// 这个也是必须的，不然会报错</span></span><br><span class="line">  c_pro.setProperty(<span class="string">&quot;createTableOptions&quot;</span>, <span class="string">&quot;ENGINE=Log()&quot;</span>)</span><br><span class="line">  </span><br><span class="line">  <span class="comment">// 传入sql查询语句返回一个DataFrame对象</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">loadMysql</span></span>(query: <span class="type">String</span>): <span class="type">DataFrame</span> = </span><br><span class="line">    spark.read</span><br><span class="line">      .format(<span class="string">&quot;jdbc&quot;</span>)</span><br><span class="line">      .options(m_opt ++ <span class="type">Map</span>(<span class="string">&quot;query&quot;</span> -&gt; query))</span><br><span class="line">      .load</span><br><span class="line">  </span><br><span class="line">  <span class="comment">// 传入DataFrame对象和表名，将df对象存入到ods层的表中</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">to_ods</span></span>(df: <span class="type">DataFrame</span>, tbName: <span class="type">String</span>): <span class="type">Unit</span> = </span><br><span class="line">    <span class="comment">// 添加分区字段</span></span><br><span class="line">    df.withColumn(<span class="string">&quot;etl_date&quot;</span>, lit(<span class="string">&quot;20230212&quot;</span>))</span><br><span class="line">      .write</span><br><span class="line">      .partitionBy(<span class="string">&quot;etl_date&quot;</span>)</span><br><span class="line">      <span class="comment">// 写入模式一定得是追加</span></span><br><span class="line">      .mode(<span class="string">&quot;append&quot;</span>)</span><br><span class="line">      .saveAsTable(<span class="string">&quot;ods.&quot;</span> + tbName)</span><br><span class="line">  </span><br><span class="line">  <span class="comment">// 传入DataFrame对象和表名，将df对象存入到mysql中</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">save_mysql</span></span>(df: <span class="type">DataFrame</span>, tbName: <span class="type">String</span>): <span class="type">Unit</span> = </span><br><span class="line">    df.write</span><br><span class="line">      .format(<span class="string">&quot;jdbc&quot;</span>)</span><br><span class="line">      .options(<span class="type">Map</span>(<span class="string">&quot;dbtable&quot;</span> -&gt; tbName))</span><br><span class="line">      .mode(<span class="string">&quot;overwrite&quot;</span>)</span><br><span class="line">      .save</span><br><span class="line">  </span><br><span class="line">  <span class="comment">// 传入DataFrame对象和表名，将df对象存入到clickhouse中</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">save_click</span></span>(df: <span class="type">DataFrame</span>, tbName: <span class="type">String</span>): <span class="type">Unit</span> = </span><br><span class="line">    df.write</span><br><span class="line">      .mode(<span class="string">&quot;overwrite&quot;</span>)</span><br><span class="line">      .jdbc(c_pro.getProperty(<span class="string">&quot;url&quot;</span>), tbName, c_pro)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="开始做题"><a href="#开始做题" class="headerlink" title="开始做题"></a>开始做题</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">抽取`ds_db01`库中`customer_inf`的增量数据进入Hive的ods库中表`customer_inf`</span><br><span class="line">根据`ods.customer_inf`表中`modified_time`作为增量字段，只将新增的数据抽入，字段名称、类型不变</span><br><span class="line">同时添加静态分区，分区字段为`etl_date`，类型为String，且值为当前日期的前一天日期（格式为yyyyMMdd）</span><br><span class="line">使用hive cli执行`show partitions ods.customer_inf;`命令</span><br></pre></td></tr></table></figure><ol><li><p>查询出 ods 库中表 customer_inf 的最大的 modified_time 值</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// df.first 取出df的第一行数据，返回的是Row对象</span></span><br><span class="line"><span class="keyword">val</span> first: <span class="type">Row</span> = spark.sql(<span class="string">&quot;select max(modified_time) from ods.customer_inf&quot;</span>).first</span><br><span class="line"><span class="comment">// 行对象调用get方法参数传入索引，可以获取该行对应数据类型对应索引的数据</span></span><br><span class="line"><span class="keyword">val</span> max_modified_time: <span class="type">Timestamp</span> = first.getTimestamp(<span class="number">0</span>)</span><br></pre></td></tr></table></figure></li><li><p>定义查询语句</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 已知存量表中最大时间为`max_modified_time`，要求只将新增的数据抽入</span></span><br><span class="line"><span class="comment">// 即：mysql中大于该时间的为需要抽取的增量数据，小于等于的数据都已经在ods层里了</span></span><br><span class="line"><span class="keyword">val</span> query = <span class="string">s&quot;select * from customer_inf where modified_time &gt; &#x27;<span class="subst">$max_modified_time</span>&#x27;&quot;</span></span><br></pre></td></tr></table></figure></li><li><p>传入先前定义的方法</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 传入sql查询语句，执行该语句并返回一个DataFrame对象</span></span><br><span class="line"><span class="keyword">val</span> customer_inf: <span class="type">DataFrame</span> = loadMysql(query)</span><br></pre></td></tr></table></figure></li><li><p>至此，以完成抽取增量数据，现在需要追加到ods层的customer_inf表</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 调用方法即可</span></span><br><span class="line">to_ods(customer_inf, <span class="string">&quot;customer_inf&quot;</span>)</span><br></pre></td></tr></table></figure></li><li><p>代码</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> commerce</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.sql.<span class="type">DataFrame</span></span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Created By `Super小飞象` on 2023/2/15 18:42</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">Task1</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="comment">// 四张表步骤一样，循环执行即可</span></span><br><span class="line">    <span class="type">List</span>(<span class="string">&quot;customer_inf&quot;</span>, <span class="string">&quot;product_info&quot;</span>, <span class="string">&quot;order_master&quot;</span>, <span class="string">&quot;order_detail&quot;</span>)</span><br><span class="line">      .foreach &#123;</span><br><span class="line">        tbName =&gt;</span><br><span class="line">          <span class="comment">// 取最大modified_time值</span></span><br><span class="line">          <span class="keyword">val</span> max_modified_time = spark.sql(<span class="string">s&quot;select max(modified_time) from ods.<span class="subst">$tbName</span>&quot;</span>).first().getTimestamp(<span class="number">0</span>)</span><br><span class="line">          <span class="comment">// 从mysql通过比对modified_time值过滤出增量数据</span></span><br><span class="line">          <span class="keyword">val</span> dataframe: <span class="type">DataFrame</span> = loadMysql(<span class="string">s&quot;select * from <span class="subst">$tbName</span> where modified_time &gt; &#x27;<span class="subst">$max_modified_time</span>&#x27;&quot;</span>)</span><br><span class="line">          <span class="comment">// 增量数据存入ods层对应的表</span></span><br><span class="line">          to_ods(dataframe, tbName)</span><br><span class="line">          <span class="comment">// 查看数据行数进行核对</span></span><br><span class="line">          println(spark.table(<span class="string">s&quot;ods.<span class="subst">$tbName</span>&quot;</span>).count)</span><br><span class="line">      &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>如果代码出错，数据插进去了，那么你插进去的数据就和存量数据混了，但是有分区，你的增量数据存放在你指定的分区中，那么删掉该分区就好了。</p><p>一个很有用的命令</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 删除分区</span></span><br><span class="line">alter table ods.customer_inf drop partition(etl_date=<span class="string">&#x27;20230215&#x27;</span>);</span><br><span class="line">alter table ods.product_info drop partition(etl_date=<span class="string">&#x27;20230215&#x27;</span>);</span><br><span class="line">alter table ods.order_master drop partition(etl_date=<span class="string">&#x27;20230215&#x27;</span>);</span><br><span class="line">alter table ods.order_detail drop partition(etl_date=<span class="string">&#x27;20230215&#x27;</span>);</span><br></pre></td></tr></table></figure></li></ol><h1 id="任务二：数据清洗"><a href="#任务二：数据清洗" class="headerlink" title="任务二：数据清洗"></a>任务二：数据清洗</h1><h2 id="customer-inf"><a href="#customer-inf" class="headerlink" title="customer_inf"></a>customer_inf</h2><p>抽取<code>ods</code>库中<code>customer_inf</code>表中任务一生成的分区数据，并结合<code>dim_customer_inf</code>最新分区现有的数据，根据<code>customer_id</code>合并数据到<code>dwd</code>库中<code>dim_customer_inf</code>的分区表（合并是指对<code>dwd</code>层数据进行插入或修改，需修改的数据以<code>customer_id</code>为合并字段，根据<code>modified_time</code>排序取最新的一条），分区字段为<code>etl_date</code>且值与<code>ods</code>库的相对应表该值相等，并添加<code>dwd_insert_user</code>、<code>dwd_insert_time</code>、<code>dwd_modify_user</code>、<code>dwd_modify_time</code>四列,其中<code>dwd_insert_user</code>、<code>dwd_modify_user</code>均填写<code>user1</code>。若该条记录第一次进入数仓<code>dwd</code>层则<code>dwd_insert_time</code>、<code>dwd_modify_time</code>均存当前操作时间，并进行数据类型转换。若该数据在进入<code>dwd</code>层时发生了合并修改，则<code>dwd_insert_time</code>时间不变，<code>dwd_modify_time</code>存当前操作时间，其余列存最新的值。使用<code>hive cl</code>i执行<code>show partitions dwd.dim_customer_in;</code>命令；</p><h3 id="题目解析"><a href="#题目解析" class="headerlink" title="题目解析"></a>题目解析</h3><p>字确实多，总结也就几点</p><ul><li>取<code>ods</code>库中<code>customer_inf</code>表中任务一生成的分区数据<ul><li>添加 <code>dwd_insert_user</code>、<code>dwd_insert_time</code>、<code>dwd_modify_user</code>、<code>dwd_modify_time</code></li></ul></li><li>取<code>dwd</code>库中<code>dim_customer_inf</code>表中最新分区数据</li><li>两个分区的数据进行合并，如果有两条相同<code>customer_id</code>的数据则取<code>modified_time</code>更大的一条</li></ul><h3 id="解题思路"><a href="#解题思路" class="headerlink" title="解题思路"></a>解题思路</h3><ol><li><p>已知</p><ul><li><code>dim_customer_inf</code>已有旧分区数据+新分区的50%抽样数据</li><li>完成任务一之后，<code>customer_inf</code>已有旧分区数据+新分区全部数据</li></ul></li><li><p>取出<code>dim_customer_inf</code>旧分区数据覆盖写入至临时表temp</p><p>为什么需要临时表，因为你真的没办法保证你可以100%一次性把代码写正确，在任务一写错了你可以删除那个分区，这里可不行，这里删了那新分区已有的存量数据是没办法找到的。</p></li><li><p>取出<code>dim_customer_inf</code>的新分区数据(只有抽样的50%)，这里这些是dwd层已经清洗好的数据</p></li><li><p>取出<code>customer_inf</code>新分区数据，添加那四列</p></li><li><p>两个分区的数据进行合并，如果有两条相同<code>customer_id</code>的数据则取<code>modified_time</code>更大的一条</p></li><li><p>将合并数据追加写入到临时表temp</p></li><li><p>查看temp表数据，查看数据量，反复确认是否正确</p></li><li><p>确认正确，将temp表覆盖写入至dwd层的<code>dim_customer_inf</code></p></li></ol><h3 id="上操作"><a href="#上操作" class="headerlink" title="上操作"></a>上操作</h3><ol><li><p>取出<code>dim_customer_inf</code>旧分区数据覆盖写入至临时表temp</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">spark.table(<span class="string">&quot;dwd.dim_customer_inf&quot;</span>)</span><br><span class="line">  <span class="comment">// 查询该表非最新分区的数据</span></span><br><span class="line">  .where($<span class="string">&quot;etl_date&quot;</span> =!= <span class="string">&quot;20230217&quot;</span>)</span><br><span class="line">  <span class="comment">// 写入</span></span><br><span class="line">  .write</span><br><span class="line">  <span class="comment">// 覆盖写入</span></span><br><span class="line">  .mode(<span class="string">&quot;overwrite&quot;</span>)</span><br><span class="line">  <span class="comment">// 临时表</span></span><br><span class="line">  .saveAsTable(<span class="string">&quot;temp&quot;</span>)</span><br></pre></td></tr></table></figure></li><li><p>取出<code>dim_customer_inf</code>的新分区数据</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 取出来用变量保存</span></span><br><span class="line"><span class="keyword">val</span> dim_customer_inf = spark.table(<span class="string">&quot;dwd.dim_customer_inf&quot;</span>)</span><br><span class="line">  <span class="comment">// 查询该表最新分区的数据</span></span><br><span class="line">  .where($<span class="string">&quot;etl_date&quot;</span> === <span class="string">&quot;20230217&quot;</span>)</span><br></pre></td></tr></table></figure></li><li><p>取出<code>customer_inf</code>新分区数据，添加那四列</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> customer_inf = spark.sql(<span class="string">&quot;select * from ods.customer_inf where etl_date = &#x27;20230217&#x27;&quot;</span>)</span><br><span class="line">  <span class="comment">// dwd_insert_user、dwd_insert_time、dwd_modify_user、dwd_modify_time</span></span><br><span class="line">  .withColumn(<span class="string">&quot;dwd_insert_user&quot;</span>, lit(<span class="string">&quot;user1&quot;</span>))</span><br><span class="line">  <span class="comment">// current_timestamp() 获取当前时间戳(例：2023-02-18 14:46:07.574)</span></span><br><span class="line">  <span class="comment">// 题目中有说不记录毫秒数，使用date_trunc截取时间到秒</span></span><br><span class="line">  .withColumn(<span class="string">&quot;dwd_insert_time&quot;</span>, date_trunc(<span class="string">&quot;second&quot;</span>, current_timestamp()))</span><br><span class="line">  .withColumn(<span class="string">&quot;dwd_modify_user&quot;</span>, lit(<span class="string">&quot;user1&quot;</span>))</span><br><span class="line">  .withColumn(<span class="string">&quot;dwd_modify_time&quot;</span>, date_trunc(<span class="string">&quot;second&quot;</span>, current_timestamp()))</span><br></pre></td></tr></table></figure></li><li><p>重要操作：合并两个分区追加写入到temp临时表</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> spec: <span class="type">WindowSpec</span> = <span class="type">Window</span>.partitionBy(<span class="string">&quot;customer_id&quot;</span>)</span><br><span class="line">dim_customer_inf.unionByName(customer_inf)</span><br><span class="line">  .withColumn(<span class="string">&quot;rk&quot;</span>, row_number over spec.orderBy($<span class="string">&quot;modified_time&quot;</span>.desc))</span><br><span class="line">  .withColumn(<span class="string">&quot;dwd_insert_time&quot;</span>, min($<span class="string">&quot;dwd_insert_time&quot;</span>) over spec)</span><br><span class="line">  .withColumn(<span class="string">&quot;dwd_modify_time&quot;</span>, max($<span class="string">&quot;dwd_modify_time&quot;</span>) over spec)</span><br><span class="line">  .where(<span class="string">&quot;rk == 1&quot;</span>)</span><br><span class="line">  .select(dim_customer_inf.columns.map(col): _*)</span><br><span class="line">  .write</span><br><span class="line">  .mode(<span class="string">&quot;append&quot;</span>)</span><br><span class="line">  .saveAsTable(<span class="string">&quot;temp&quot;</span>)</span><br></pre></td></tr></table></figure><ul><li><p>定义一个WindowSpec对象，后面要用几次</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 相同 customer_id 的数据作为一个窗口</span></span><br><span class="line"><span class="keyword">val</span> spec: <span class="type">WindowSpec</span> = <span class="type">Window</span>.partitionBy(<span class="string">&quot;customer_id&quot;</span>)</span><br></pre></td></tr></table></figure></li><li><p>合并</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">dim_customer_inf.unionByName(customer_inf)</span><br></pre></td></tr></table></figure></li><li><p>窗口函数，相同customer_id的数据为同一个窗口，窗口内根据modified_time降序，row_number函数则是给窗口内每一行数据分配一个行号，题目说根据<code>modified_time</code>排序取最新的一条，则这里只取行号为1的数据。</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">.withColumn(<span class="string">&quot;rk&quot;</span>, row_number over spec.orderBy($<span class="string">&quot;modified_time&quot;</span>.desc))</span><br></pre></td></tr></table></figure></li><li><p>若该数据在进入<code>dwd</code>层时发生了合并修改，则<code>dwd_insert_time</code>时间不变，<code>dwd_modify_time</code>存当前操作时间，其余列存最新的值。</p><p>这里分两种情况：</p><ol><li><p>数据第一次进入dwd层，dwd_insert_time、dwd_modify_time均存当前操作时间，事实上这个已经在第三步的时候已经处理了。下面两行代码，窗口内取最大取最小，无所谓，因为是第一次进入，那这个customer_id也没有别的数据，该窗口就这一条数据，最大最小都是本身。</p></li><li><p>若该数据在进入dwd层时发生了合并修改，则 dwd_insert_time 时间不变，dwd_modify_time 存当前操作时间。此时max和min的效果就来了：</p><ul><li>此时有两条数据：<code>10086,13:00:01,13:00:01,1</code>和 <code>10086,18:00:01,18:00:01,2</code></li><li>解释：<code>customer_id,dwd_insert_time,dwd_modify_time,rank</code></li><li><code>dwd_insert_time</code>取最小值，<code>dwd_modify_time</code>取最大值</li><li>最后变成：<code>10086,13:00:01,18:00:01,1</code> 和 <code>10086,13:00:01,18:00:01,2</code></li><li>两条数据都满足<code>dwd_insert_time</code> 时间不变，<code>dwd_modify_time</code> 存当前操作时间</li><li>那两条都变了啊！无所谓，我只要<code>modified_time</code>最新的那条，即<code>rk</code>为1的那条</li></ul></li><li><p>代码</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">.withColumn(<span class="string">&quot;dwd_insert_time&quot;</span>, min($<span class="string">&quot;dwd_insert_time&quot;</span>) over spec)</span><br><span class="line">.withColumn(<span class="string">&quot;dwd_modify_time&quot;</span>, max($<span class="string">&quot;dwd_modify_time&quot;</span>) over spec)</span><br><span class="line">.where(<span class="string">&quot;rk == 1&quot;</span>)</span><br></pre></td></tr></table></figure></li></ol></li><li><p>追加写入到temp临时表</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 查询dim_customer_inf已有的列</span></span><br><span class="line">.select(dim_customer_inf.columns.map(col): _*)</span><br><span class="line">.write</span><br><span class="line">.mode(<span class="string">&quot;append&quot;</span>)</span><br><span class="line">.saveAsTable(<span class="string">&quot;temp&quot;</span>)</span><br></pre></td></tr></table></figure></li></ul></li><li><p>查看temp表数据，查看数据量，反复确认是否正确</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> frame = spark.table(<span class="string">&quot;temp&quot;</span>)</span><br><span class="line">frame.show</span><br><span class="line">println(frame.count())</span><br></pre></td></tr></table></figure></li><li><p>确认无误，覆盖至目标表</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">frame</span><br><span class="line">  .write</span><br><span class="line">  .partitionBy(<span class="string">&quot;etl_date&quot;</span>)</span><br><span class="line">  .mode(<span class="string">&quot;overwrite&quot;</span>)</span><br><span class="line">  .saveAsTable(<span class="string">&quot;dwd.dim_customer_inf&quot;</span>)</span><br></pre></td></tr></table></figure></li><li><p>代码</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">run1</span></span>(): <span class="type">Unit</span> = &#123;</span><br><span class="line">  spark.table(<span class="string">&quot;dwd.dim_customer_inf&quot;</span>)</span><br><span class="line">    .where($<span class="string">&quot;etl_date&quot;</span> =!= <span class="string">&quot;20230217&quot;</span>)</span><br><span class="line">    .write</span><br><span class="line">    .mode(<span class="string">&quot;overwrite&quot;</span>)</span><br><span class="line">    .saveAsTable(<span class="string">&quot;temp&quot;</span>)</span><br><span class="line">  <span class="keyword">val</span> dim_customer_inf = spark.table(<span class="string">&quot;dwd.dim_customer_inf&quot;</span>)</span><br><span class="line">    .where($<span class="string">&quot;etl_date&quot;</span> === <span class="string">&quot;20230217&quot;</span>)</span><br><span class="line">  <span class="keyword">val</span> customer_inf = spark.sql(<span class="string">&quot;select * from ods.customer_inf where etl_date = &#x27;20230217&#x27;&quot;</span>)</span><br><span class="line">    .withColumn(<span class="string">&quot;dwd_insert_user&quot;</span>, lit(<span class="string">&quot;user1&quot;</span>))</span><br><span class="line">    .withColumn(<span class="string">&quot;dwd_insert_time&quot;</span>, date_trunc(<span class="string">&quot;second&quot;</span>, current_timestamp()))</span><br><span class="line">    .withColumn(<span class="string">&quot;dwd_modify_user&quot;</span>, lit(<span class="string">&quot;user1&quot;</span>))</span><br><span class="line">    .withColumn(<span class="string">&quot;dwd_modify_time&quot;</span>, date_trunc(<span class="string">&quot;second&quot;</span>, current_timestamp()))</span><br><span class="line">  <span class="keyword">val</span> spec: <span class="type">WindowSpec</span> = <span class="type">Window</span>.partitionBy(<span class="string">&quot;customer_id&quot;</span>)</span><br><span class="line">  dim_customer_inf.unionByName(customer_inf)</span><br><span class="line">    .withColumn(<span class="string">&quot;rk&quot;</span>, row_number over spec.orderBy($<span class="string">&quot;modified_time&quot;</span>.desc))</span><br><span class="line">    .withColumn(<span class="string">&quot;dwd_insert_time&quot;</span>, min($<span class="string">&quot;dwd_insert_time&quot;</span>) over spec)</span><br><span class="line">    .withColumn(<span class="string">&quot;dwd_modify_time&quot;</span>, max($<span class="string">&quot;dwd_modify_time&quot;</span>) over spec)</span><br><span class="line">    .where(<span class="string">&quot;rk == 1&quot;</span>)</span><br><span class="line">    .select(dim_customer_inf.columns.map(col): _*)</span><br><span class="line">    .write</span><br><span class="line">    .mode(<span class="string">&quot;append&quot;</span>)</span><br><span class="line">    .saveAsTable(<span class="string">&quot;temp&quot;</span>)</span><br><span class="line">  <span class="keyword">val</span> frame = spark.table(<span class="string">&quot;temp&quot;</span>)</span><br><span class="line">  println(frame.count())</span><br><span class="line">  frame</span><br><span class="line">    .write</span><br><span class="line">    .partitionBy(<span class="string">&quot;etl_date&quot;</span>)</span><br><span class="line">    .mode(<span class="string">&quot;overwrite&quot;</span>)</span><br><span class="line">    .saveAsTable(<span class="string">&quot;dwd.dim_customer_inf&quot;</span>)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ol><h2 id="product-info"><a href="#product-info" class="headerlink" title="product_info"></a>product_info</h2><p>除了表名和<code>customer_inf</code>不一样，其他操作都一样</p><h2 id="order-master"><a href="#order-master" class="headerlink" title="order_master"></a>order_master</h2><p>将<code>ods</code>库中<code>order_master</code>表任务一生成的分区数据抽取到<code>dwd</code>库中<code>fact_order_master</code>的动态分区表，分区字段为<code>etl_date</code>，取<code>create_time</code>值并将格式转换为<code>yyyyMMdd</code>，并添加<code>dwd_insert_user</code>、<code>dwd_insert_time</code>、<code>dwd_modify_user</code>、<code>dwd_modify_time</code>四列，其中<code>dwd_insert_user</code>、<code>dwd_modify_user</code>均填写<code>user1</code>，<code>dwd_insert_time</code>、<code>dwd_modify_time</code>均填写当前操作时间，并进行数据类型转换，需要过滤掉city字段长度大于8。使用hive cli执行<code>show partitions dwd.fact_order_master</code>命令；</p><p>简单的数据清洗而已，直接上代码吧</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">run3</span></span>(): <span class="type">Unit</span> = &#123;</span><br><span class="line">  <span class="comment">// order_master 表中昨天的分区（任务一生成的分区）数据</span></span><br><span class="line">  spark.sql(<span class="string">&quot;select * from ods.order_master where etl_date = &#x27;20230217&#x27;&quot;</span>)</span><br><span class="line">    <span class="comment">// 需要过滤掉city字段长度大于8</span></span><br><span class="line">    .where(length($<span class="string">&quot;city&quot;</span>) &lt;= <span class="number">8</span>)</span><br><span class="line">    <span class="comment">// dwd_insert_user、dwd_insert_time、dwd_modify_user、dwd_modify_time</span></span><br><span class="line">    .withColumn(<span class="string">&quot;dwd_insert_user&quot;</span>, lit(<span class="string">&quot;user1&quot;</span>))</span><br><span class="line">    .withColumn(<span class="string">&quot;dwd_insert_time&quot;</span>, date_trunc(<span class="string">&quot;second&quot;</span>, current_timestamp()))</span><br><span class="line">    .withColumn(<span class="string">&quot;dwd_modify_user&quot;</span>, lit(<span class="string">&quot;user1&quot;</span>))</span><br><span class="line">    .withColumn(<span class="string">&quot;dwd_modify_time&quot;</span>, date_trunc(<span class="string">&quot;second&quot;</span>, current_timestamp()))</span><br><span class="line">    <span class="comment">// 按照题目要求进行格式转换</span></span><br><span class="line">    .withColumn(<span class="string">&quot;create_time&quot;</span>, from_unixtime(unix_timestamp($<span class="string">&quot;create_time&quot;</span>, <span class="string">&quot;yyyyMMddHHmmss&quot;</span>), <span class="string">&quot;yyyyMMdd&quot;</span>))</span><br><span class="line">    <span class="comment">// 按照题目要求进行格式转换</span></span><br><span class="line">    .withColumn(<span class="string">&quot;shipping_time&quot;</span>, from_unixtime(unix_timestamp($<span class="string">&quot;shipping_time&quot;</span>, <span class="string">&quot;yyyyMMddHHmmss&quot;</span>)))</span><br><span class="line">    <span class="comment">// 按照题目要求进行格式转换</span></span><br><span class="line">    .withColumn(<span class="string">&quot;pay_time&quot;</span>, from_unixtime(unix_timestamp($<span class="string">&quot;pay_time&quot;</span>, <span class="string">&quot;yyyyMMddHHmmss&quot;</span>)))</span><br><span class="line">    <span class="comment">// 按照题目要求进行格式转换</span></span><br><span class="line">    .withColumn(<span class="string">&quot;receive_time&quot;</span>, from_unixtime(unix_timestamp($<span class="string">&quot;receive_time&quot;</span>, <span class="string">&quot;yyyyMMddHHmmss&quot;</span>)))</span><br><span class="line">    .write</span><br><span class="line">    .partitionBy(<span class="string">&quot;etl_date&quot;</span>)</span><br><span class="line">    <span class="comment">// 追加写入</span></span><br><span class="line">    .mode(<span class="string">&quot;append&quot;</span>)</span><br><span class="line">    .saveAsTable(<span class="string">&quot;dwd.fact_order_master&quot;</span>)</span><br><span class="line">  <span class="comment">// 核对数据量，如果不对，那就删了dwd层该表的20230217分区数据然后仔细检查代码</span></span><br><span class="line">  println(spark.table(<span class="string">&quot;dwd.fact_order_master&quot;</span>).count())</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="order-detail"><a href="#order-detail" class="headerlink" title="order_detail"></a>order_detail</h2><p>上代码</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">run4</span></span>(): <span class="type">Unit</span> = &#123;</span><br><span class="line">  spark.sql(<span class="string">&quot;select * from ods.order_detail where etl_date = &#x27;20230217&#x27;&quot;</span>)</span><br><span class="line">    .withColumn(<span class="string">&quot;dwd_insert_user&quot;</span>, lit(<span class="string">&quot;user1&quot;</span>))</span><br><span class="line">    .withColumn(<span class="string">&quot;dwd_insert_time&quot;</span>, date_trunc(<span class="string">&quot;second&quot;</span>, current_timestamp()))</span><br><span class="line">    .withColumn(<span class="string">&quot;dwd_modify_user&quot;</span>, lit(<span class="string">&quot;user1&quot;</span>))</span><br><span class="line">    .withColumn(<span class="string">&quot;dwd_modify_time&quot;</span>, date_trunc(<span class="string">&quot;second&quot;</span>, current_timestamp()))</span><br><span class="line">    .withColumn(<span class="string">&quot;create_time&quot;</span>, from_unixtime(unix_timestamp($<span class="string">&quot;create_time&quot;</span>, <span class="string">&quot;yyyyMMddHHmmss&quot;</span>), <span class="string">&quot;yyyyMMdd&quot;</span>))</span><br><span class="line">    .write</span><br><span class="line">    .partitionBy(<span class="string">&quot;etl_date&quot;</span>)</span><br><span class="line">    .mode(<span class="string">&quot;append&quot;</span>)</span><br><span class="line">    .saveAsTable(<span class="string">&quot;dwd.fact_order_detail&quot;</span>)</span><br><span class="line">  println(spark.table(<span class="string">&quot;dwd.fact_order_detail&quot;</span>).count())</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h1 id="任务三：指标计算"><a href="#任务三：指标计算" class="headerlink" title="任务三：指标计算"></a>任务三：指标计算</h1><p>订单金额计算相关使用<code>order_money</code>字段，同一个订单无需多次重复计算，需要考虑退款或者取消的订单</p><ul><li>查看数据发现有这几种订单状态：已下单、已支付、已发货、已签收、已退款</li><li><code>create_time</code>为下单时间，后续有关下单的计算使用该字段</li><li><code>pay_time</code>为支付时间，后续有关订单金额的计算使用该字段</li><li>订单金额计算相关使用<code>order_money</code>字段</li><li>同一个订单无需多次重复计算</li><li>需要考虑退款或者取消的订单</li></ul><h2 id="第一题"><a href="#第一题" class="headerlink" title="第一题"></a>第一题</h2><h3 id="题目"><a href="#题目" class="headerlink" title="题目"></a>题目</h3><p>根据dwd层表统计每人每天下单的数量和下单的总金额，存入<code>dws</code>层的<code>user_consumption_day_aggr</code>表中，然后使用<code>hive cli</code>按照客户主键、订单总金额均为降序排序，查询出前5条；</p><p><code>user_consumption_day_aggr</code>表结构</p><table><thead><tr><th>字段</th><th>类型</th><th>中文含义</th><th>备注</th></tr></thead><tbody><tr><td>customer_id</td><td>int</td><td>客户主键</td><td>customer_id</td></tr><tr><td>customer_name</td><td>string</td><td>客户名称</td><td>customer_name</td></tr><tr><td>total_amount</td><td>double</td><td>订单总金额</td><td>当天订单总金额</td></tr><tr><td>total_count</td><td>int</td><td>订单总数</td><td>当天订单总数</td></tr><tr><td>year</td><td>int</td><td>年</td><td>订单产生的年,为动态分区字段</td></tr><tr><td>month</td><td>int</td><td>月</td><td>订单产生的月,为动态分区字段</td></tr><tr><td>day</td><td>int</td><td>日</td><td>订单产生的日,为动态分区字段</td></tr></tbody></table><h3 id="思路"><a href="#思路" class="headerlink" title="思路"></a>思路</h3><p>生成年月日三列，根据客户主键和年月日分组，计算每人每天下单数量和总金额，由于还需要一个客户名称字段，所以需要再连接一下客户表取得客户名称字段。</p><h3 id="开始"><a href="#开始" class="headerlink" title="开始"></a>开始</h3><ol><li><p>先导入隐式转换</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> spark.implicits._</span><br></pre></td></tr></table></figure></li><li><p>取出<code>dim_customer_inf</code>的客户主键和客户名称字段等待被连接</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> frame = spark.table(<span class="string">&quot;dwd.dim_customer_inf&quot;</span>)</span><br><span class="line">.select(<span class="string">&quot;customer_id&quot;</span>, <span class="string">&quot;customer_name&quot;</span>)</span><br></pre></td></tr></table></figure></li><li><p>读取<code>fact_order_master</code>表只取订单状态为下单的订单并且进行去重</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">spark.table(<span class="string">&quot;dwd.fact_order_master&quot;</span>)</span><br><span class="line">  .where(&#x27;order_status === <span class="string">&quot;已下单&quot;</span>)</span><br><span class="line">  .distinct</span><br></pre></td></tr></table></figure></li><li><p>生成年月日三列</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"> <span class="comment">// unix_timestamp 转成时间戳，这种的 -&gt; 1670818332</span></span><br><span class="line"><span class="comment">// 数字的不通用，得用from_unixtime把数字的转成这样的 -&gt; 2022-12-12 12:12:12</span></span><br><span class="line">.withColumn(<span class="string">&quot;date&quot;</span>, from_unixtime(unix_timestamp($<span class="string">&quot;create_time&quot;</span>, <span class="string">&quot;yyyyMMdd&quot;</span>)))</span><br><span class="line"><span class="comment">// 取出年</span></span><br><span class="line"> .withColumn(<span class="string">&quot;year&quot;</span>, year($<span class="string">&quot;date&quot;</span>))</span><br><span class="line"> <span class="comment">// 取出月</span></span><br><span class="line"> .withColumn(<span class="string">&quot;month&quot;</span>, month($<span class="string">&quot;date&quot;</span>))</span><br><span class="line"><span class="comment">// dayofmonth 获取当前是这个月的第几天</span></span><br><span class="line"> .withColumn(<span class="string">&quot;day&quot;</span>, dayofmonth($<span class="string">&quot;date&quot;</span>))</span><br></pre></td></tr></table></figure></li><li><p>根据客户主键和年月日分组，计算每人每天下单数量和总金额</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"> .groupBy(<span class="string">&quot;customer_id&quot;</span>, <span class="string">&quot;year&quot;</span>, <span class="string">&quot;month&quot;</span>, <span class="string">&quot;day&quot;</span>)</span><br><span class="line"><span class="comment">// as 重命名</span></span><br><span class="line"><span class="comment">// lit 把数值、日期或字符串包装成列对象</span></span><br><span class="line"><span class="comment">// count(lit(1)) =&gt; count(1) =&gt; 组内计数</span></span><br><span class="line"> .agg(sum($<span class="string">&quot;order_money&quot;</span>) as <span class="string">&quot;total_amount&quot;</span>, count(lit(<span class="number">1</span>)) as <span class="string">&quot;total_count&quot;</span>)</span><br></pre></td></tr></table></figure></li><li><p>由于还需要一个客户名称字段，所以需要再连接一下客户表取得客户名称字段</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 根据customer_id字段内连接</span></span><br><span class="line">.join(frame, <span class="string">&quot;customer_id&quot;</span>)</span><br></pre></td></tr></table></figure></li><li><p>查询所需要的字段</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">.select(<span class="string">&quot;customer_id&quot;</span>, <span class="string">&quot;customer_name&quot;</span>, <span class="string">&quot;total_amount&quot;</span>, <span class="string">&quot;total_count&quot;</span>, <span class="string">&quot;year&quot;</span>, <span class="string">&quot;month&quot;</span>, <span class="string">&quot;day&quot;</span>)</span><br></pre></td></tr></table></figure></li><li><p>写入dws层</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">.write </span><br><span class="line"><span class="comment">// 表结构中要求年月日为分区字段</span></span><br><span class="line"><span class="comment">// 但是加上这行，执行时间非常长，然而题目并没有要求要看分区，所以我选择注释掉他</span></span><br><span class="line"><span class="comment">// .partitionBy(&quot;year&quot;, &quot;month&quot;, &quot;day&quot;)</span></span><br><span class="line">.mode(<span class="string">&quot;overwrite&quot;</span>)</span><br><span class="line">.saveAsTable(<span class="string">&quot;dws.user_consumption_day_aggr&quot;</span>)</span><br></pre></td></tr></table></figure></li><li><p>代码</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> commerce</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.sql.functions._</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Created By `Super小飞象` on 2023/2/18 19:33</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">Analyse1</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="keyword">import</span> spark.implicits._</span><br><span class="line">    <span class="keyword">val</span> frame = spark.table(<span class="string">&quot;dwd.dim_customer_inf&quot;</span>)</span><br><span class="line">      .select(<span class="string">&quot;customer_id&quot;</span>, <span class="string">&quot;customer_name&quot;</span>)</span><br><span class="line">    spark.table(<span class="string">&quot;dwd.fact_order_master&quot;</span>)</span><br><span class="line">      .where(&#x27;order_status === <span class="string">&quot;已下单&quot;</span>)</span><br><span class="line">      .distinct</span><br><span class="line">      .withColumn(<span class="string">&quot;date&quot;</span>, from_unixtime(unix_timestamp($<span class="string">&quot;create_time&quot;</span>, <span class="string">&quot;yyyyMMdd&quot;</span>)))</span><br><span class="line">      .withColumn(<span class="string">&quot;year&quot;</span>, year($<span class="string">&quot;date&quot;</span>))</span><br><span class="line">      .withColumn(<span class="string">&quot;month&quot;</span>, month($<span class="string">&quot;date&quot;</span>))</span><br><span class="line">      .withColumn(<span class="string">&quot;day&quot;</span>, dayofmonth($<span class="string">&quot;date&quot;</span>))</span><br><span class="line">      .groupBy(<span class="string">&quot;customer_id&quot;</span>, <span class="string">&quot;year&quot;</span>, <span class="string">&quot;month&quot;</span>, <span class="string">&quot;day&quot;</span>)</span><br><span class="line">      .agg(sum($<span class="string">&quot;order_money&quot;</span>) as <span class="string">&quot;total_amount&quot;</span>, count(lit(<span class="number">1</span>)) as <span class="string">&quot;total_count&quot;</span>)</span><br><span class="line">      .join(frame, <span class="string">&quot;customer_id&quot;</span>)</span><br><span class="line">      .select(<span class="string">&quot;customer_id&quot;</span>, <span class="string">&quot;customer_name&quot;</span>, <span class="string">&quot;total_amount&quot;</span>, <span class="string">&quot;total_count&quot;</span>, <span class="string">&quot;year&quot;</span>, <span class="string">&quot;month&quot;</span>, <span class="string">&quot;day&quot;</span>)</span><br><span class="line">      .write</span><br><span class="line"><span class="comment">//      .partitionBy(&quot;year&quot;, &quot;month&quot;, &quot;day&quot;)</span></span><br><span class="line">      .mode(<span class="string">&quot;overwrite&quot;</span>)</span><br><span class="line">      .saveAsTable(<span class="string">&quot;dws.user_consumption_day_aggr&quot;</span>)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>结果</p><p>select * from dws.user_consumption_day_aggr order by customer_id desc, total_amount desc limit 5;</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">19999</span>吉秀芳<span class="number">2967.75</span><span class="number">1</span><span class="number">2022</span><span class="number">4</span><span class="number">15</span></span><br><span class="line"><span class="number">19999</span>吉秀芳<span class="number">775.75</span><span class="number">1</span><span class="number">2022</span><span class="number">5</span><span class="number">7</span></span><br><span class="line"><span class="number">19998</span>赵丹丹<span class="number">7215.19</span><span class="number">1</span><span class="number">2022</span><span class="number">4</span><span class="number">6</span></span><br><span class="line"><span class="number">19998</span>赵丹丹<span class="number">3303.48</span><span class="number">1</span><span class="number">2022</span><span class="number">4</span><span class="number">2</span></span><br><span class="line"><span class="number">19997</span>解娜<span class="number">11474.22</span><span class="number">1</span><span class="number">2022</span><span class="number">3</span><span class="number">30</span></span><br></pre></td></tr></table></figure></li></ol><h2 id="第二题"><a href="#第二题" class="headerlink" title="第二题"></a>第二题</h2><h3 id="题目-1"><a href="#题目-1" class="headerlink" title="题目"></a>题目</h3><p>根据<code>dwd</code>层表统计每个城市每月下单的数量和每月下单的总金额（以<code>order_master</code>中的地址为判断依据），并按照<code>province</code>，<code>year</code>，<code>month</code>进行分组,按照<code>total_amount</code>逆序排序，形成<code>sequence</code>值，将计算结果存入<code>dws</code>数据库<code>city_consumption_day_aggr</code>表中，然后使用<code>hive cli</code>根据订单总数、订单总金额均为降序排序，查询出前5条，在查询时对于订单总金额字段将其转为bigint类型（避免用科学计数法展示）；</p><p><code>city_consumption_day_aggr</code>表结构</p><table><thead><tr><th>字段</th><th>类型</th><th>中文含义</th><th>备注</th></tr></thead><tbody><tr><td>city_name</td><td>string</td><td>城市名称</td><td></td></tr><tr><td>province_name</td><td>string</td><td>省份名称</td><td></td></tr><tr><td>total_amount</td><td>double</td><td>订单总金额</td><td>当月订单总金额</td></tr><tr><td>total_count</td><td>int</td><td>订单总数</td><td>当月订单总数</td></tr><tr><td>sequence</td><td>int</td><td>次序</td><td>即当月中该城市消费额在该省中的排名（分组排序）</td></tr><tr><td>year</td><td>int</td><td>年</td><td>订单产生的年,为动态分区字段</td></tr><tr><td>month</td><td>int</td><td>月</td><td>订单产生的月,为动态分区字段</td></tr></tbody></table><h3 id="思路-1"><a href="#思路-1" class="headerlink" title="思路"></a>思路</h3><p>挺简单的，先生成年月两列，再根据省份、城市和年月分组，统计每个城市每月下单的数量和每月下单的总金额，并按照<code>province</code>，<code>year</code>，<code>month</code>进行分组,按照<code>total_amount</code>逆序排序，形成<code>sequence</code>值。</p><h3 id="开始-1"><a href="#开始-1" class="headerlink" title="开始"></a>开始</h3><ol><li><p>读取<code>fact_order_master</code>表只取订单状态为下单的订单并且进行去重</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> spark.implicits._</span><br><span class="line">spark.table(<span class="string">&quot;dwd.fact_order_master&quot;</span>)</span><br><span class="line">  .where(&#x27;order_status === <span class="string">&quot;已下单&quot;</span>)</span><br><span class="line">  .distinct</span><br></pre></td></tr></table></figure></li><li><p>生成年月两列，根据省份、城市和年月分组</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">.withColumn(<span class="string">&quot;date&quot;</span>, from_unixtime(unix_timestamp($<span class="string">&quot;create_time&quot;</span>, <span class="string">&quot;yyyyMMdd&quot;</span>)))</span><br><span class="line">.withColumn(<span class="string">&quot;year&quot;</span>, year($<span class="string">&quot;date&quot;</span>))</span><br><span class="line">.withColumn(<span class="string">&quot;month&quot;</span>, month($<span class="string">&quot;date&quot;</span>))</span><br><span class="line">.groupBy(<span class="string">&quot;province&quot;</span>, <span class="string">&quot;city&quot;</span>, <span class="string">&quot;year&quot;</span>, <span class="string">&quot;month&quot;</span>)</span><br></pre></td></tr></table></figure></li><li><p>统计每个城市每月下单的数量和每月下单的总金额</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">.agg(sum($<span class="string">&quot;order_money&quot;</span>) as <span class="string">&quot;total_amount&quot;</span>, count(lit(<span class="number">1</span>)) as <span class="string">&quot;total_count&quot;</span>)</span><br></pre></td></tr></table></figure></li><li><p>按照<code>province</code>，<code>year</code>，<code>month</code>进行分组,按照<code>total_amount</code>逆序排序，形成<code>sequence</code>值</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">.withColumn(<span class="string">&quot;sequence&quot;</span>, row_number over <span class="type">Window</span>.partitionBy(<span class="string">&quot;province&quot;</span>, <span class="string">&quot;year&quot;</span>, <span class="string">&quot;month&quot;</span>).orderBy($<span class="string">&quot;total_amount&quot;</span>.desc))</span><br></pre></td></tr></table></figure></li><li><p>查询字段，该改名的改名，转换类型的转换类型</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">.select(</span><br><span class="line">$<span class="string">&quot;city&quot;</span> as <span class="string">&quot;city_name&quot;</span>,</span><br><span class="line">  $<span class="string">&quot;province&quot;</span> as <span class="string">&quot;province_name&quot;</span>,</span><br><span class="line">   <span class="comment">// 在查询时对于订单总金额字段将其转为bigint类型</span></span><br><span class="line">   <span class="comment">// 讲道理应该是在hive cli查询的时候转，但是那样多麻烦啊，这里转就好</span></span><br><span class="line">  $<span class="string">&quot;total_amount&quot;</span> cast <span class="string">&quot;bigint&quot;</span>,</span><br><span class="line"> $<span class="string">&quot;total_count&quot;</span>,</span><br><span class="line"> $<span class="string">&quot;sequence&quot;</span>,</span><br><span class="line"> $<span class="string">&quot;year&quot;</span>,</span><br><span class="line"> $<span class="string">&quot;month&quot;</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure></li><li><p>存入</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">.write</span><br><span class="line"><span class="comment">// 注释掉</span></span><br><span class="line"><span class="comment">// .partitionBy(&quot;year&quot;, &quot;month&quot;)</span></span><br><span class="line">.mode(<span class="string">&quot;overwrite&quot;</span>)</span><br><span class="line">.saveAsTable(<span class="string">&quot;dws.city_consumption_day_aggr&quot;</span>)</span><br></pre></td></tr></table></figure></li><li><p>代码</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> commerce</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.sql.expressions.<span class="type">Window</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.sql.functions._</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Created By `Super小飞象` on 2023/2/18 20:44</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">Analyse2</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="keyword">import</span> spark.implicits._</span><br><span class="line">    spark.table(<span class="string">&quot;dwd.fact_order_master&quot;</span>)</span><br><span class="line">      .where(&#x27;order_status === <span class="string">&quot;已下单&quot;</span>)</span><br><span class="line">      .distinct</span><br><span class="line">      .withColumn(<span class="string">&quot;date&quot;</span>, from_unixtime(unix_timestamp($<span class="string">&quot;create_time&quot;</span>, <span class="string">&quot;yyyyMMdd&quot;</span>)))</span><br><span class="line">      .withColumn(<span class="string">&quot;year&quot;</span>, year($<span class="string">&quot;date&quot;</span>))</span><br><span class="line">      .withColumn(<span class="string">&quot;month&quot;</span>, month($<span class="string">&quot;date&quot;</span>))</span><br><span class="line">      .groupBy(<span class="string">&quot;province&quot;</span>, <span class="string">&quot;city&quot;</span>, <span class="string">&quot;year&quot;</span>, <span class="string">&quot;month&quot;</span>)</span><br><span class="line">      .agg(sum($<span class="string">&quot;order_money&quot;</span>) as <span class="string">&quot;total_amount&quot;</span>, count(lit(<span class="number">1</span>)) as <span class="string">&quot;total_count&quot;</span>)</span><br><span class="line">      .withColumn(<span class="string">&quot;sequence&quot;</span>, row_number over <span class="type">Window</span>.partitionBy(<span class="string">&quot;province&quot;</span>, <span class="string">&quot;year&quot;</span>, <span class="string">&quot;month&quot;</span>).orderBy($<span class="string">&quot;total_amount&quot;</span>.desc))</span><br><span class="line">      .select(</span><br><span class="line">        $<span class="string">&quot;city&quot;</span> as <span class="string">&quot;city_name&quot;</span>,</span><br><span class="line">        $<span class="string">&quot;province&quot;</span> as <span class="string">&quot;province_name&quot;</span>,</span><br><span class="line">        $<span class="string">&quot;total_amount&quot;</span> cast <span class="string">&quot;bigint&quot;</span>,</span><br><span class="line">        $<span class="string">&quot;total_count&quot;</span>,</span><br><span class="line">        $<span class="string">&quot;sequence&quot;</span>,</span><br><span class="line">        $<span class="string">&quot;year&quot;</span>,</span><br><span class="line">        $<span class="string">&quot;month&quot;</span></span><br><span class="line">      )</span><br><span class="line">      .write</span><br><span class="line">      <span class="comment">// .partitionBy(&quot;year&quot;, &quot;month&quot;)</span></span><br><span class="line">      .mode(<span class="string">&quot;overwrite&quot;</span>)</span><br><span class="line">      .saveAsTable(<span class="string">&quot;dws.city_consumption_day_aggr&quot;</span>)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ol><h2 id="第三题"><a href="#第三题" class="headerlink" title="第三题"></a>第三题</h2><h3 id="题目-2"><a href="#题目-2" class="headerlink" title="题目"></a>题目</h3><p>请根据<code>dwd</code>层表计算出每个城市月平均订单金额和该城市所在省份月平均订单金额相比较结果（“高&#x2F;低&#x2F;相同”）,存入ClickHouse数据库<code>shtd_result</code>的<code>cityavgcmpprovince</code>表中（表结构如下），然后在Linux的ClickHouse命令行中根据城市平均订单金额、省份平均订单金额均为降序排序，查询出前5条；</p><p><code>cityavgcmpprovince</code>表结构</p><table><thead><tr><th>字段</th><th>类型</th><th>中文含义</th><th>备注</th></tr></thead><tbody><tr><td>cityname</td><td>text</td><td>城市份名称</td><td></td></tr><tr><td>cityavgconsumption</td><td>double</td><td>该城市平均订单金额</td><td></td></tr><tr><td>provincename</td><td>text</td><td>省份名称</td><td></td></tr><tr><td>provinceavgconsumption</td><td>double</td><td>该省平均订单金额</td><td></td></tr><tr><td>comparison</td><td>text</td><td>比较结果</td><td>城市平均订单金额和该省平均订单金额比较结果，值为：高&#x2F;低&#x2F;相同</td></tr></tbody></table><h4 id="思路-2"><a href="#思路-2" class="headerlink" title="思路"></a>思路</h4><p>生成年月两列，分别计算出每个城市每月平均订单金额和每个省份每月平均订单金额作为两个DataFrame对象，以省份为连接条件连接这两个DataFrame对象，比较城市月平均订单金额和所在省份平均订单金额大小并生成<code>comparison</code>字段</p><h4 id="当时只写到这里，这个可能就不更新了。"><a href="#当时只写到这里，这个可能就不更新了。" class="headerlink" title="当时只写到这里，这个可能就不更新了。"></a>当时只写到这里，这个可能就不更新了。</h4>]]></content>
      
      
      <categories>
          
          <category> 大数据比赛 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 大数据 </tag>
            
            <tag> Spark </tag>
            
            <tag> Hive </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Spark读写HBase</title>
      <link href="/2023/02/27/%E8%AF%BB%E5%86%99HBase/"/>
      <url>/2023/02/27/%E8%AF%BB%E5%86%99HBase/</url>
      
        <content type="html"><![CDATA[<p>版权：flyohh</p><h2 id="spark读取hbase"><a href="#spark读取hbase" class="headerlink" title="spark读取hbase"></a>spark读取hbase</h2><h3 id="准备"><a href="#准备" class="headerlink" title="准备"></a>准备</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">1、进入hbase客户端</span><br><span class="line">hbase shell</span><br><span class="line">2、建表 </span><br><span class="line">create &#x27;student&#x27;, &#x27;info&#x27;</span><br><span class="line">3、插入测试数据</span><br><span class="line">    put &#x27;student&#x27;,&#x27;1&#x27;,&#x27;info:name&#x27;,&#x27;Xueqian&#x27;</span><br><span class="line">    put &#x27;student&#x27;,&#x27;1&#x27;,&#x27;info:gender&#x27;,&#x27;F&#x27;</span><br><span class="line">    put &#x27;student&#x27;,&#x27;1&#x27;,&#x27;info:age&#x27;,&#x27;23&#x27;</span><br><span class="line">    put &#x27;student&#x27;,&#x27;2&#x27;,&#x27;info:name&#x27;,&#x27;Weiliang&#x27;</span><br><span class="line">    put &#x27;student&#x27;,&#x27;2&#x27;,&#x27;info:gender&#x27;,&#x27;M&#x27;</span><br><span class="line">    put &#x27;student&#x27;,&#x27;2&#x27;,&#x27;info:age&#x27;,&#x27;24&#x27;</span><br></pre></td></tr></table></figure><h3 id="教程"><a href="#教程" class="headerlink" title="教程"></a>教程</h3><ol><li><p>创建hbase的配置类对象</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">val hbaseConf = HBaseConfiguration.create()</span><br></pre></td></tr></table></figure><ul><li><p>为什么不是 new HBaseConfiguration() ？</p></li><li><p>去看构造方法，源码中有一行代码如下</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">LOG.warn(&quot;instantiating HBaseConfiguration() is deprecated. Please use HBaseConfiguration#create() to construct a plain Configuration&quot;);</span><br></pre></td></tr></table></figure></li><li><p>翻译一下就是：实例化 HBaseConfiguration（） 已弃用。请使用 HBaseConfiguration#create（） 构造一个普通的配置</p></li></ul></li><li><p>添加hbase的配置</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hbaseConf.set(&quot;hbase.zookeeper.quorum&quot;, &quot;bigdata1:2182&quot;)</span><br><span class="line">hbaseConf.set(TableInputFormat.Input_Table, &quot;student&quot;)</span><br></pre></td></tr></table></figure><ul><li><p>读表需要什么？首先就是要先连接上吧。没记错的话，hbase的通信是zookeeper负责的，可以明确的是在代码里你只需要告诉你的程序zookeeper所在的ip地址和端口号，你的hbase就可以连接上。这里配置bigdata1就够了，为了代码的健壮性，你也可以写上其他两个主机的地址，用英文逗号隔开。</p></li><li><p>TableInputFormat.Input_Table，这是啥？这是”类名.常量名”，众所周知全部大写的变量是常量，即静态的不可重新赋值的变量。在源码中有：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">public static final String INPUT_TABLE = &quot;hbase.mapreduce.inputtable&quot;;</span><br></pre></td></tr></table></figure><p>和上边一样，你得告诉程序你要读取哪个表，配置项为”hbase.mapreduce.inputtable”，为了提高你的工作效率，人家提供了一个常量给你使用，你就不需要记这个配置项，你只需要知道 INPUT_TABLE 需要配置就可以了。</p><p>基于上面，你也可以将 hbaseConf.set(TableInputFormat.Input_Table, “student”) 改成  hbaseConf.set(“hbase.mapreduce.inputtable”, “student”)。</p><p>注意：导包不要导错，正确的是 import org.apache.hadoop.hbase.mapreduce.TableInputFormat</p></li></ul></li><li><p>创建spark的操作对象</p><p>就是SparkContext的实例对象，这里我的方法是从SparkSession的对象里拿一个sc对象，如下</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> spark: <span class="type">SparkSession</span> = <span class="type">SparkSession</span>.builder()</span><br><span class="line">    .appName(<span class="string">&quot;hbase&quot;</span>)</span><br><span class="line">    .master(<span class="string">&quot;local[*]&quot;</span>)</span><br><span class="line">    .enableHiveSupport()</span><br><span class="line">    .getOrCreate()</span><br><span class="line"><span class="keyword">val</span> sc = spark.sparkContext</span><br></pre></td></tr></table></figure></li><li><p>读取hbase</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> rdd:<span class="type">RDD</span>[(<span class="type">ImmutableBytesWritable</span>, <span class="type">Result</span>)] = sc.newAPIHadoopRDD(</span><br><span class="line">    hbaseConf,</span><br><span class="line">    classOf[<span class="type">TableInputFormat</span>],</span><br><span class="line">    classOf[<span class="type">ImmutableBytesWritable</span>],</span><br><span class="line">    classOf[<span class="type">Result</span>]</span><br><span class="line">)</span><br></pre></td></tr></table></figure><ul><li><p>sc.newAPIHadoopRDD()</p><ol><li><p>调用该方法返回一个RDD对象</p></li><li><p>该方法需要四个参数</p><ul><li>hbase配置对象</li><li>TableInputFormat的class对象</li><li>ImmutableBytesWritable的class对象，用作键或值的字节序列，和网络传输过程中的序列化有关</li><li>Result的class对象</li></ul></li><li><p>参数暂时就固定这四个，别的值咱也没试过，没接触过。</p></li><li><p>classof[T]的作用是获取T类的class对象</p></li><li><p>值得注意的是，参数三和参数四会被组合起来作为返回的RDD对象每一行数据的数据类型，如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">val rdd:RDD[(ImmutableBytesWritable, Result)]</span><br></pre></td></tr></table></figure></li></ol></li><li><p>返回的RDD，每一行都是<code>(ImmutableBytesWritable, Result)</code>这样的数据，就我目前的理解，第一个值用不上，数据都在Result对象中</p></li></ul></li><li><p>输出rdd</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">rdd.foreach&#123;</span><br><span class="line"> <span class="keyword">case</span> (_, result) =&gt;</span><br><span class="line">    <span class="keyword">val</span> row: <span class="type">Array</span>[<span class="type">Byte</span>] = result.getRow</span><br><span class="line">    <span class="keyword">val</span> key = <span class="type">Bytes</span>.toString(row)</span><br><span class="line">    <span class="keyword">val</span> name = <span class="type">Bytes</span>.toString(result.getValue(<span class="type">Bytes</span>.toBytes(<span class="string">&quot;info&quot;</span>), <span class="type">Bytes</span>.toBytes(<span class="string">&quot;name&quot;</span>)))</span><br><span class="line">    <span class="keyword">val</span> age = <span class="type">Bytes</span>.toString(result.getValue(<span class="type">Bytes</span>.toBytes(<span class="string">&quot;info&quot;</span>), <span class="type">Bytes</span>.toBytes(<span class="string">&quot;age&quot;</span>)))</span><br><span class="line">    <span class="keyword">val</span> gender = <span class="type">Bytes</span>.toString(result.getValue(<span class="type">Bytes</span>.toBytes(<span class="string">&quot;info&quot;</span>), <span class="type">Bytes</span>.toBytes(<span class="string">&quot;gender&quot;</span>)))</span><br><span class="line">    println(key, name, age, gender)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li><p>rdd.foreach() </p><p>这个不解释</p></li><li><p>case (_, result)</p><ol><li>模式匹配，说了第一个值用不上，所以给个 <code>_</code> 占个位就行</li><li>第二个值取个名，数据类型为 Result</li></ol></li><li><p>result.getRow</p><p>获取数据的行键，返回的数据类型为 Array[Byte]</p></li><li><p>Bytes.toString(result.getRow)</p><ol><li>学了hbase的都知道，麻烦的很，拿到的数据是字节数组，得转成字符串才行</li><li>hbase提供了工具类，Bytes.toString(参数)，用这个把参数转成字符串</li></ol></li><li><p>result.getValue(Bytes.toBytes(“info”), Bytes.toBytes(“name”))</p><ol><li>result.getValue(参数1，参数2)</li><li>取数据的值嘛，第一个参数指定列族，第二个参数指定列名</li><li>麻烦的很，参数要求你是字节数组的，这里又得转成字符串转字节数组传进去</li><li>Bytes.toBytes(“info”)，将info转为字符串</li><li>其他同理</li></ol></li></ul></li></ol><h3 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> hbaseDemo</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.hbase.<span class="type">HBaseConfiguration</span></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.hbase.client.<span class="type">Result</span></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.hbase.io.<span class="type">ImmutableBytesWritable</span></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.hbase.mapreduce.<span class="type">TableInputFormat</span></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.hbase.util.<span class="type">Bytes</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">ReadHBaseDemo</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="keyword">val</span> hbaseConf = <span class="type">HBaseConfiguration</span>.create()</span><br><span class="line">    <span class="comment">// 注：我习惯把spark写在包对象中，所以这里看不到，需要的话参考教程中第三步即可</span></span><br><span class="line">    <span class="keyword">val</span> sc = spark.sparkContext</span><br><span class="line">    hbaseConf.set(<span class="type">TableInputFormat</span>.<span class="type">INPUT_TABLE</span>, <span class="string">&quot;student&quot;</span>)</span><br><span class="line">    hbaseConf.set(<span class="string">&quot;hbase.zookeeper.quorum&quot;</span>, <span class="string">&quot;bigdata1:2181&quot;</span>)</span><br><span class="line">    <span class="keyword">val</span> rdd = sc.newAPIHadoopRDD(</span><br><span class="line">      hbaseConf,</span><br><span class="line">      classOf[<span class="type">TableInputFormat</span>],</span><br><span class="line">      classOf[<span class="type">ImmutableBytesWritable</span>],</span><br><span class="line">      classOf[<span class="type">Result</span>]</span><br><span class="line">    )</span><br><span class="line">    rdd.foreach&#123;</span><br><span class="line">      <span class="keyword">case</span> (_, result) =&gt; &#123;</span><br><span class="line">        <span class="keyword">val</span> key = <span class="type">Bytes</span>.toString(result.getRow)</span><br><span class="line">        <span class="keyword">val</span> name = <span class="type">Bytes</span>.toString(result.getValue(<span class="type">Bytes</span>.toBytes(<span class="string">&quot;info&quot;</span>), <span class="type">Bytes</span>.toBytes(<span class="string">&quot;name&quot;</span>)))</span><br><span class="line">        <span class="keyword">val</span> age = <span class="type">Bytes</span>.toString(result.getValue(<span class="type">Bytes</span>.toBytes(<span class="string">&quot;info&quot;</span>), <span class="type">Bytes</span>.toBytes(<span class="string">&quot;age&quot;</span>)))</span><br><span class="line">        <span class="keyword">val</span> gender = <span class="type">Bytes</span>.toString(result.getValue(<span class="type">Bytes</span>.toBytes(<span class="string">&quot;info&quot;</span>), <span class="type">Bytes</span>.toBytes(<span class="string">&quot;gender&quot;</span>)))</span><br><span class="line">        println(key, name, age, gender)</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="spark写入hbase"><a href="#spark写入hbase" class="headerlink" title="spark写入hbase"></a>spark写入hbase</h2><h3 id="教程-1"><a href="#教程-1" class="headerlink" title="教程"></a>教程</h3><ol><li><p>创建hbase的配置类对象</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> hbaseConf = <span class="type">HBaseConfiguration</span>.create()</span><br></pre></td></tr></table></figure></li><li><p>写好配置</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hbaseConf.set(<span class="string">&quot;hbase.zookeeper.quorum&quot;</span>, <span class="string">&quot;bigdata1:2181&quot;</span>)</span><br><span class="line">hbaseConf.set(<span class="type">TableOutputFormat</span>.<span class="type">OUTPUT_TABLE</span>, <span class="string">&quot;student&quot;</span>)</span><br></pre></td></tr></table></figure><ul><li>注意这里是OutPut了，写出&#x2F;输出，上边是Input，读取</li></ul></li><li><p>再创建一个配置对象</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> job = <span class="keyword">new</span> <span class="type">JobConf</span>(hbaseConf)</span><br></pre></td></tr></table></figure><ul><li>需要一个配置，指定输出的格式化类</li><li>HBaseConfiguration，在这里没法配置，至少我没找到</li><li>JobConf对象有个方法setOutputFormat()，用于配置输出的格式化类</li><li>为什么上边不需要？因为上边的sc有个newAPIHadoopRDD方法，在该方法里面指定</li><li>对了记得把HBaseConfiguration对象丢进去，这样在他里边配置的东西就也都进去了</li></ul></li><li><p>构建标准的可以写入到hbase的rdd对象</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> rdd: <span class="type">RDD</span>[(<span class="type">ImmutableBytesWritable</span>, <span class="type">Put</span>)] = sc.makeRDD(<span class="type">Array</span>(<span class="type">Array</span>(<span class="string">&quot;5&quot;</span>, <span class="string">&quot;XuMengYi&quot;</span>, <span class="string">&quot;M&quot;</span>), <span class="type">Array</span>(<span class="string">&quot;6&quot;</span>, <span class="string">&quot;&quot;</span>, <span class="string">&quot;F&quot;</span>)))</span><br><span class="line">  .map(arr =&gt; &#123;</span><br><span class="line">    <span class="keyword">val</span> put = <span class="keyword">new</span> <span class="type">Put</span>(<span class="type">Bytes</span>.toBytes(arr(<span class="number">0</span>)))</span><br><span class="line">    put.addColumn(<span class="type">Bytes</span>.toBytes(<span class="string">&quot;info&quot;</span>), <span class="type">Bytes</span>.toBytes(<span class="string">&quot;name&quot;</span>), <span class="type">Bytes</span>.toBytes(arr(<span class="number">1</span>)))</span><br><span class="line">    put.addColumn(<span class="type">Bytes</span>.toBytes(<span class="string">&quot;info&quot;</span>), <span class="type">Bytes</span>.toBytes(<span class="string">&quot;gender&quot;</span>), <span class="type">Bytes</span>.toBytes(arr(<span class="number">2</span>)))</span><br><span class="line">    (<span class="keyword">new</span> <span class="type">ImmutableBytesWritable</span>, put)</span><br><span class="line">  &#125;)</span><br></pre></td></tr></table></figure><ul><li>sc.makeRDD(Array(Array(“5”, “XuMengYi”, “M”), Array(“6”, “”, “F”)))<ol><li>构造一个rdd对象，不多解释</li></ol></li><li>.map()<ol><li>不解释</li></ol></li><li>val put &#x3D; new Put(Bytes.toBytes(arr(0)))<ol><li>构造一个Put对象，构造方法参数传入行键，数据类型为字节数组所以需要转换。</li><li>该对象会在最后做返回值</li><li>首先指定行键构造对象，然后添加列信息(列族、列名、值)，此时构造完毕进行返回</li></ol></li><li>put.addColumn(Bytes.toBytes(“info”), Bytes.toBytes(“name”), Bytes.toBytes(arr(1)))<ol><li>添加列，指定 列族、列名、值</li></ol></li><li>(new ImmutableBytesWritable, put)<ol><li>这是必备的返回值形式</li><li>参数1是ImmutableBytesWritable对象，需要new一下，因为不是接受一个class对象</li><li>参数2是Put类实例对象</li></ol></li></ul></li><li><p>写入</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rdd.saveAsHadoopDataset(job)</span><br></pre></td></tr></table></figure></li></ol><h3 id="代码-1"><a href="#代码-1" class="headerlink" title="代码"></a>代码</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> hbaseDemo</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.hbase.<span class="type">HBaseConfiguration</span></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.hbase.client.<span class="type">Put</span></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.hbase.io.<span class="type">ImmutableBytesWritable</span></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.hbase.mapred.<span class="type">TableOutputFormat</span></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.hbase.util.<span class="type">Bytes</span></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapred.<span class="type">JobConf</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">WriteHbaseDemo</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="keyword">val</span> hbaseConf = <span class="type">HBaseConfiguration</span>.create()</span><br><span class="line">hbaseConf.set(<span class="string">&quot;hbase.zookeeper.quorum&quot;</span>, <span class="string">&quot;bigdata1:2181&quot;</span>)</span><br><span class="line">hbaseConf.set(<span class="type">TableOutputFormat</span>.<span class="type">OUTPUT_TABLE</span>, <span class="string">&quot;student&quot;</span>)</span><br><span class="line">    <span class="keyword">val</span> job = <span class="keyword">new</span> <span class="type">JobConf</span>(hbaseConf)</span><br><span class="line">    job.setOutputFormat(classOf[<span class="type">TableOutputFormat</span>])</span><br><span class="line"><span class="keyword">val</span> sc = spark.sparkContext</span><br><span class="line"><span class="keyword">val</span> rdd: <span class="type">RDD</span>[(<span class="type">ImmutableBytesWritable</span>, <span class="type">Put</span>)] = sc.makeRDD(<span class="type">Array</span>(<span class="type">Array</span>(<span class="string">&quot;5&quot;</span>, <span class="string">&quot;XuMengYi&quot;</span>, <span class="string">&quot;M&quot;</span>), <span class="type">Array</span>(<span class="string">&quot;6&quot;</span>, <span class="string">&quot;&quot;</span>, <span class="string">&quot;F&quot;</span>)))</span><br><span class="line">    .map(arr =&gt; &#123;</span><br><span class="line">        <span class="keyword">val</span> put = <span class="keyword">new</span> <span class="type">Put</span>(<span class="type">Bytes</span>.toBytes(arr(<span class="number">0</span>)))</span><br><span class="line">        put.addColumn(<span class="type">Bytes</span>.toBytes(<span class="string">&quot;info&quot;</span>), <span class="type">Bytes</span>.toBytes(<span class="string">&quot;name&quot;</span>), <span class="type">Bytes</span>.toBytes(arr(<span class="number">1</span>)))</span><br><span class="line">        put.addColumn(<span class="type">Bytes</span>.toBytes(<span class="string">&quot;info&quot;</span>), <span class="type">Bytes</span>.toBytes(<span class="string">&quot;gender&quot;</span>), <span class="type">Bytes</span>.toBytes(arr(<span class="number">2</span>)))</span><br><span class="line">       (<span class="keyword">new</span> <span class="type">ImmutableBytesWritable</span>, put)</span><br><span class="line">  &#125;)</span><br><span class="line">    rdd.saveAsHadoopDataset(job)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="读取hbase进阶"><a href="#读取hbase进阶" class="headerlink" title="读取hbase进阶"></a>读取hbase进阶</h2><p>好了你已经学会了读取hbase并输出，现在尝试读取一个表并且写入到hive中吧！</p><h3 id="代码-2"><a href="#代码-2" class="headerlink" title="代码"></a>代码</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> hbaseDemo</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.hbase.<span class="type">HBaseConfiguration</span></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.hbase.client.<span class="type">Result</span></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.hbase.io.<span class="type">ImmutableBytesWritable</span></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.hbase.mapreduce.<span class="type">TableInputFormat</span></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.hbase.util.<span class="type">Bytes</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.rdd.<span class="type">RDD</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">HBaseToHive</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="keyword">val</span> hbaseConf = <span class="type">HBaseConfiguration</span>.create()</span><br><span class="line">    hbaseConf.set(<span class="type">TableInputFormat</span>.<span class="type">INPUT_TABLE</span>, <span class="string">&quot;order_master&quot;</span>)</span><br><span class="line">    hbaseConf.set(<span class="string">&quot;hbase.zookeeper.quorum&quot;</span>, <span class="string">&quot;bigdata1:2181&quot;</span>)</span><br><span class="line">    <span class="keyword">val</span> rdd: <span class="type">RDD</span>[(<span class="type">ImmutableBytesWritable</span>, <span class="type">Result</span>)] = spark.sparkContext</span><br><span class="line">      .newAPIHadoopRDD(</span><br><span class="line">        hbaseConf,</span><br><span class="line">        classOf[<span class="type">TableInputFormat</span>],</span><br><span class="line">        classOf[<span class="type">ImmutableBytesWritable</span>],</span><br><span class="line">        classOf[<span class="type">Result</span>]</span><br><span class="line">      )</span><br><span class="line">    <span class="keyword">import</span> spark.implicits._</span><br><span class="line">    rdd.map &#123;</span><br><span class="line">      <span class="keyword">case</span> (_, result) =&gt;</span><br><span class="line">        <span class="keyword">val</span> address = <span class="type">Bytes</span>.toString(result.getValue(<span class="type">Bytes</span>.toBytes(<span class="string">&quot;info&quot;</span>), <span class="type">Bytes</span>.toBytes(<span class="string">&quot;address&quot;</span>)))</span><br><span class="line">        <span class="keyword">val</span> city = <span class="type">Bytes</span>.toString(result.getValue(<span class="type">Bytes</span>.toBytes(<span class="string">&quot;info&quot;</span>), <span class="type">Bytes</span>.toBytes(<span class="string">&quot;city&quot;</span>)))</span><br><span class="line">        <span class="keyword">val</span> create_time = <span class="type">Bytes</span>.toString(result.getValue(<span class="type">Bytes</span>.toBytes(<span class="string">&quot;info&quot;</span>), <span class="type">Bytes</span>.toBytes(<span class="string">&quot;create_time&quot;</span>)))</span><br><span class="line">        <span class="keyword">val</span> customer_id = <span class="type">Bytes</span>.toString(result.getValue(<span class="type">Bytes</span>.toBytes(<span class="string">&quot;info&quot;</span>), <span class="type">Bytes</span>.toBytes(<span class="string">&quot;customer_id&quot;</span>)))</span><br><span class="line">        <span class="keyword">val</span> district_money = <span class="type">Bytes</span>.toString(result.getValue(<span class="type">Bytes</span>.toBytes(<span class="string">&quot;info&quot;</span>), <span class="type">Bytes</span>.toBytes(<span class="string">&quot;district_money&quot;</span>)))</span><br><span class="line">        <span class="keyword">val</span> invoice_title = <span class="type">Bytes</span>.toString(result.getValue(<span class="type">Bytes</span>.toBytes(<span class="string">&quot;info&quot;</span>), <span class="type">Bytes</span>.toBytes(<span class="string">&quot;invoice_title&quot;</span>)))</span><br><span class="line">        <span class="keyword">val</span> modified_time = <span class="type">Bytes</span>.toString(result.getValue(<span class="type">Bytes</span>.toBytes(<span class="string">&quot;info&quot;</span>), <span class="type">Bytes</span>.toBytes(<span class="string">&quot;modified_time&quot;</span>)))</span><br><span class="line">        <span class="keyword">val</span> order_id = <span class="type">Bytes</span>.toString(result.getValue(<span class="type">Bytes</span>.toBytes(<span class="string">&quot;info&quot;</span>), <span class="type">Bytes</span>.toBytes(<span class="string">&quot;order_id&quot;</span>)))</span><br><span class="line">        <span class="keyword">val</span> order_money = <span class="type">Bytes</span>.toString(result.getValue(<span class="type">Bytes</span>.toBytes(<span class="string">&quot;info&quot;</span>), <span class="type">Bytes</span>.toBytes(<span class="string">&quot;order_money&quot;</span>)))</span><br><span class="line">        <span class="keyword">val</span> order_point = <span class="type">Bytes</span>.toString(result.getValue(<span class="type">Bytes</span>.toBytes(<span class="string">&quot;info&quot;</span>), <span class="type">Bytes</span>.toBytes(<span class="string">&quot;order_point&quot;</span>)))</span><br><span class="line">        <span class="keyword">val</span> order_sn = <span class="type">Bytes</span>.toString(result.getValue(<span class="type">Bytes</span>.toBytes(<span class="string">&quot;info&quot;</span>), <span class="type">Bytes</span>.toBytes(<span class="string">&quot;order_sn&quot;</span>)))</span><br><span class="line">        <span class="keyword">val</span> order_source = <span class="type">Bytes</span>.toString(result.getValue(<span class="type">Bytes</span>.toBytes(<span class="string">&quot;info&quot;</span>), <span class="type">Bytes</span>.toBytes(<span class="string">&quot;order_source&quot;</span>)))</span><br><span class="line">        <span class="keyword">val</span> order_status = <span class="type">Bytes</span>.toString(result.getValue(<span class="type">Bytes</span>.toBytes(<span class="string">&quot;info&quot;</span>), <span class="type">Bytes</span>.toBytes(<span class="string">&quot;order_status&quot;</span>)))</span><br><span class="line">        <span class="keyword">val</span> pay_time = <span class="type">Bytes</span>.toString(result.getValue(<span class="type">Bytes</span>.toBytes(<span class="string">&quot;info&quot;</span>), <span class="type">Bytes</span>.toBytes(<span class="string">&quot;pay_time&quot;</span>)))</span><br><span class="line">        <span class="keyword">val</span> payment_method = <span class="type">Bytes</span>.toString(result.getValue(<span class="type">Bytes</span>.toBytes(<span class="string">&quot;info&quot;</span>), <span class="type">Bytes</span>.toBytes(<span class="string">&quot;payment_method&quot;</span>)))</span><br><span class="line">        <span class="keyword">val</span> payment_money = <span class="type">Bytes</span>.toString(result.getValue(<span class="type">Bytes</span>.toBytes(<span class="string">&quot;info&quot;</span>), <span class="type">Bytes</span>.toBytes(<span class="string">&quot;payment_money&quot;</span>)))</span><br><span class="line">        <span class="keyword">val</span> province = <span class="type">Bytes</span>.toString(result.getValue(<span class="type">Bytes</span>.toBytes(<span class="string">&quot;info&quot;</span>), <span class="type">Bytes</span>.toBytes(<span class="string">&quot;province&quot;</span>)))</span><br><span class="line">        <span class="keyword">val</span> receive_time = <span class="type">Bytes</span>.toString(result.getValue(<span class="type">Bytes</span>.toBytes(<span class="string">&quot;info&quot;</span>), <span class="type">Bytes</span>.toBytes(<span class="string">&quot;receive_time&quot;</span>)))</span><br><span class="line">        <span class="keyword">val</span> shipping_comp_name = <span class="type">Bytes</span>.toString(result.getValue(<span class="type">Bytes</span>.toBytes(<span class="string">&quot;info&quot;</span>), <span class="type">Bytes</span>.toBytes(<span class="string">&quot;shipping_comp_name&quot;</span>)))</span><br><span class="line">        <span class="keyword">val</span> shipping_money = <span class="type">Bytes</span>.toString(result.getValue(<span class="type">Bytes</span>.toBytes(<span class="string">&quot;info&quot;</span>), <span class="type">Bytes</span>.toBytes(<span class="string">&quot;shipping_money&quot;</span>)))</span><br><span class="line">        <span class="keyword">val</span> shipping_sn = <span class="type">Bytes</span>.toString(result.getValue(<span class="type">Bytes</span>.toBytes(<span class="string">&quot;info&quot;</span>), <span class="type">Bytes</span>.toBytes(<span class="string">&quot;shipping_sn&quot;</span>)))</span><br><span class="line">        <span class="keyword">val</span> shipping_time = <span class="type">Bytes</span>.toString(result.getValue(<span class="type">Bytes</span>.toBytes(<span class="string">&quot;info&quot;</span>), <span class="type">Bytes</span>.toBytes(<span class="string">&quot;shipping_time&quot;</span>)))</span><br><span class="line">        <span class="keyword">val</span> shipping_user = <span class="type">Bytes</span>.toString(result.getValue(<span class="type">Bytes</span>.toBytes(<span class="string">&quot;info&quot;</span>), <span class="type">Bytes</span>.toBytes(<span class="string">&quot;shipping_user&quot;</span>)))</span><br><span class="line">        <span class="type">OrderMaster</span>(order_id, order_sn, customer_id, shipping_user, province, city, address, order_source, payment_method, order_money, district_money, shipping_money, payment_money, shipping_comp_name, shipping_sn, create_time, shipping_time, pay_time, receive_time, order_status, order_point, invoice_title, modified_time)</span><br><span class="line">    &#125;</span><br><span class="line">      .toDF</span><br><span class="line">      .write</span><br><span class="line">      .mode(<span class="string">&quot;overwrite&quot;</span>)</span><br><span class="line">      .saveAsTable(<span class="string">&quot;ods.order_master&quot;</span>)</span><br><span class="line">    spark.table(<span class="string">&quot;ods.order_master&quot;</span>).show</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">case</span> <span class="class"><span class="keyword">class</span> <span class="title">OrderMaster</span>(<span class="params"></span></span></span><br><span class="line"><span class="params"><span class="class">                          order_id: <span class="type">String</span>,</span></span></span><br><span class="line"><span class="params"><span class="class">                          order_sn: <span class="type">String</span>,</span></span></span><br><span class="line"><span class="params"><span class="class">                          customer_id: <span class="type">String</span>,</span></span></span><br><span class="line"><span class="params"><span class="class">                          shipping_user: <span class="type">String</span>,</span></span></span><br><span class="line"><span class="params"><span class="class">                          province: <span class="type">String</span>,</span></span></span><br><span class="line"><span class="params"><span class="class">                          city: <span class="type">String</span>,</span></span></span><br><span class="line"><span class="params"><span class="class">                          address: <span class="type">String</span>,</span></span></span><br><span class="line"><span class="params"><span class="class">                          order_source: <span class="type">String</span>,</span></span></span><br><span class="line"><span class="params"><span class="class">                          payment_method: <span class="type">String</span>,</span></span></span><br><span class="line"><span class="params"><span class="class">                          order_money: <span class="type">String</span>,</span></span></span><br><span class="line"><span class="params"><span class="class">                          district_money: <span class="type">String</span>,</span></span></span><br><span class="line"><span class="params"><span class="class">                          shipping_money: <span class="type">String</span>,</span></span></span><br><span class="line"><span class="params"><span class="class">                          payment_money: <span class="type">String</span>,</span></span></span><br><span class="line"><span class="params"><span class="class">                          shipping_comp_name: <span class="type">String</span>,</span></span></span><br><span class="line"><span class="params"><span class="class">                          shipping_sn: <span class="type">String</span>,</span></span></span><br><span class="line"><span class="params"><span class="class">                          create_time: <span class="type">String</span>,</span></span></span><br><span class="line"><span class="params"><span class="class">                          shipping_time: <span class="type">String</span>,</span></span></span><br><span class="line"><span class="params"><span class="class">                          pay_time: <span class="type">String</span>,</span></span></span><br><span class="line"><span class="params"><span class="class">                          receive_time: <span class="type">String</span>,</span></span></span><br><span class="line"><span class="params"><span class="class">                          order_status: <span class="type">String</span>,</span></span></span><br><span class="line"><span class="params"><span class="class">                          order_point: <span class="type">String</span>,</span></span></span><br><span class="line"><span class="params"><span class="class">                          invoice_title: <span class="type">String</span>,</span></span></span><br><span class="line"><span class="params"><span class="class">                          modified_time: <span class="type">String</span></span></span></span><br><span class="line"><span class="params"><span class="class">                        </span>)</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 大数据比赛 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 大数据 </tag>
            
            <tag> Spark </tag>
            
            <tag> HBase </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>使用Vue+Echarts+Axios画图</title>
      <link href="/2021/12/10/%E5%8F%AF%E8%A7%86%E5%8C%96%E6%89%8B%E5%86%8C/"/>
      <url>/2021/12/10/%E5%8F%AF%E8%A7%86%E5%8C%96%E6%89%8B%E5%86%8C/</url>
      
        <content type="html"><![CDATA[<p>2022年楚怡杯湖南省高职院校技能竞赛大数据赛项可视化部分的入门教学<br>版权：flyohh</p><h1 id="准备工作"><a href="#准备工作" class="headerlink" title="准备工作"></a>准备工作</h1><ol><li><p>npm切换淘宝镜像</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">npm config set registry https://registry.npm.taobao.or</span><br></pre></td></tr></table></figure></li><li><p>如果想还原npm仓库地址，只需再把地址配置成<a href="https://so.csdn.net/so/search?q=npm%E9%95%9C%E5%83%8F&spm=1001.2101.3001.7020">npm镜像</a>就可以了</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">npm config set registry https://registry.npmjs.org/</span><br></pre></td></tr></table></figure></li><li><p>查看当前镜像</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">npm config get registry</span><br></pre></td></tr></table></figure></li><li><p>创建vue工程</p><ul><li><p>查看@vue&#x2F;cli版本，确保@vue&#x2F;cli版本在4.5.0以上</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vue --version</span><br></pre></td></tr></table></figure></li><li><p>安装或者升级你的@vue&#x2F;cli</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">npm install -g @vue/cli</span><br></pre></td></tr></table></figure></li><li><p>创建工程</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vue create vue_echarts</span><br></pre></td></tr></table></figure></li><li><p>选择vue3</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[ ] Default ([Vue 2] babel, eslint)</span><br><span class="line">[√] Default (Vue 3) ([Vue 3] babel, eslint)</span><br><span class="line">[ ] Manually select features</span><br></pre></td></tr></table></figure></li></ul></li><li><p>vscode打开vue_echarts文件夹，终端运行工程，查看工程原效果</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">npm run serve</span><br></pre></td></tr></table></figure></li><li><p>整理文件目录</p><ul><li>删掉src下的App.vue和src.components目录，都用不上</li><li>如果不想用vue-route路由，那就留着components目录，以组件的形式来写vue工程</li><li>vue_echarts文件夹下创建 views 文件夹(存放若干个单个echarts图表的组件视图)</li><li>vue_echarts文件夹下创建 route 文件夹(存放index.js路由文件)</li><li>将echarts.min.js复制粘贴至 vue_echarts.assets 下</li></ul></li></ol><h1 id="第一个echarts图表"><a href="#第一个echarts图表" class="headerlink" title="第一个echarts图表"></a>第一个echarts图表</h1><h2 id="完成骨架"><a href="#完成骨架" class="headerlink" title="完成骨架"></a>完成骨架</h2><p>在views目录创建第一个图表文件<code>Bar.vue</code></p><p>把div容器给出来</p><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">template</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- ref用于获取这个dom元素 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">div</span> <span class="attr">ref</span>=<span class="string">&quot;ref_bar&quot;</span> <span class="attr">style</span>=<span class="string">&quot;width: 600px;height: 400px;&quot;</span>&lt;/<span class="attr">div</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">template</span>&gt;</span></span><br></pre></td></tr></table></figure><p>架子做出来</p><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">script</span>&gt;</span><span class="language-javascript"></span></span><br><span class="line"><span class="language-javascript">    <span class="comment">// 引入生命周期函数和ref函数</span></span></span><br><span class="line"><span class="language-javascript">    <span class="keyword">import</span> &#123; onMounted, ref &#125; <span class="keyword">from</span> <span class="string">&#x27;vue&#x27;</span></span></span><br><span class="line"><span class="language-javascript">    <span class="keyword">export</span> <span class="keyword">default</span> &#123;</span></span><br><span class="line"><span class="language-javascript">        <span class="attr">name</span>: <span class="string">&#x27;Bar&#x27;</span>,</span></span><br><span class="line"><span class="language-javascript">        <span class="attr">setup</span>: <span class="keyword">function</span>(<span class="params"></span>) &#123;</span></span><br><span class="line"><span class="language-javascript">            <span class="comment">// 该变量用于返回出去到模板，div中ref=&quot;ref_bar&quot;</span></span></span><br><span class="line"><span class="language-javascript">            <span class="comment">// 这样就可以通过 ref_bar.value 这个变量拿到dom元素</span></span></span><br><span class="line"><span class="language-javascript">            <span class="comment">// 不用 document.getElementById()</span></span></span><br><span class="line"><span class="language-javascript">            <span class="keyword">let</span> ref_bar = <span class="title function_">ref</span>()</span></span><br><span class="line"><span class="language-javascript">            <span class="comment">// 这个要写在setup里，执行时机：虚拟dom转为真实dom挂载到网页之后</span></span></span><br><span class="line"><span class="language-javascript">            <span class="title function_">onMounted</span>(<span class="function">() =&gt;</span> &#123;</span></span><br><span class="line"><span class="language-javascript">                <span class="comment">// 打印拿到的dom元素，检查一下</span></span></span><br><span class="line"><span class="language-javascript">                <span class="variable language_">console</span>.<span class="title function_">log</span>(ref_bar.<span class="property">value</span>)</span></span><br><span class="line"><span class="language-javascript">            &#125;)</span></span><br><span class="line"><span class="language-javascript">            <span class="comment">// 这里要做返回，否则无效</span></span></span><br><span class="line"><span class="language-javascript">            <span class="keyword">return</span> &#123;</span></span><br><span class="line"><span class="language-javascript">                ref_bar</span></span><br><span class="line"><span class="language-javascript">            &#125;</span></span><br><span class="line"><span class="language-javascript">        &#125;</span></span><br><span class="line"><span class="language-javascript">    &#125;</span></span><br><span class="line"><span class="language-javascript"></span><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br></pre></td></tr></table></figure><h2 id="创建App-vue"><a href="#创建App-vue" class="headerlink" title="创建App.vue"></a>创建App.vue</h2><p>在src目录下创建<code>App.vue</code>，代码如下</p><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">template</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">Bar</span> /&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">template</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">script</span>&gt;</span><span class="language-javascript"></span></span><br><span class="line"><span class="language-javascript">    <span class="keyword">import</span> <span class="title class_">Bar</span> <span class="keyword">from</span> <span class="string">&#x27;./views/Bar&#x27;</span></span></span><br><span class="line"><span class="language-javascript">    <span class="keyword">export</span> <span class="keyword">default</span> &#123;</span></span><br><span class="line"><span class="language-javascript">        <span class="attr">name</span>: <span class="string">&#x27;App&#x27;</span>,</span></span><br><span class="line"><span class="language-javascript">        <span class="attr">components</span>: &#123;<span class="title class_">Bar</span>&#125;</span></span><br><span class="line"><span class="language-javascript">    &#125;</span></span><br><span class="line"><span class="language-javascript"></span><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br></pre></td></tr></table></figure><h2 id="运行工程"><a href="#运行工程" class="headerlink" title="运行工程"></a>运行工程</h2><p>终端执行命令</p><ul><li>npm  run serve</li><li>注意：每次对文件进行修改，修改完之后都要ctrl+s进行保存，养成好习惯，避免没必要的错误</li><li>打开网页console控制台，会看见一个div，是 Bar.vue 里做的打印</li><li>至此，骨架完成，下面开始结合axios和echarts</li></ul><h2 id="通过axios请求数据"><a href="#通过axios请求数据" class="headerlink" title="通过axios请求数据"></a>通过axios请求数据</h2><p>执行<code>node data.js</code></p><p>data.js内容如下</p>  <figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">const</span> express = <span class="built_in">require</span>(<span class="string">&#x27;express&#x27;</span>)</span><br><span class="line"><span class="keyword">const</span> app = <span class="title function_">express</span>()</span><br><span class="line"></span><br><span class="line">app.<span class="title function_">use</span>(<span class="function">(<span class="params">request,response,next</span>)=&gt;</span>&#123;</span><br><span class="line"><span class="variable language_">console</span>.<span class="title function_">log</span>(<span class="string">&#x27;请求来自于&#x27;</span>,request.<span class="title function_">get</span>(<span class="string">&#x27;Host&#x27;</span>));</span><br><span class="line"><span class="variable language_">console</span>.<span class="title function_">log</span>(<span class="string">&#x27;请求的地址&#x27;</span>,request.<span class="property">url</span>);</span><br><span class="line"><span class="title function_">next</span>()</span><br><span class="line">&#125;)</span><br><span class="line"></span><br><span class="line">app.<span class="title function_">get</span>(<span class="string">&#x27;/data&#x27;</span>,<span class="function">(<span class="params">request,response</span>)=&gt;</span>&#123;</span><br><span class="line"><span class="keyword">const</span> data = [</span><br><span class="line">  &#123;<span class="string">&quot;name&quot;</span>: <span class="string">&quot;内蒙古&quot;</span>, <span class="string">&quot;value&quot;</span>: <span class="number">34</span>&#125;,</span><br><span class="line">  &#123;<span class="string">&quot;name&quot;</span>: <span class="string">&quot;台湾&quot;</span>, <span class="string">&quot;value&quot;</span>: <span class="number">21</span>&#125;,</span><br><span class="line">  &#123;<span class="string">&quot;name&quot;</span>: <span class="string">&quot;上海&quot;</span>, <span class="string">&quot;value&quot;</span>: <span class="number">9</span>&#125;,</span><br><span class="line">  &#123;<span class="string">&quot;name&quot;</span>: <span class="string">&quot;浙江&quot;</span>, <span class="string">&quot;value&quot;</span>: <span class="number">8</span>&#125;,</span><br><span class="line">  &#123;<span class="string">&quot;name&quot;</span>: <span class="string">&quot;广西&quot;</span>, <span class="string">&quot;value&quot;</span>: <span class="number">8</span>&#125;,</span><br><span class="line">  &#123;<span class="string">&quot;name&quot;</span>: <span class="string">&quot;香港&quot;</span>, <span class="string">&quot;value&quot;</span>: <span class="number">5</span>&#125;,</span><br><span class="line">  &#123;<span class="string">&quot;name&quot;</span>: <span class="string">&quot;福建&quot;</span>, <span class="string">&quot;value&quot;</span>: <span class="number">3</span>&#125;,</span><br><span class="line">  &#123;<span class="string">&quot;name&quot;</span>: <span class="string">&quot;云南&quot;</span>, <span class="string">&quot;value&quot;</span>: <span class="number">3</span>&#125;,</span><br><span class="line">  &#123;<span class="string">&quot;name&quot;</span>: <span class="string">&quot;广东&quot;</span>, <span class="string">&quot;value&quot;</span>: <span class="number">3</span>&#125;,</span><br><span class="line">  &#123;<span class="string">&quot;name&quot;</span>: <span class="string">&quot;四川&quot;</span>, <span class="string">&quot;value&quot;</span>: <span class="number">3</span>&#125;</span><br><span class="line">]</span><br><span class="line">response.<span class="title function_">send</span>(data)</span><br><span class="line">&#125;)</span><br><span class="line"></span><br><span class="line">app.<span class="title function_">listen</span>(<span class="number">5000</span>,<span class="function">(<span class="params">err</span>)=&gt;</span>&#123;</span><br><span class="line"><span class="keyword">if</span>(!err) <span class="variable language_">console</span>.<span class="title function_">log</span>(<span class="string">&#x27;启动成功了,请求数据地址为：http://localhost:5000/data&#x27;</span>);</span><br><span class="line">&#125;)</span><br></pre></td></tr></table></figure><p>响应结果为：启动成功了,请求数据地址为：<a href="http://localhost:5000/data%EF%BC%8C%E6%AD%A4%E6%97%B6%E5%8F%AF%E4%BB%A5%E9%80%9A%E8%BF%87%E5%A6%82%E4%B8%8A%E5%9C%B0%E5%9D%80%E8%AE%BF%E9%97%AE%E5%88%B0%E6%95%B0%E6%8D%AE">http://localhost:5000/data，此时可以通过如上地址访问到数据</a></p><p>至此数据已挂载好</p><p>打开终端下载axios</p>  <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">npm install axios --save</span><br></pre></td></tr></table></figure><p>来到 Bar.vue 文件，引入axios</p>  <figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> axios <span class="keyword">from</span> <span class="string">&#x27;axios&#x27;</span></span><br></pre></td></tr></table></figure><p>写一个函数用于请求数据，函数写在setup()里</p>  <figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="title function_">setup</span>(<span class="params"></span>) &#123;</span><br><span class="line">    <span class="keyword">let</span> ref_bar = <span class="title function_">ref</span>()</span><br><span class="line">    <span class="comment">// 定义一个函数请求数据</span></span><br><span class="line">    <span class="keyword">function</span> <span class="title function_">getData</span>(<span class="params"></span>) &#123;</span><br><span class="line">        <span class="comment">// then(请求成功的回调函数, 请求失败的回调函数)</span></span><br><span class="line">        axios.<span class="title function_">get</span>(<span class="string">&#x27;http://localhost:5000/data&#x27;</span>).<span class="title function_">then</span>(</span><br><span class="line">            <span class="comment">// function (response) &#123;请求成功函数体&#125;简写如下</span></span><br><span class="line">            <span class="function"><span class="params">res</span> =&gt;</span> &#123;</span><br><span class="line">               <span class="variable language_">console</span>.<span class="title function_">log</span>(<span class="string">&#x27;成功&#x27;</span>, res)</span><br><span class="line">            <span class="comment">// function (error) &#123;请求失败函数体&#125;简写如下</span></span><br><span class="line">            &#125;, <span class="function"><span class="params">err</span> =&gt;</span> &#123;</span><br><span class="line">                <span class="variable language_">console</span>.<span class="title function_">log</span>(<span class="string">&#x27;5000/data&#x27;</span>, err)</span><br><span class="line">            &#125;</span><br><span class="line">        )</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="title function_">onMounted</span>(<span class="function">() =&gt;</span> &#123;</span><br><span class="line">        <span class="variable language_">console</span>.<span class="title function_">log</span>(ref_bar.<span class="property">value</span>)</span><br><span class="line">        <span class="comment">// dom挂载后调用函数请求数据</span></span><br><span class="line">        <span class="title function_">getData</span>();</span><br><span class="line">    &#125;)</span><br><span class="line">    <span class="keyword">return</span> &#123;</span><br><span class="line">        ref_bar</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>此时出现如下错误</p>  <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">- 失败 Error: Network Error</span><br><span class="line">- Access to XMLHttpRequest at &#x27;http://localhost:5000/data&#x27; from origin &#x27;http://localhost:8080&#x27; has been blocked by CORS policy: No &#x27;Access-Control-Allow-Origin&#x27; header is present on the requested resource</span><br><span class="line">- GET http://localhost:5000/data net::ERR_FAILED 200</span><br></pre></td></tr></table></figure><h2 id="处理跨域问题"><a href="#处理跨域问题" class="headerlink" title="处理跨域问题"></a>处理跨域问题</h2><p>在项目根目录创建vue.config.js文件，代码如下</p><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="variable language_">module</span>.<span class="property">exports</span> = &#123;</span><br><span class="line">  <span class="attr">devServer</span>: &#123;</span><br><span class="line">    <span class="attr">proxy</span>: &#123;</span><br><span class="line">      <span class="comment">// 所有端口号后面是data1的请求，通过代理服务器请求至target对应的网址</span></span><br><span class="line">      <span class="string">&#x27;/data1&#x27;</span>: &#123;</span><br><span class="line">        <span class="attr">target</span>: <span class="string">&#x27;http://localhost:5000&#x27;</span>,</span><br><span class="line">        <span class="comment">// 重写路径,将/data1开头的替换为空字符串</span></span><br><span class="line">        <span class="attr">pathRewrite</span>: &#123;<span class="string">&#x27;^/data1&#x27;</span>: <span class="string">&#x27;&#x27;</span>&#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>效果为：请求网址 <a href="http://localhost:8080/data1/data">http://localhost:8080/data1/data</a> ,经过如上规则最终请求的网址为<a href="http://localhost:5000/data">http://localhost:5000/data</a></p><p>重启项目，每次修改vue.config.js都要重启项目</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">- 打开终端</span><br><span class="line">- ctrl+c(两次)</span><br><span class="line">- npm run serve</span><br></pre></td></tr></table></figure><p>来到 Bar.vue 的setup()函数下，修改请求的网址，让其可以通过代理服务器去请求到数据</p><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">axios.<span class="title function_">get</span>(<span class="string">&#x27;http://localhost:8080/data1/data&#x27;</span>).<span class="title function_">then</span>(...)</span><br></pre></td></tr></table></figure><p>保存刷新，打开网页console发现请求数据成功</p><p>此时拿到了请求成功的response响应对象，响应对象.data 即 你要的数据</p><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">res =&gt; &#123;</span><br><span class="line">    <span class="comment">// data就是你要的数据</span></span><br><span class="line">    <span class="keyword">var</span> data = res.<span class="property">data</span></span><br><span class="line">    <span class="variable language_">console</span>.<span class="title function_">log</span>(<span class="string">&#x27;成功&#x27;</span>, data)</span><br></pre></td></tr></table></figure><h2 id="编写配置项文件"><a href="#编写配置项文件" class="headerlink" title="编写配置项文件"></a>编写配置项文件</h2><p>在assets目录下新建 bar_option.js 文件</p><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// option配置项没什么讲的</span></span><br><span class="line"><span class="keyword">var</span> option = &#123;</span><br><span class="line">  <span class="attr">title</span>: &#123;</span><br><span class="line">     <span class="attr">text</span>: <span class="string">&#x27;奶茶销量&#x27;</span></span><br><span class="line">  &#125;,</span><br><span class="line">  <span class="attr">xAxis</span>: &#123;</span><br><span class="line">     <span class="attr">type</span>: <span class="string">&#x27;category&#x27;</span>,</span><br><span class="line"> <span class="comment">// 数据先定死，做测试</span></span><br><span class="line">     <span class="attr">data</span>: [<span class="string">&#x27;芋圆麻薯羊奶&#x27;</span>, <span class="string">&#x27;麻薯羊奶芋圆&#x27;</span>]</span><br><span class="line">  &#125;,</span><br><span class="line">  <span class="attr">yAxis</span>: &#123;&#125;,</span><br><span class="line">  <span class="attr">tooltip</span>: &#123;</span><br><span class="line">     <span class="attr">trigger</span>: <span class="string">&#x27;axis&#x27;</span></span><br><span class="line">  &#125;,</span><br><span class="line">  <span class="attr">series</span>: &#123;</span><br><span class="line">     <span class="attr">type</span>: <span class="string">&#x27;bar&#x27;</span>,</span><br><span class="line"> <span class="comment">// 数据先定死，做测试</span></span><br><span class="line">     <span class="attr">data</span>: [<span class="number">88</span>, <span class="number">120</span>]</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 对外暴露，供其他文件引用</span></span><br><span class="line"><span class="keyword">export</span> <span class="keyword">default</span> option</span><br></pre></td></tr></table></figure><p>来到 Bar.vue ，引入echarts</p><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> echarts <span class="keyword">from</span> <span class="string">&#x27;../assets/echarts.min.js&#x27;</span></span><br></pre></td></tr></table></figure><p>在setup函数体写一个画图函数</p><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">function</span> <span class="title function_">draw</span>(<span class="params"></span>)&#123;</span><br><span class="line">    <span class="comment">// 控制台查看之前定义的ref_bar</span></span><br><span class="line">    <span class="variable language_">console</span>.<span class="title function_">log</span>(ref_bar)</span><br><span class="line">    <span class="comment">// ref_bar下的value属性就是我们需要的dom元素</span></span><br><span class="line">    <span class="keyword">var</span> et = echarts.<span class="title function_">init</span>(ref_bar.<span class="property">value</span>)</span><br><span class="line">    <span class="comment">// 设置配置项，这个option是我们之前引入的那个option文件里的</span></span><br><span class="line">    et.<span class="title function_">setOption</span>(option)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在onMounted生命周期函数中如下代码</p><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="title function_">onMounted</span>(<span class="function">() =&gt;</span> &#123;</span><br><span class="line">    <span class="variable language_">console</span>.<span class="title function_">log</span>(ref_bar.<span class="property">value</span>)</span><br><span class="line">    <span class="comment">// dom挂载后调用函数请求数据</span></span><br><span class="line">    <span class="title function_">getData</span>();</span><br><span class="line">    <span class="comment">// 请求完数据画图</span></span><br><span class="line">    <span class="title function_">draw</span>( );</span><br><span class="line">&#125;)</span><br></pre></td></tr></table></figure><p>保存刷新查看网页，至此，axios请求数据成功、echarts渲染成功</p><h2 id="echarts结合axios"><a href="#echarts结合axios" class="headerlink" title="echarts结合axios"></a>echarts结合axios</h2><p>对之前请求到的数据做个处理，数据如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">[</span><br><span class="line">  &#123;name: &#x27;内蒙古&#x27;, value: 34&#125;, </span><br><span class="line">  &#123;name: &#x27;台湾&#x27;, value: 21&#125;, </span><br><span class="line">  &#123;name: &#x27;上海&#x27;, value: 9&#125;,  </span><br><span class="line">  &#123;name: &#x27;浙江&#x27;, value: 8&#125;,  </span><br><span class="line">  &#123;name: &#x27;广西&#x27;, value: 8&#125;, </span><br><span class="line">  &#123;name: &#x27;香港&#x27;, value: 5&#125;, </span><br><span class="line">  &#123;name: &#x27;福建&#x27;, value: 3&#125;,  </span><br><span class="line">  &#123;name: &#x27;云南&#x27;, value: 3&#125;, </span><br><span class="line">  &#123;name: &#x27;广东&#x27;, value: 3&#125;, </span><br><span class="line">  &#123;name: &#x27;四川&#x27;, value: 3&#125;</span><br><span class="line">]</span><br></pre></td></tr></table></figure><p>这里我对其进行提取，分别声明两个数组，一个做x类目轴数据，一个做series下data数据</p><p>然后echarts实例对象调用setOption进行配置项更新，代码最终如下</p><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">script</span>&gt;</span><span class="language-javascript"></span></span><br><span class="line"><span class="language-javascript">    <span class="comment">// 引入各种文件，此处省略</span></span></span><br><span class="line"><span class="language-javascript">    <span class="keyword">import</span> ... <span class="keyword">from</span> <span class="string">&#x27;xx&#x27;</span></span></span><br><span class="line"><span class="language-javascript">    <span class="keyword">export</span> <span class="keyword">default</span> &#123;</span></span><br><span class="line"><span class="language-javascript">        <span class="attr">name</span>: <span class="string">&#x27;Bar&#x27;</span>,</span></span><br><span class="line"><span class="language-javascript">        <span class="title function_">setup</span>(<span class="params"></span>) &#123; </span></span><br><span class="line"><span class="language-javascript">            <span class="keyword">var</span> ref_bar = <span class="title function_">ref</span>()</span></span><br><span class="line"><span class="language-javascript">            <span class="comment">// 声明两个空数组</span></span></span><br><span class="line"><span class="language-javascript">            <span class="keyword">var</span> xdata = []</span></span><br><span class="line"><span class="language-javascript">            <span class="keyword">var</span> data = []</span></span><br><span class="line"><span class="language-javascript">            <span class="keyword">function</span> <span class="title function_">getData</span>(<span class="params"></span>) &#123;</span></span><br><span class="line"><span class="language-javascript">                axios.<span class="title function_">get</span>(<span class="string">&#x27;http://localhost:8080/data1/data&#x27;</span>).<span class="title function_">then</span>(</span></span><br><span class="line"><span class="language-javascript">                    <span class="function"><span class="params">res</span> =&gt;</span> &#123;</span></span><br><span class="line"><span class="language-javascript">                        <span class="keyword">var</span> data = res.<span class="property">data</span></span></span><br><span class="line"><span class="language-javascript">                        <span class="variable language_">console</span>.<span class="title function_">log</span>(<span class="string">&#x27;成功&#x27;</span>, data)</span></span><br><span class="line"><span class="language-javascript">                        <span class="comment">// 拿到数据，遍历，取前五</span></span></span><br><span class="line"><span class="language-javascript">                        <span class="keyword">for</span>(<span class="keyword">var</span> i = <span class="number">0</span>; i &lt; <span class="number">5</span>; i++) &#123;</span></span><br><span class="line"><span class="language-javascript">                            <span class="comment">// 把name放在提前声明的xdata中</span></span></span><br><span class="line"><span class="language-javascript">                            xdata.<span class="title function_">push</span>(data[i].<span class="property">name</span>);</span></span><br><span class="line"><span class="language-javascript">                            <span class="comment">// 把value放在提前声明的data中</span></span></span><br><span class="line"><span class="language-javascript">                            data.<span class="title function_">push</span>(data[i].<span class="property">value</span>);</span></span><br><span class="line"><span class="language-javascript">                        &#125;</span></span><br><span class="line"><span class="language-javascript">                    &#125;, <span class="function"><span class="params">err</span> =&gt;</span> &#123;</span></span><br><span class="line"><span class="language-javascript">                        <span class="variable language_">console</span>.<span class="title function_">log</span>(<span class="string">&#x27;失败&#x27;</span>, err)</span></span><br><span class="line"><span class="language-javascript">                    &#125;</span></span><br><span class="line"><span class="language-javascript">                )</span></span><br><span class="line"><span class="language-javascript">            &#125;</span></span><br><span class="line"><span class="language-javascript">            <span class="keyword">function</span> <span class="title function_">draw</span>(<span class="params"></span>)&#123;</span></span><br><span class="line"><span class="language-javascript">                <span class="keyword">var</span> et = echarts.<span class="title function_">init</span>(ref_bar.<span class="property">value</span>)</span></span><br><span class="line"><span class="language-javascript">                et.<span class="title function_">setOption</span>(option)</span></span><br><span class="line"><span class="language-javascript">                <span class="variable language_">console</span>.<span class="title function_">log</span>(xdata)</span></span><br><span class="line"><span class="language-javascript">                <span class="variable language_">console</span>.<span class="title function_">log</span>(data)</span></span><br><span class="line"><span class="language-javascript">                <span class="comment">// 创建一个新配置项</span></span></span><br><span class="line"><span class="language-javascript">                <span class="keyword">var</span> new_option = &#123;</span></span><br><span class="line"><span class="language-javascript">                    <span class="attr">title</span>: &#123;<span class="attr">text</span>: <span class="string">&#x27;2021.12.07 各省新增确诊Top5&#x27;</span>&#125;</span></span><br><span class="line"><span class="language-javascript">                    <span class="attr">xAixs</span>: &#123;<span class="attr">data</span>: xdata&#125;,</span></span><br><span class="line"><span class="language-javascript">                    <span class="attr">series</span>: &#123;<span class="attr">data</span>: data&#125;</span></span><br><span class="line"><span class="language-javascript">                &#125;</span></span><br><span class="line"><span class="language-javascript">                <span class="comment">// 覆盖原有的配置</span></span></span><br><span class="line"><span class="language-javascript">                et.<span class="title function_">setOption</span>(new_option)</span></span><br><span class="line"><span class="language-javascript">            &#125;</span></span><br><span class="line"><span class="language-javascript">            <span class="title function_">onMounted</span>(<span class="function">() =&gt;</span> &#123;本函数未做变更，此处省略&#125;)</span></span><br><span class="line"><span class="language-javascript">            <span class="keyword">return</span> &#123;ref_bar&#125;</span></span><br><span class="line"><span class="language-javascript">        &#125;</span></span><br><span class="line"><span class="language-javascript">    &#125;</span></span><br><span class="line"><span class="language-javascript"></span><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br></pre></td></tr></table></figure><p>此时，你会发现只剩下了xy轴和标题，而且明明执行的请求数据再执行的画图，结果控制台先输出的draw函数的xdata和data，而且两个都是空数组，最后输出的居然还是getData函数还打印了 成功以及请求的数据。这是因为axios请求数据的是异步的，执行异步请求时，他不会阻塞当前程序，而是一种这样的情况：你在请求数据啊？我不等你请求完，我先去画图啦！</p><p>这里用了最low的方法，把onMounted里的draw()放在了getData()函数体末尾，如下</p><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">function</span> <span class="title function_">getData</span>(<span class="params"></span>) &#123;</span><br><span class="line">    axios.<span class="title function_">get</span>(<span class="string">&#x27;http://localhost:8080/data1/data&#x27;</span>).<span class="title function_">then</span>(</span><br><span class="line">        <span class="function"><span class="params">res</span> =&gt;</span> &#123;</span><br><span class="line">            <span class="keyword">var</span> data = res.<span class="property">data</span></span><br><span class="line">            <span class="variable language_">console</span>.<span class="title function_">log</span>(<span class="string">&#x27;成功&#x27;</span>, data)</span><br><span class="line">            <span class="keyword">for</span>(<span class="keyword">var</span> i = <span class="number">0</span>; i &lt; <span class="number">5</span>; i++) &#123;</span><br><span class="line">                xdata.<span class="title function_">push</span>(data[i].<span class="property">name</span>);</span><br><span class="line">                ydata.<span class="title function_">push</span>(data[i].<span class="property">value</span>);</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="title function_">draw</span>();<span class="comment">// 我在这里</span></span><br><span class="line">        &#125;, <span class="function"><span class="params">err</span> =&gt;</span> &#123;</span><br><span class="line">            <span class="variable language_">console</span>.<span class="title function_">log</span>(<span class="string">&#x27;失败&#x27;</span>, err)</span><br><span class="line">        &#125;</span><br><span class="line">    )</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>解决这个问题还有其他办法，如：nextTick、设置个延时、async+await</p><h2 id="版权所有©小飞象"><a href="#版权所有©小飞象" class="headerlink" title="版权所有©小飞象"></a>版权所有©小飞象</h2><ul><li>至此，首个图表已完成vue+axios+echarts</li><li>如有错误，请联系我更正！谢谢！</li><li>联系我？微信：13118099720</li></ul><h1 id="第二个echarts图表"><a href="#第二个echarts图表" class="headerlink" title="第二个echarts图表"></a>第二个echarts图表</h1><h2 id="新建-Line-vue"><a href="#新建-Line-vue" class="headerlink" title="新建 Line.vue"></a>新建 Line.vue</h2><p>views下新建 Line.vue，代码如下</p><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">template</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">div</span> <span class="attr">ref</span>=<span class="string">&quot;line&quot;</span> <span class="attr">style</span>=<span class="string">&quot;width: 600px;height: 400px;&quot;</span>&gt;</span><span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">template</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">script</span>&gt;</span><span class="language-javascript"></span></span><br><span class="line"><span class="language-javascript">    <span class="keyword">import</span> echarts <span class="keyword">from</span> <span class="string">&#x27;../assets/echarts.min.js&#x27;</span></span></span><br><span class="line"><span class="language-javascript">    <span class="comment">// 折线图柱状图都是直角坐标系，这个配置项文件可以公用</span></span></span><br><span class="line"><span class="language-javascript">    <span class="keyword">import</span> option <span class="keyword">from</span> <span class="string">&#x27;../assets/bar_option.js&#x27;</span></span></span><br><span class="line"><span class="language-javascript">    <span class="keyword">import</span> &#123; ref, onMounted &#125; <span class="keyword">from</span> <span class="string">&#x27;vue&#x27;</span></span></span><br><span class="line"><span class="language-javascript">    <span class="keyword">export</span> <span class="keyword">default</span> &#123;</span></span><br><span class="line"><span class="language-javascript">        <span class="attr">name</span>: <span class="string">&#x27;Line&#x27;</span>,</span></span><br><span class="line"><span class="language-javascript">        <span class="attr">setup</span>: <span class="keyword">function</span>(<span class="params"></span>) &#123;</span></span><br><span class="line"><span class="language-javascript">            <span class="keyword">let</span> line = <span class="title function_">ref</span>()</span></span><br><span class="line"><span class="language-javascript">            <span class="keyword">function</span> <span class="title function_">mount</span> () &#123;</span></span><br><span class="line"><span class="language-javascript">                <span class="variable language_">console</span>.<span class="title function_">log</span>(line)</span></span><br><span class="line"><span class="language-javascript">                <span class="keyword">var</span> et = echarts.<span class="title function_">init</span>(line.<span class="property">value</span>)               </span></span><br><span class="line"><span class="language-javascript">                et.<span class="title function_">setOption</span>(option)</span></span><br><span class="line"><span class="language-javascript">            &#125;</span></span><br><span class="line"><span class="language-javascript">            <span class="comment">// 实例挂载完毕后执行mount函数</span></span></span><br><span class="line"><span class="language-javascript">            <span class="title function_">onMounted</span>(<span class="function">() =&gt;</span> &#123;</span></span><br><span class="line"><span class="language-javascript">                <span class="title function_">mount</span>()</span></span><br><span class="line"><span class="language-javascript">            &#125;)</span></span><br><span class="line"><span class="language-javascript">            <span class="comment">// 此处应返回&#123;line&#125;形式的，返回一个line时报错了</span></span></span><br><span class="line"><span class="language-javascript">            <span class="keyword">return</span> &#123;line&#125;</span></span><br><span class="line"><span class="language-javascript">        &#125;</span></span><br><span class="line"><span class="language-javascript">    &#125;</span></span><br><span class="line"><span class="language-javascript"></span><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br></pre></td></tr></table></figure><h2 id="测试新图表"><a href="#测试新图表" class="headerlink" title="测试新图表"></a>测试新图表</h2><p>打开 App.vue，注册组件，</p><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">template</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">Bar</span> /&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">hr</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">Line</span> /&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">template</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">script</span>&gt;</span><span class="language-javascript"></span></span><br><span class="line"><span class="language-javascript">    <span class="keyword">import</span> <span class="title class_">Bar</span> <span class="keyword">from</span> <span class="string">&#x27;./views/Bar&#x27;</span></span></span><br><span class="line"><span class="language-javascript">    <span class="keyword">import</span> <span class="title class_">Line</span> <span class="keyword">from</span> <span class="string">&#x27;./views/Line&#x27;</span></span></span><br><span class="line"><span class="language-javascript">    <span class="keyword">export</span> <span class="keyword">default</span> &#123;</span></span><br><span class="line"><span class="language-javascript">        <span class="attr">name</span>: <span class="string">&#x27;App&#x27;</span>,</span></span><br><span class="line"><span class="language-javascript">        <span class="attr">components</span>: &#123;<span class="title class_">Bar</span>, <span class="title class_">Line</span>&#125;</span></span><br><span class="line"><span class="language-javascript">    &#125;</span></span><br><span class="line"><span class="language-javascript"></span><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br></pre></td></tr></table></figure><p>保存APP和Line，刷新，此时应该有两张图在页面</p><h2 id="加上axios"><a href="#加上axios" class="headerlink" title="加上axios"></a>加上axios</h2><p>对 Line.vue 做点改动</p><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">template</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">div</span> <span class="attr">ref</span>=<span class="string">&quot;line&quot;</span> <span class="attr">style</span>=<span class="string">&quot;width: 600px;height: 400px;&quot;</span>&gt;</span><span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">template</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">script</span>&gt;</span><span class="language-javascript"></span></span><br><span class="line"><span class="language-javascript">    <span class="comment">// 以下导包，不比比</span></span></span><br><span class="line"><span class="language-javascript">    <span class="keyword">import</span> echarts <span class="keyword">from</span> <span class="string">&#x27;../assets/echarts.min.js&#x27;</span></span></span><br><span class="line"><span class="language-javascript">    <span class="keyword">import</span> option <span class="keyword">from</span> <span class="string">&#x27;../assets/bar_option.js&#x27;</span></span></span><br><span class="line"><span class="language-javascript">    <span class="keyword">import</span> &#123; ref, onMounted &#125; <span class="keyword">from</span> <span class="string">&#x27;vue&#x27;</span></span></span><br><span class="line"><span class="language-javascript">    <span class="keyword">import</span> axios <span class="keyword">from</span> <span class="string">&#x27;axios&#x27;</span></span></span><br><span class="line"><span class="language-javascript">    <span class="comment">// 暴露 Line 视图</span></span></span><br><span class="line"><span class="language-javascript">    <span class="keyword">export</span> <span class="keyword">default</span> &#123;</span></span><br><span class="line"><span class="language-javascript">        <span class="attr">name</span>: <span class="string">&#x27;Line&#x27;</span>,</span></span><br><span class="line"><span class="language-javascript">        <span class="attr">setup</span>: <span class="keyword">function</span>(<span class="params"></span>) &#123;</span></span><br><span class="line"><span class="language-javascript">            <span class="keyword">let</span> line = <span class="title function_">ref</span>()</span></span><br><span class="line"><span class="language-javascript">            <span class="comment">// 请求数据函数</span></span></span><br><span class="line"><span class="language-javascript">            <span class="keyword">function</span> <span class="title function_">getData</span>(<span class="params"></span>) &#123;</span></span><br><span class="line"><span class="language-javascript">                <span class="keyword">var</span> xdata = []</span></span><br><span class="line"><span class="language-javascript">                <span class="keyword">var</span> data = []</span></span><br><span class="line"><span class="language-javascript">                axios.<span class="title function_">get</span>(<span class="string">&#x27;http://localhost:8080/data2/data&#x27;</span>).<span class="title function_">then</span>(</span></span><br><span class="line"><span class="language-javascript">                    <span class="comment">// 请求成功时</span></span></span><br><span class="line"><span class="language-javascript">                    <span class="function"><span class="params">res</span> =&gt;</span> &#123;</span></span><br><span class="line"><span class="language-javascript">                        <span class="variable language_">console</span>.<span class="title function_">log</span>(res.<span class="property">data</span>)</span></span><br><span class="line"><span class="language-javascript">                        <span class="comment">// 处理拿到的数据</span></span></span><br><span class="line"><span class="language-javascript">                        xdata = res.<span class="property">data</span>.<span class="property">date</span></span></span><br><span class="line"><span class="language-javascript">                        data = res.<span class="property">data</span>.<span class="property">add</span></span></span><br><span class="line"><span class="language-javascript">                        <span class="comment">// 传给画图函数并调用</span></span></span><br><span class="line"><span class="language-javascript">                        <span class="title function_">draw</span>(xdata, data)</span></span><br><span class="line"><span class="language-javascript">                    &#125;,</span></span><br><span class="line"><span class="language-javascript">                    <span class="comment">// 错误时</span></span></span><br><span class="line"><span class="language-javascript">                    <span class="function"><span class="params">err</span> =&gt;</span> &#123;</span></span><br><span class="line"><span class="language-javascript">                        <span class="variable language_">console</span>.<span class="title function_">log</span>(<span class="string">&#x27;5002&#x27;</span>, err)</span></span><br><span class="line"><span class="language-javascript">                    &#125;</span></span><br><span class="line"><span class="language-javascript">                )   </span></span><br><span class="line"><span class="language-javascript">            &#125;</span></span><br><span class="line"><span class="language-javascript">            <span class="comment">// 画图函数</span></span></span><br><span class="line"><span class="language-javascript">            <span class="keyword">function</span> <span class="title function_">draw</span> (xdata, data) &#123;</span></span><br><span class="line"><span class="language-javascript">                <span class="comment">// 初始化</span></span></span><br><span class="line"><span class="language-javascript">                <span class="keyword">var</span> et = echarts.<span class="title function_">init</span>(line.<span class="property">value</span>) </span></span><br><span class="line"><span class="language-javascript">                <span class="comment">// 设置配置项，此处option为引入的option</span></span></span><br><span class="line"><span class="language-javascript">                et.<span class="title function_">setOption</span>(option)</span></span><br><span class="line"><span class="language-javascript">                <span class="comment">// 检查xdata是否正常</span></span></span><br><span class="line"><span class="language-javascript">                <span class="variable language_">console</span>.<span class="title function_">log</span>(xdata)</span></span><br><span class="line"><span class="language-javascript">                <span class="comment">// 覆盖掉之前已有的配置项(只会覆盖掉双方都有的重复的配置)</span></span></span><br><span class="line"><span class="language-javascript">                et.<span class="title function_">setOption</span>(&#123;</span></span><br><span class="line"><span class="language-javascript">                    <span class="attr">title</span>: &#123;<span class="attr">text</span>: <span class="string">&#x27;11.07-12.07 全国新增确诊趋势折线图&#x27;</span>&#125;,</span></span><br><span class="line"><span class="language-javascript">                    <span class="attr">xAxis</span>: &#123;<span class="attr">data</span>: xdata&#125;,</span></span><br><span class="line"><span class="language-javascript">                    <span class="attr">series</span>: &#123;</span></span><br><span class="line"><span class="language-javascript">                        <span class="attr">type</span>: <span class="string">&#x27;line&#x27;</span>, </span></span><br><span class="line"><span class="language-javascript">                        <span class="attr">data</span>: data, </span></span><br><span class="line"><span class="language-javascript">                        <span class="comment">// 曲线</span></span></span><br><span class="line"><span class="language-javascript">                        <span class="attr">smooth</span>: <span class="literal">true</span>, </span></span><br><span class="line"><span class="language-javascript">                        <span class="comment">// 不显示点</span></span></span><br><span class="line"><span class="language-javascript">                        <span class="attr">showSymbol</span>: <span class="literal">false</span></span></span><br><span class="line"><span class="language-javascript">                    &#125;,</span></span><br><span class="line"><span class="language-javascript">                    <span class="attr">yAxis</span>: &#123;</span></span><br><span class="line"><span class="language-javascript">                        <span class="comment">// 不显示y轴分割线</span></span></span><br><span class="line"><span class="language-javascript">                        <span class="attr">splitLine</span>: <span class="literal">false</span>, </span></span><br><span class="line"><span class="language-javascript">                        <span class="attr">axisLabel</span>: &#123;</span></span><br><span class="line"><span class="language-javascript">                            <span class="attr">formatter</span>: <span class="string">&#x27;&#123;value&#125;例&#x27;</span></span></span><br><span class="line"><span class="language-javascript">                        &#125;</span></span><br><span class="line"><span class="language-javascript">                    &#125;,</span></span><br><span class="line"><span class="language-javascript">                &#125;)</span></span><br><span class="line"><span class="language-javascript">            &#125;</span></span><br><span class="line"><span class="language-javascript">            <span class="comment">// onMounted(() =&gt; &#123;函数体&#125;)     正确</span></span></span><br><span class="line"><span class="language-javascript">            <span class="comment">// onMounted(getData())    错误</span></span></span><br><span class="line"><span class="language-javascript">            <span class="title function_">onMounted</span>(getData)      <span class="comment">// 正确</span></span></span><br><span class="line"><span class="language-javascript">            <span class="comment">// 返回到模板，模板中ref=&quot;line&quot;</span></span></span><br><span class="line"><span class="language-javascript">            <span class="keyword">return</span> &#123;line&#125;</span></span><br><span class="line"><span class="language-javascript">        &#125;</span></span><br><span class="line"><span class="language-javascript">    &#125;</span></span><br><span class="line"><span class="language-javascript"></span><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br></pre></td></tr></table></figure><p>保存刷新，此时应该有两张图实现了axios请求数据渲染到图表</p><h2 id="路由来了"><a href="#路由来了" class="headerlink" title="路由来了"></a>路由来了</h2><p>在终端下载vue-router</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">npm install --save vue-router</span><br></pre></td></tr></table></figure><p>打开 route 目录，新建 index.js 文件，代码如下</p><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> &#123; createRouter, createWebHashHistory&#125; <span class="keyword">from</span> <span class="string">&quot;vue-router&quot;</span>;</span><br><span class="line"><span class="comment">// 定义路由组件</span></span><br><span class="line"><span class="keyword">const</span> <span class="title function_">Line</span> = (<span class="params"></span>) =&gt; <span class="keyword">import</span>(<span class="string">&#x27;../views/Line.vue&#x27;</span>)</span><br><span class="line"><span class="keyword">const</span> <span class="title function_">Bar</span> = (<span class="params"></span>) =&gt; <span class="keyword">import</span>(<span class="string">&#x27;../views/Bar.vue&#x27;</span>)</span><br><span class="line"><span class="comment">// 定义路由</span></span><br><span class="line"><span class="keyword">const</span> routes = [</span><br><span class="line">    &#123;<span class="attr">path</span>: <span class="string">&#x27;/bar&#x27;</span>, <span class="attr">component</span>: <span class="title class_">Bar</span>&#125;,</span><br><span class="line">    &#123;<span class="attr">path</span>: <span class="string">&#x27;/line&#x27;</span>, <span class="attr">component</span>: <span class="title class_">Line</span>&#125;,</span><br><span class="line">]</span><br><span class="line"><span class="comment">//  创建路由实例并传递 routes配置</span></span><br><span class="line"><span class="keyword">const</span> router = <span class="title function_">createRouter</span>(&#123;</span><br><span class="line">    <span class="attr">history</span>: <span class="title function_">createWebHashHistory</span>(),</span><br><span class="line">    routes</span><br><span class="line">&#125;)</span><br><span class="line"><span class="keyword">export</span> <span class="keyword">default</span> router</span><br></pre></td></tr></table></figure><p>解决报错：“export ‘createRouter‘ was not found in ‘vue-router‘</p><ul><li><p>分析：vue版本问题</p></li><li><p>解决：终端执行 </p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">npm install vue-router@next --save</span><br></pre></td></tr></table></figure></li></ul><p>来到 main.js ，这是我们首次修改他，我们需要用上router</p><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> &#123; createApp &#125; <span class="keyword">from</span> <span class="string">&#x27;vue&#x27;</span></span><br><span class="line"><span class="keyword">import</span> <span class="title class_">App</span> <span class="keyword">from</span> <span class="string">&#x27;./App.vue&#x27;</span></span><br><span class="line"><span class="comment">// 引入</span></span><br><span class="line"><span class="keyword">import</span> router <span class="keyword">from</span> <span class="string">&#x27;./route&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">const</span> app = <span class="title function_">createApp</span>(<span class="title class_">App</span>)</span><br><span class="line">app.<span class="title function_">use</span>(router)</span><br><span class="line">app.<span class="title function_">mount</span>(<span class="string">&#x27;#app&#x27;</span>)</span><br></pre></td></tr></table></figure><p>来到 App.vue ，代码如下</p><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">template</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">div</span>&gt;</span></span><br><span class="line">        // 挂载到网页后这是一个a标签，点击时观察网页地址栏的变化</span><br><span class="line">        <span class="tag">&lt;<span class="name">router-link</span> <span class="attr">to</span>=<span class="string">&quot;/bar&quot;</span>&gt;</span>柱状图<span class="tag">&lt;/<span class="name">router-link</span>&gt;</span> <span class="tag">&lt;<span class="name">br</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">router-link</span> <span class="attr">to</span>=<span class="string">&quot;/line&quot;</span>&gt;</span>折线图<span class="tag">&lt;/<span class="name">router-link</span>&gt;</span></span><br><span class="line">        // 视图显示的位置</span><br><span class="line">        <span class="tag">&lt;<span class="name">router-view</span>&gt;</span><span class="tag">&lt;/<span class="name">router-view</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">template</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">script</span>&gt;</span><span class="language-javascript"></span></span><br><span class="line"><span class="language-javascript">    <span class="keyword">export</span> <span class="keyword">default</span> &#123;</span></span><br><span class="line"><span class="language-javascript">        <span class="attr">name</span>: <span class="string">&#x27;App&#x27;</span></span></span><br><span class="line"><span class="language-javascript">    &#125;</span></span><br><span class="line"><span class="language-javascript"></span><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">style</span>&gt;</span><span class="language-css"></span></span><br><span class="line"><span class="language-css">    // 随便给点样式</span></span><br><span class="line"><span class="language-css">    <span class="selector-tag">div</span> &#123;</span></span><br><span class="line"><span class="language-css">        <span class="attribute">margin</span>: <span class="number">2%</span> <span class="number">7%</span></span></span><br><span class="line"><span class="language-css">    &#125;</span></span><br><span class="line"><span class="language-css"></span><span class="tag">&lt;/<span class="name">style</span>&gt;</span></span><br></pre></td></tr></table></figure><p>至此，请求 <a href="http://localhost:8080/#">http://localhost:8080/#</a> 时只有柱状图和折线图(文字)，而点击柱状图会显示柱状图，点击折线图则显示折线图</p><p>ByeBye！</p><h1 id="亿点点更新"><a href="#亿点点更新" class="headerlink" title="亿点点更新"></a>亿点点更新</h1><h2 id="关于路由"><a href="#关于路由" class="headerlink" title="关于路由"></a>关于路由</h2><p>在 route 目录下创建 index.js</p><ul><li>引入两个函数 createRouter、createWebHashHistory</li></ul><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> &#123; createRouter, createWebHashHistory &#125; <span class="keyword">from</span> <span class="string">&#x27;vue-router&#x27;</span></span><br></pre></td></tr></table></figure><ul><li>定义路由组件</li></ul><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">const</span> 组件对象 = <span class="function">() =&gt;</span> <span class="keyword">import</span>(<span class="string">&#x27;组件文件的路径&#x27;</span>)</span><br></pre></td></tr></table></figure><ul><li>定义路由对象</li></ul><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">const</span> 路由对象 = [</span><br><span class="line">  &#123;<span class="attr">path</span>: <span class="string">&#x27;/xxx&#x27;</span>, <span class="attr">component</span>: 组件对象&#125;,</span><br><span class="line">     &#123;<span class="attr">path</span>: <span class="string">&#x27;/xxx&#x27;</span>, <span class="attr">component</span>: 组件对象&#125;,</span><br><span class="line">     ....</span><br><span class="line">]</span><br></pre></td></tr></table></figure><ul><li>创建路由管理者实例对象</li></ul><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">const</span> 路由管理者实例对象 = <span class="title function_">createRouter</span>(&#123;</span><br><span class="line">  <span class="attr">history</span>: <span class="title function_">createWebHashHistory</span>(),</span><br><span class="line">  <span class="attr">routes</span>: routes</span><br><span class="line">&#125;)</span><br></pre></td></tr></table></figure><ul><li>把实例对象暴露出去</li></ul><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">export</span> <span class="keyword">default</span> 路由管理者实例对象</span><br></pre></td></tr></table></figure><p>来到 main.js，引入 路由实例对象</p><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> 路由实例对象 <span class="keyword">from</span> <span class="string">&#x27;./route&#x27;</span></span><br></pre></td></tr></table></figure><p>app.use(路由实例对象)</p><p>需使用时</p><ol><li><p>使用 router-link 标签，这个标签最终会被渲染成<code>&lt;a&gt;</code>标签，点击 文字 时，页面网址会跳转至 to属性中设置的path</p><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">router-link</span> <span class="attr">to</span>=<span class="string">&quot;/index.js文件中定义路由对象时的某个path&quot;</span>&gt;</span>文字<span class="tag">&lt;/<span class="name">router-link</span>&gt;</span></span><br></pre></td></tr></table></figure></li><li><p>可以通过 router-view 标签来显示组件，上方跳转网址后，<code>&lt;router-view&gt; </code>标签所在的位置会显示对应的组件</p><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">router-view</span>&gt;</span><span class="tag">&lt;/<span class="name">router-view</span>&gt;</span></span><br></pre></td></tr></table></figure></li></ol><h2 id="关于挂载全局对象"><a href="#关于挂载全局对象" class="headerlink" title="关于挂载全局对象"></a>关于挂载全局对象</h2><p>先引入</p><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> echarts <span class="keyword">from</span> <span class="string">&#x27;.....&#x27;</span></span><br></pre></td></tr></table></figure><p>挂载全局对象</p><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">app.<span class="property">config</span>.<span class="property">globalProperties</span>.<span class="property">$echarts</span> = echarts</span><br></pre></td></tr></table></figure><p>需使用时通过 getCurrenInstance() 获取 proxy </p><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 先引入函数</span></span><br><span class="line"><span class="keyword">import</span> &#123; getCurrenInstance &#125; <span class="keyword">from</span> <span class="string">&#x27;vue&#x27;</span></span><br><span class="line"><span class="comment">// ...</span></span><br><span class="line"><span class="keyword">const</span> &#123; proxy &#125; = <span class="title function_">getCurrentInstance</span>()</span><br></pre></td></tr></table></figure><p>此时通过 proxy.$echarts 来使用</p><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">var</span> et = proxy.<span class="property">$echarts</span>.<span class="title function_">init</span>(...)</span><br></pre></td></tr></table></figure><h2 id="关于跨域"><a href="#关于跨域" class="headerlink" title="关于跨域"></a>关于跨域</h2><p>在 vue.config.js 内开启代理服务器方式</p><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="variable language_">module</span>.<span class="property">exports</span> = &#123;</span><br><span class="line">    <span class="comment">// </span></span><br><span class="line">    <span class="attr">devServer</span>: &#123;</span><br><span class="line">        <span class="attr">proxy</span>: &#123;</span><br><span class="line">            <span class="comment">// 只要是proxy开头的请求，代理服务器都转发给target服务器</span></span><br><span class="line">            <span class="string">&#x27;/proxy&#x27;</span>: &#123;</span><br><span class="line">                <span class="attr">target</span>: <span class="string">&#x27;http://localhost:5001&#x27;</span>,</span><br><span class="line">                <span class="comment">// 转发到服务器的是 http://localhost:5001/proxy/xxx</span></span><br><span class="line">                <span class="comment">// 把proxy替换掉才行</span></span><br><span class="line">                <span class="attr">pathRewrite</span>: &#123;<span class="string">&#x27;^/proxy&#x27;</span>: <span class="string">&#x27;&#x27;</span>&#125;</span><br><span class="line">            &#125;,</span><br><span class="line">            <span class="string">&#x27;/pathRewrite&#x27;</span>: &#123;</span><br><span class="line">                <span class="attr">target</span>: <span class="string">&#x27;http://localhost:5000&#x27;</span>,</span><br><span class="line">                <span class="attr">pathRewrite</span>: &#123;<span class="string">&#x27;^/pathRewrite&#x27;</span>: <span class="string">&#x27;&#x27;</span>&#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="关于处理json数据"><a href="#关于处理json数据" class="headerlink" title="关于处理json数据"></a>关于处理json数据</h2><p>遍历</p><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">var</span> data = [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment">// 第一种</span></span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">var</span> i = <span class="number">0</span>; i &lt; data.<span class="property">length</span>; i++) &#123;</span><br><span class="line">    data[i]<span class="comment">// 1 2 3</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 第二种</span></span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">var</span> i <span class="keyword">in</span> data) &#123;</span><br><span class="line">    data[i]<span class="comment">// 1 2 3</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 第三种</span></span><br><span class="line">data.<span class="title function_">forEach</span>(<span class="function"><span class="params">element</span> =&gt;</span> &#123;</span><br><span class="line">    element<span class="comment">// 1 2 3</span></span><br><span class="line">&#125;)</span><br></pre></td></tr></table></figure><p>排序-sort()</p><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">var</span> data = [[<span class="number">1</span>, <span class="number">2</span>], [<span class="number">2</span>, <span class="number">1</span>], [<span class="number">0</span>, <span class="number">3</span>], [<span class="number">3</span>, <span class="number">0</span>]]</span><br><span class="line"></span><br><span class="line"><span class="comment">// 根据每个元素的下标0进行升序</span></span><br><span class="line">data.<span class="title function_">sort</span>(<span class="keyword">function</span>(<span class="params">x, y</span>) &#123;</span><br><span class="line">    <span class="keyword">return</span> x[<span class="number">0</span>] - y[<span class="number">0</span>]</span><br><span class="line">&#125;)</span><br><span class="line"><span class="variable language_">console</span>.<span class="title function_">log</span>(data)<span class="comment">// [[0, 3], [1, 2], [2, 1], [3, 0]]</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 根据每个元素的下标1进行降序</span></span><br><span class="line">data.<span class="title function_">sort</span>(<span class="keyword">function</span>(<span class="params">x, y</span>) &#123;</span><br><span class="line">    <span class="keyword">return</span> y[<span class="number">1</span>] - x[<span class="number">1</span>]</span><br><span class="line">&#125;)</span><br><span class="line"><span class="variable language_">console</span>.<span class="title function_">log</span>(data)<span class="comment">// [[0, 3], [1, 2], [2, 1], [3, 0]]</span></span><br><span class="line"></span><br><span class="line">-------------------------------------------------------------</span><br><span class="line">   </span><br><span class="line"><span class="keyword">var</span> data = [</span><br><span class="line">    &#123;<span class="string">&#x27;name&#x27;</span>: <span class="string">&#x27;张三&#x27;</span>, <span class="string">&#x27;age&#x27;</span>: <span class="number">29</span>&#125;, </span><br><span class="line">    &#123;<span class="string">&#x27;name&#x27;</span>: <span class="string">&#x27;李四&#x27;</span>, <span class="string">&#x27;age&#x27;</span>: <span class="number">19</span>&#125;, </span><br><span class="line">    &#123;<span class="string">&#x27;name&#x27;</span>: <span class="string">&#x27;王五&#x27;</span>, <span class="string">&#x27;age&#x27;</span>: <span class="number">39</span>&#125;,</span><br><span class="line">    &#123;<span class="string">&#x27;name&#x27;</span>: <span class="string">&#x27;赵六&#x27;</span>, <span class="string">&#x27;age&#x27;</span>: <span class="number">20</span>&#125;,</span><br><span class="line">]</span><br><span class="line"></span><br><span class="line">data.<span class="title function_">sort</span>(<span class="keyword">function</span>(<span class="params">x, y</span>) &#123;</span><br><span class="line">    <span class="comment">// 按照年龄降序</span></span><br><span class="line">    <span class="keyword">return</span> y.<span class="property">age</span> - x.<span class="property">age</span></span><br><span class="line">    <span class="comment">// 按照年龄升序</span></span><br><span class="line">    <span class="comment">// return x.age - y.age</span></span><br><span class="line">&#125;) </span><br></pre></td></tr></table></figure><p>筛选-filter()</p><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">var</span> da = [<span class="number">1</span>, <span class="number">32</span>, <span class="number">12</span>, <span class="number">2</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment">// 返回一个新数组</span></span><br><span class="line"><span class="keyword">var</span> new1 = da.<span class="title function_">filter</span>(<span class="keyword">function</span>(<span class="params">item</span>) &#123;</span><br><span class="line">    <span class="comment">// return一个布尔值，return true则保留被遍历的当前元素在新数组中，false则过滤掉</span></span><br><span class="line">    <span class="keyword">return</span> item &gt; <span class="number">2</span><span class="comment">// 这里的item一次为 1、32、12、2，且i&gt;2时被保留到新数组</span></span><br><span class="line">&#125;)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 简写如下</span></span><br><span class="line"><span class="keyword">var</span> new2 = da.<span class="title function_">filter</span>(<span class="function"><span class="params">item</span> =&gt;</span> &#123; <span class="keyword">return</span> item &gt; <span class="number">2</span> &#125;) </span><br><span class="line"></span><br><span class="line"><span class="variable language_">console</span>.<span class="title function_">log</span>(new1)<span class="comment">// [32, 12]</span></span><br><span class="line"><span class="variable language_">console</span>.<span class="title function_">log</span>(new2)<span class="comment">// [32, 12]</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// filter() 不会对空数组进行检测</span></span><br><span class="line"><span class="comment">// filter() 不会改变原始数组</span></span><br></pre></td></tr></table></figure><p>map()</p><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">var</span> da = [<span class="number">1</span>, <span class="number">32</span>, <span class="number">12</span>, <span class="number">2</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment">// 返回一个新数组，数组中的元素为原始数组元素调用函数处理后的值</span></span><br><span class="line"><span class="comment">// 按照原始数组元素顺序依次处理元素</span></span><br><span class="line"><span class="keyword">var</span> <span class="keyword">new</span> = da.<span class="title function_">map</span>(<span class="function"><span class="params">item</span> =&gt;</span> &#123;<span class="keyword">return</span> item * <span class="number">2</span>&#125;)</span><br><span class="line"></span><br><span class="line"><span class="variable language_">console</span>.<span class="title function_">log</span>(<span class="keyword">new</span>)<span class="comment">// [2, 64, 24, 4]</span></span><br></pre></td></tr></table></figure><p>头部插入-unshift()</p><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">var</span> data = [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment">// ... 的方式</span></span><br><span class="line"><span class="keyword">var</span> dataset = [[<span class="number">2</span>, <span class="number">11</span>], ...data]</span><br><span class="line"><span class="variable language_">console</span>.<span class="title function_">log</span>(data) <span class="comment">// [1, 2, 3]</span></span><br><span class="line"><span class="variable language_">console</span>.<span class="title function_">log</span>(dataset) <span class="comment">// [[2, 11], 1, 2, 3]</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 在调用unshift函数的数组的头部(0下标位置)，插入数据</span></span><br><span class="line">data.<span class="title function_">unshift</span>([<span class="number">2</span>, <span class="number">11</span>])</span><br><span class="line"><span class="variable language_">console</span>.<span class="title function_">log</span>(data) <span class="comment">// [[2, 11], 1, 2, 3]</span></span><br></pre></td></tr></table></figure><h2 id="关于地图"><a href="#关于地图" class="headerlink" title="关于地图"></a>关于地图</h2><p>main.js代码</p><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> &#123; createApp &#125; <span class="keyword">from</span> <span class="string">&#x27;vue&#x27;</span></span><br><span class="line"><span class="keyword">import</span> <span class="title class_">App</span> <span class="keyword">from</span> <span class="string">&#x27;./App.vue&#x27;</span></span><br><span class="line"><span class="comment">// 引入中国地图的china.json文件</span></span><br><span class="line"><span class="keyword">import</span> china <span class="keyword">from</span> <span class="string">&#x27;./assets/china.json&#x27;</span></span><br><span class="line"><span class="comment">// 引入echarts文件</span></span><br><span class="line"><span class="keyword">import</span> echarts <span class="keyword">from</span> <span class="string">&#x27;./assets/echarts.min.js&#x27;</span></span><br><span class="line"><span class="comment">// 用引入的echarts对象调用注册地图方法注册地图</span></span><br><span class="line"><span class="comment">// 参数1后续会用到，&#x27;名字随便取&#x27;</span></span><br><span class="line"><span class="comment">// 参数2为上方引入的china.json文件的china对象</span></span><br><span class="line">echarts.<span class="title function_">registerMap</span>(<span class="string">&#x27;chinaMap&#x27;</span>, china)</span><br><span class="line"><span class="keyword">const</span> app = <span class="title function_">createApp</span>(<span class="title class_">App</span>)</span><br><span class="line"><span class="comment">// 注册全局对象</span></span><br><span class="line">app.<span class="property">config</span>.<span class="property">globalProperties</span>.<span class="property">$echarts</span> = echarts</span><br><span class="line">app.<span class="title function_">mount</span>(<span class="string">&#x27;#app&#x27;</span>)</span><br></pre></td></tr></table></figure><p>Map.vue代码</p><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">template</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">div</span> <span class="attr">ref</span>=<span class="string">&quot;map&quot;</span> <span class="attr">style</span>=<span class="string">&quot;height: 400px;width: 600px;&quot;</span>&gt;</span><span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">template</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">script</span>&gt;</span><span class="language-javascript"></span></span><br><span class="line"><span class="language-javascript">    <span class="comment">// 引入需要用到的函数</span></span></span><br><span class="line"><span class="language-javascript">    <span class="keyword">import</span> &#123; ref, onMounted, getCurrentInstance &#125; <span class="keyword">from</span> <span class="string">&#x27;vue&#x27;</span></span></span><br><span class="line"><span class="language-javascript">    <span class="comment">// axios获取地图数据</span></span></span><br><span class="line"><span class="language-javascript">    <span class="keyword">import</span> axios <span class="keyword">from</span> <span class="string">&#x27;axios&#x27;</span></span></span><br><span class="line"><span class="language-javascript">    <span class="keyword">export</span> <span class="keyword">default</span> &#123;</span></span><br><span class="line"><span class="language-javascript">        <span class="title function_">setup</span>(<span class="params"></span>) &#123;</span></span><br><span class="line"><span class="language-javascript">            <span class="comment">// 用于返回出去给div的ref属性</span></span></span><br><span class="line"><span class="language-javascript">            <span class="keyword">const</span> map = <span class="title function_">ref</span>()</span></span><br><span class="line"><span class="language-javascript">            <span class="comment">// 通过proxy可以拿到全局对象</span></span></span><br><span class="line"><span class="language-javascript">            <span class="keyword">const</span> &#123; proxy &#125; = <span class="title function_">getCurrentInstance</span>()</span></span><br><span class="line"><span class="language-javascript">            <span class="keyword">function</span> <span class="title function_">get</span>(<span class="params"></span>) &#123;</span></span><br><span class="line"><span class="language-javascript">                <span class="comment">// 获取数据，记得处理跨域，跨域上面有讲到如何解决</span></span></span><br><span class="line"><span class="language-javascript">                axios.<span class="title function_">get</span>(<span class="string">&#x27;http://localhost:8080/data&#x27;</span>).<span class="title function_">then</span>(</span></span><br><span class="line"><span class="language-javascript">                    <span class="comment">// 请求成功时调用draw函数</span></span></span><br><span class="line"><span class="language-javascript">                    <span class="function"><span class="params">rsp</span> =&gt;</span> <span class="title function_">draw</span>(rsp.<span class="property">data</span>)</span></span><br><span class="line"><span class="language-javascript">                )</span></span><br><span class="line"><span class="language-javascript">            &#125;</span></span><br><span class="line"><span class="language-javascript">            <span class="keyword">function</span> <span class="title function_">draw</span>(<span class="params">data</span>) &#123;</span></span><br><span class="line"><span class="language-javascript">                <span class="comment">// console.log(data)</span></span></span><br><span class="line"><span class="language-javascript">                <span class="comment">// [&#123;name: &#x27;台湾&#x27;, value: 2093&#125;, &#123;name: &#x27;内蒙古&#x27;, value: 449&#125;......]</span></span></span><br><span class="line"><span class="language-javascript">                <span class="comment">// 通过map.value拿到ref绑定的div进行初始化</span></span></span><br><span class="line"><span class="language-javascript">                <span class="keyword">const</span> et = proxy.<span class="property">$echarts</span>.<span class="title function_">init</span>(map.<span class="property">value</span>)</span></span><br><span class="line"><span class="language-javascript">                et.<span class="title function_">setOption</span>(&#123;</span></span><br><span class="line"><span class="language-javascript">                    <span class="attr">geo</span>: &#123;</span></span><br><span class="line"><span class="language-javascript">                        <span class="comment">// 这里的china就是main.js中取名的china</span></span></span><br><span class="line"><span class="language-javascript">                        <span class="comment">// echarts.registerMap(&#x27;chinaMap&#x27;, china)</span></span></span><br><span class="line"><span class="language-javascript">                        <span class="comment">// 参数1</span></span></span><br><span class="line"><span class="language-javascript">                        <span class="attr">map</span>: <span class="string">&#x27;chinaMap&#x27;</span>,</span></span><br><span class="line"><span class="language-javascript">                        <span class="attr">label</span>: &#123;<span class="attr">show</span>: <span class="literal">true</span>&#125;</span></span><br><span class="line"><span class="language-javascript">                    &#125;,</span></span><br><span class="line"><span class="language-javascript">                    <span class="attr">series</span>: &#123;</span></span><br><span class="line"><span class="language-javascript">                        <span class="attr">type</span>: <span class="string">&#x27;map&#x27;</span>,</span></span><br><span class="line"><span class="language-javascript">                        <span class="comment">// data给过来</span></span></span><br><span class="line"><span class="language-javascript">                        <span class="attr">data</span>: data,</span></span><br><span class="line"><span class="language-javascript">                        <span class="attr">geoIndex</span>: <span class="number">0</span>,</span></span><br><span class="line"><span class="language-javascript">                    &#125;,</span></span><br><span class="line"><span class="language-javascript">                    <span class="attr">visualMap</span>: &#123;</span></span><br><span class="line"><span class="language-javascript">                        <span class="attr">max</span>: <span class="number">1000</span>,</span></span><br><span class="line"><span class="language-javascript">                        <span class="attr">min</span>: <span class="number">0</span>,</span></span><br><span class="line"><span class="language-javascript">                        <span class="attr">color</span>: [</span></span><br><span class="line"><span class="language-javascript">                            <span class="string">&#x27;red&#x27;</span>, <span class="string">&#x27;pink&#x27;</span>, <span class="string">&#x27;#fff&#x27;</span></span></span><br><span class="line"><span class="language-javascript">                        ]</span></span><br><span class="line"><span class="language-javascript">                    &#125;,</span></span><br><span class="line"><span class="language-javascript">                    <span class="attr">tooltip</span>: &#123;<span class="attr">formatter</span>: <span class="string">&#x27;&#123;b&#125;现有确诊人数: &#123;c&#125;&#x27;</span>&#125;</span></span><br><span class="line"><span class="language-javascript">                &#125;)</span></span><br><span class="line"><span class="language-javascript">            &#125;</span></span><br><span class="line"><span class="language-javascript">            <span class="title function_">onMounted</span>(get)</span></span><br><span class="line"><span class="language-javascript">            <span class="keyword">return</span> &#123; map &#125;</span></span><br><span class="line"><span class="language-javascript">        &#125;</span></span><br><span class="line"><span class="language-javascript">    &#125;</span></span><br><span class="line"><span class="language-javascript"></span><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 大数据比赛 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Echarts </tag>
            
            <tag> 可视化 </tag>
            
            <tag> Vue </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
